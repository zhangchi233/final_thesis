{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, asdict\n",
    "from typing import Union, Optional, Literal, Tuple\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "import tyro\n",
    "import copy\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.checkpoint\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from accelerate.utils import set_seed\n",
    "from accelerate.logging import get_logger\n",
    "from diffusers import DPMSolverMultistepScheduler, UniPCMultistepScheduler, DDPMScheduler, DDIMScheduler\n",
    "\n",
    "from model.custom_unet_2d_condition import (\n",
    "    UNet2DConditionCrossFrameInExistingAttnModel,\n",
    ")\n",
    "from model.util import (\n",
    "    replace_self_attention_with_cross_frame_attention,\n",
    "    add_pose_cond_to_attention_layers,\n",
    "    update_cross_frame_attention_config,\n",
    "    update_last_layer_mode,\n",
    "    update_vol_rend_inject_noise_sigma,\n",
    "    update_n_novel_images,\n",
    "    CrossFrameAttentionConfig,\n",
    "    ModelConfig,\n",
    ")\n",
    "from model.custom_stable_diffusion_pipeline import CustomStableDiffusionPipeline\n",
    "from model.custom_stable_instructPix2pix_pipeline import CustomInstructPix2pixDiffusionPipeline\n",
    "\n",
    "from io_util import (\n",
    "    setup_output_directories,\n",
    "    make_output_directories,\n",
    "    convert_to_tensorboard_dict,\n",
    "    SaveConfig\n",
    ")\n",
    "\n",
    "from metrics.image_metrics import load_lpips_vgg_model\n",
    "\n",
    "from model.util import (\n",
    "    replace_self_attention_with_cross_frame_attention,\n",
    "    update_last_layer_mode,\n",
    "    update_vol_rend_inject_noise_sigma,\n",
    "    update_n_novel_images,\n",
    "    update_cross_frame_attention_config,\n",
    "    add_pose_cond_to_attention_layers,\n",
    "    collapse_prompt_to_batch_dim,\n",
    "    collapse_tensor_to_batch_dim,\n",
    "    expand_output_to_k,\n",
    "    expand_tensor_to_k,\n",
    "    tokenize_captions,\n",
    "    ModelConfig,\n",
    "    CrossFrameAttentionConfig,\n",
    "    build_cross_attention_kwargs,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "from train_util import FinetuneConfig\n",
    "from diffusers.loaders import LoraLoaderMixin\n",
    "\n",
    "from dacite import from_dict, Config\n",
    "\n",
    "from train import test_step\n",
    "\n",
    "logger = get_logger(__name__, log_level=\"INFO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', shell=True, capture_output=True, text=True)\n",
    "output = result.stdout\n",
    "for line in output.splitlines():\n",
    "    if '=' in line:\n",
    "        var, value = line.split('=', 1)\n",
    "        os.environ[var] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataconfig:\n",
    "    root_dir =\"/root/autodl-tmp/mvs_training/dtu/\"\n",
    "    split = \"val\"\n",
    "\n",
    "    target_light = 6\n",
    "    n_views:int=3 \n",
    "    levels:int=3 \n",
    "    depth_interval:int =2.65\n",
    "    img_wh:int=None\n",
    "    abs_error:Optional[str] =\"abs\"\n",
    "    output_total:Optional[bool]=False\n",
    "    threshold: Optional[int] = 4.7\n",
    "    prompt_dir: Optional[str] = \"/root/autodl-tmp/mvs_training/dtu/co3d_blip2_captions_final.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import sys\n",
    "sys.path.append('/root/autodl-tmp/project/dp_simple/')\n",
    "from CasMVSNet_pl.datasets.utils import read_pfm\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms as T\n",
    "class DTUDataset(Dataset):\n",
    "    def __init__(self, config):\n",
    "        \"\"\"\n",
    "        img_wh should be set to a tuple ex: (1152, 864) to enable test mode!\n",
    "        \"\"\"\n",
    "\n",
    "        self.root_dir = config.root_dir\n",
    "        self.split = config.split\n",
    "        assert self.split in ['train', 'val', 'test'], \\\n",
    "            'split must be either \"train\", \"val\" or \"test\"!'\n",
    "        \n",
    "        \n",
    "        self.light_class = config.target_light\n",
    "        self.img_wh = None\n",
    "\n",
    "        \n",
    "        self.threshold = config.threshold\n",
    "        self.build_metas()\n",
    "        self.n_views = config.n_views\n",
    "        self.levels = config.levels # FPN levels\n",
    "        self.depth_interval = config.depth_interval\n",
    "        self.build_proj_mats()\n",
    "        self.define_transforms()\n",
    "        self.output_total = config.output_total\n",
    "        prompt_dir = config.prompt_dir\n",
    "        if prompt_dir != None:\n",
    "            import json\n",
    "            captions = json.load(open(prompt_dir))\n",
    "        self.prompt_dir =captions\n",
    "        \n",
    "      \n",
    "        \n",
    "        \n",
    "        \n",
    "    def build_metas(self):\n",
    "        self.metas = []\n",
    "        with open(f'/root/autodl-tmp/project/dp_simple/CasMVSNet_pl/datasets/lists/dtu/{self.split}.txt') as f:\n",
    "            self.scans = [line.rstrip() for line in f.readlines()]\n",
    "        output_pkl = f'/root/autodl-tmp/project/dp_simple/CasMVSNet_pl/datasets/lists/dtu/{self.split}_abs.pkl'\n",
    "        import pickle\n",
    "        with open(output_pkl, 'rb') as f:\n",
    "            self.output_pkl = pickle.load(f)\n",
    "        # light conditions 0-6 for training\n",
    "        # light condition 3 for testing (the brightest?)\n",
    "        outputs_total = {}\n",
    "        for scan in self.output_pkl.keys():\n",
    "            scan_index = scan.split('_')[0]\n",
    "            if scan_index not in outputs_total:\n",
    "                outputs_total[scan_index] = []\n",
    "            outputs_total[scan_index].append(self.output_pkl[scan])\n",
    "        for scan in outputs_total.keys():\n",
    "            outputs_total[scan] = np.mean(np.array(outputs_total[scan]), axis=0)\n",
    "            print(f\"scan {scan} mean output: {outputs_total[scan]}\")\n",
    "        self.total_pkl = outputs_total\n",
    "\n",
    "\n",
    "        light_idxs = list(range(7))\n",
    "\n",
    "        pair_file = \"Cameras/pair.txt\"\n",
    "        for scan in self.scans:\n",
    "            with open(os.path.join(self.root_dir, pair_file)) as f:\n",
    "                num_viewpoint = int(f.readline())\n",
    "                # viewpoints (49)\n",
    "                for _ in range(num_viewpoint):\n",
    "                    ref_view = int(f.readline().rstrip())\n",
    "                    src_views = [int(x) for x in f.readline().rstrip().split()[1::2]]\n",
    "                    \n",
    "\n",
    "                    for light_idx in light_idxs:\n",
    "                        output_key = f\"{scan}_{ref_view}_{src_views[0]}_{src_views[1]}\"\n",
    "                        losses = self.output_pkl[output_key]\n",
    "                        if np.argmin(losses)==self.light_class and self.split==\"train\":\n",
    "                            self.metas += [(scan, ref_view,light_idx, src_views,int(np.argmin(losses)))]\n",
    "                        elif self.split!=\"train\":\n",
    "                            if light_idx!=0:\n",
    "                                continue\n",
    "                            else:\n",
    "                                self.metas += [(scan, ref_view,light_idx, src_views,int(np.argmin(losses)))]\n",
    "                                \n",
    "                                \n",
    "                           \n",
    "                         \n",
    "    def build_proj_mats(self):\n",
    "        proj_mats = []\n",
    "        for vid in range(49): # total 49 view ids\n",
    "            if self.img_wh is None:\n",
    "                proj_mat_filename = os.path.join(self.root_dir,\n",
    "                                                 f'Cameras/train/{vid:08d}_cam.txt')\n",
    "            else:\n",
    "                proj_mat_filename = os.path.join(self.root_dir,\n",
    "                                                 f'Cameras/{vid:08d}_cam.txt')\n",
    "            intrinsics, extrinsics, depth_min = \\\n",
    "                self.read_cam_file(proj_mat_filename)\n",
    "            if self.img_wh is not None: # resize the intrinsics to the coarsest level\n",
    "                intrinsics[0] *= self.img_wh[0]/1600/4\n",
    "                intrinsics[1] *= self.img_wh[1]/1200/4\n",
    "            K = intrinsics\n",
    "            R = extrinsics\n",
    "            # multiply intrinsics and extrinsics to get projection matrix\n",
    "            proj_mat_ls = []\n",
    "            for l in reversed(range(self.levels)):\n",
    "                proj_mat_l = np.eye(4)\n",
    "                proj_mat_l[:3, :4] = intrinsics @ extrinsics[:3, :4]\n",
    "                intrinsics[:2] *= 2 # 1/4->1/2->1\n",
    "                proj_mat_ls += [torch.FloatTensor(proj_mat_l)]\n",
    "            # (self.levels, 4, 4) from fine to coarse\n",
    "            proj_mat_ls = torch.stack(proj_mat_ls[::-1])\n",
    "           \n",
    "            proj_mats += [(proj_mat_ls, depth_min,K,R)]\n",
    "\n",
    "        self.proj_mats = proj_mats\n",
    "\n",
    "    def read_cam_file(self, filename):\n",
    "        with open(filename) as f:\n",
    "            lines = [line.rstrip() for line in f.readlines()]\n",
    "        # extrinsics: line [1,5), 4x4 matrix\n",
    "        extrinsics = np.fromstring(' '.join(lines[1:5]), dtype=np.float32, sep=' ')\n",
    "        extrinsics = extrinsics.reshape((4, 4))\n",
    "        # intrinsics: line [7-10), 3x3 matrix\n",
    "        intrinsics = np.fromstring(' '.join(lines[7:10]), dtype=np.float32, sep=' ')\n",
    "        intrinsics = intrinsics.reshape((3, 3))\n",
    "        # depth_min & depth_interval: line 11\n",
    "        depth_min = float(lines[11].split()[0])\n",
    "        return intrinsics, extrinsics, depth_min\n",
    "\n",
    "    def read_depth(self, filename):\n",
    "        depth = np.array(read_pfm(filename)[0], dtype=np.float32) # (1200, 1600)\n",
    "        if self.img_wh is None:\n",
    "            depth = cv2.resize(depth, None, fx=0.5, fy=0.5,\n",
    "                            interpolation=cv2.INTER_NEAREST) # (600, 800)\n",
    "            depth_0 = depth[44:556, 80:720] # (512, 640)\n",
    "        else:\n",
    "            depth_0 = cv2.resize(depth, self.img_wh,\n",
    "                                 interpolation=cv2.INTER_NEAREST)\n",
    "        depth_1 = cv2.resize(depth_0, None, fx=0.5, fy=0.5,\n",
    "                             interpolation=cv2.INTER_NEAREST)\n",
    "        depth_2 = cv2.resize(depth_1, None, fx=0.5, fy=0.5,\n",
    "                             interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        depths = {\"level_0\": torch.FloatTensor(depth_0),\n",
    "                  \"level_1\": torch.FloatTensor(depth_1),\n",
    "                  \"level_2\": torch.FloatTensor(depth_2)}\n",
    "        \n",
    "        return depths\n",
    "\n",
    "    def read_mask(self, filename):\n",
    "        mask = cv2.imread(filename, 0) # (1200, 1600)\n",
    "       \n",
    "        if self.img_wh is None:\n",
    "            mask = cv2.resize(mask, None, fx=0.5, fy=0.5,\n",
    "                            interpolation=cv2.INTER_NEAREST) # (600, 800)\n",
    "            mask_0 = mask[44:556, 80:720] # (512, 640)\n",
    "        else:\n",
    "            mask_0 = cv2.resize(mask, self.img_wh,\n",
    "                                interpolation=cv2.INTER_NEAREST)\n",
    "        mask_1 = cv2.resize(mask_0, None, fx=0.5, fy=0.5,\n",
    "                            interpolation=cv2.INTER_NEAREST)\n",
    "        mask_2 = cv2.resize(mask_1, None, fx=0.5, fy=0.5,\n",
    "                            interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        masks = {\"level_0\": torch.BoolTensor(mask_0),\n",
    "                 \"level_1\": torch.BoolTensor(mask_1),\n",
    "                 \"level_2\": torch.BoolTensor(mask_2)}\n",
    "\n",
    "        return masks\n",
    "\n",
    "    def define_transforms(self):\n",
    "        if self.split == 'train': # you can add augmentation here\n",
    "            self.transform = T.Compose([T.ToTensor(),\n",
    "                                        T.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                                                    std=[0.229, 0.224, 0.225]),\n",
    "                                       ])\n",
    "        else:\n",
    "            self.transform = T.Compose([T.ToTensor(),\n",
    "                                        T.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                                                    std=[0.229, 0.224, 0.225]),\n",
    "                                       ])\n",
    "        self.unpreprocess = T.Compose([\n",
    "            T.Normalize(mean=[0, 0, 0], std=[1/0.229, 1/0.224, 1/0.225]),\n",
    "            T.Normalize(mean=[-0.485, -0.456, -0.406], std=[1, 1, 1]),\n",
    "        ])\n",
    "    \n",
    "    def decode_batch(self, batch):\n",
    "        imgs = batch['imgs']\n",
    "        proj_mats = batch['proj_mats']\n",
    "        depths = batch['depths']\n",
    "        masks = batch['masks']\n",
    "        init_depth_min = batch['init_depth_min']\n",
    "        depth_interval = batch['depth_interval']\n",
    "        return imgs, proj_mats, depths, masks, init_depth_min, depth_interval\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.metas)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    def  __getitem__(self, idx):\n",
    "       \n",
    "        scan, ref_view,light_idx, src_views,target_light = self.metas[idx]\n",
    "        # use only the reference view and first nviews-1 source views\n",
    "        view_ids = [ref_view] + src_views[:self.n_views-1]\n",
    "\n",
    "        # output_key = f\"{scan}_{ref_view}_{src_views[0]}_{src_views[1]}\"\n",
    "        # if self.total_pkl:\n",
    "        #     target_light = self.total_pkl[scan]\n",
    "        #     target_light = np.argmin(target_light)\n",
    "        # else:\n",
    "        #     target_light = self.output_pkl[output_key]\n",
    "        #     target_light = np.argmin(target_light)\n",
    "\n",
    "        \n",
    "\n",
    "        sample = {}\n",
    "        imgs = []\n",
    "        cams = []\n",
    "        proj_mats = []\n",
    "        target_imgs = []\n",
    "        Ks = []\n",
    "        Rs = []\n",
    "        intensity_stats =[]\n",
    "        prompt = str(np.random.choice(self.prompt_dir[scan][str(ref_view)],1)[0])\n",
    "         \n",
    "        sample['prompt'] = [f\"modify the lightness of image to light_class_{self.light_class} style\"]\n",
    "        for i, vid in enumerate(view_ids):\n",
    "        # NOTE that the id in image file names is from 1 to 49 (not 0~48)\n",
    "        \n",
    "            img_filename = os.path.join(self.root_dir,\n",
    "                            f'Rectified/{scan}_train/rect_{vid+1:03d}_{light_idx}_r5000.png')\n",
    "            target_filename = os.path.join(self.root_dir,\n",
    "                            f'Rectified/{scan}_train/rect_{vid+1:03d}_{self.light_class}_r5000.png')\n",
    "            mask_filename = os.path.join(self.root_dir,\n",
    "                            f'Depths/{scan}/depth_visual_{vid:04d}.png')\n",
    "            depth_filename = os.path.join(self.root_dir,\n",
    "                            f'Depths/{scan}/depth_map_{vid:04d}.pfm')\n",
    "    \n",
    "\n",
    "            img = Image.open(img_filename)\n",
    "            target_img = Image.open(target_filename)\n",
    "            if self.img_wh is not None:\n",
    "                img = img.resize(self.img_wh, Image.BILINEAR)\n",
    "                target_img = target_img.resize(self.img_wh, Image.BILINEAR)\n",
    "\n",
    "            img = self.transform(img)\n",
    "            target_img = self.transform(target_img)\n",
    "            imgs += [img]\n",
    "            target_imgs += [target_img]\n",
    "\n",
    "            proj_mat_ls, depth_min,K,R = self.proj_mats[vid]\n",
    "            Ks += [K]\n",
    "            Rs += [R]\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "            if i == 0:  # reference view\n",
    "                \n",
    "                sample['init_depth_min'] = torch.FloatTensor([depth_min])\n",
    "                \n",
    "                sample['masks'] = self.read_mask(mask_filename)\n",
    "                for key in sample['masks']:\n",
    "                    sample['masks'][key] = sample['masks'][key]\n",
    "                sample['depths'] = self.read_depth(depth_filename)\n",
    "                for key in sample['depths']:\n",
    "                    sample['depths'][key] = sample['depths'][key]\n",
    "                sample[\"depth\"] = sample[\"depths\"][\"level_0\"]\n",
    "                ref_proj_inv = torch.inverse(proj_mat_ls)\n",
    "            else:\n",
    "                \n",
    "                proj_mats += [proj_mat_ls @ ref_proj_inv]\n",
    "            var, mean = torch.var_mean(img)\n",
    "            intensity_stat = torch.stack([mean, var], dim=0)\n",
    "            intensity_stats.append(intensity_stat)\n",
    "    \n",
    "    \n",
    "        imgs = torch.stack(imgs) # (V, 3, H, W)\n",
    "        target_imgs = torch.stack(target_imgs)\n",
    "        proj_mats = torch.stack(proj_mats)[:,:,:3] # (V-1, self.levels, 3, 4) from fine to coarse\n",
    "        \n",
    "        imgs = self.unpreprocess(imgs)\n",
    "        target_imgs = self.unpreprocess(target_imgs)\n",
    "       \n",
    "        Ks = np.stack(Ks)\n",
    "        Rs = np.stack(Rs)\n",
    "        sample['pose'] = torch.tensor(Rs)\n",
    "        sample['K'] = torch.tensor(Ks)\n",
    "        sample['images'] = imgs\n",
    "        sample[\"intensity_stats\"] = torch.stack(intensity_stats)\n",
    "        sample['proj_mats'] = proj_mats\n",
    "        sample['depth_interval'] = torch.FloatTensor([self.depth_interval])\n",
    "        sample['scan_vid'] = (scan, ref_view)\n",
    "        \n",
    "\n",
    "        sample['target_imgs'] = target_imgs\n",
    "        sample[\"bbox\"] =torch.tensor([[-1, -1, -1], [1, 1, 1]], dtype=torch.float32)\n",
    "\n",
    "\n",
    "\n",
    "        return sample\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scan scan3 mean output: [3.05263341 2.92222905 2.79727794 2.86347311 2.84872966 2.86011306\n",
      " 2.89029897]\n",
      "scan scan5 mean output: [1.27925969 1.21662743 1.19024779 1.17714057 1.17585228 1.13693983\n",
      " 1.13944231]\n",
      "scan scan17 mean output: [4.23918102 4.3646479  4.26873698 4.152941   4.16164234 4.44407791\n",
      " 4.15546879]\n",
      "scan scan21 mean output: [6.7044504  6.78296111 6.79752936 6.78882487 6.74292021 6.64370545\n",
      " 6.71224226]\n",
      "scan scan28 mean output: [8.33500304 8.26974845 8.08564879 7.80853114 7.63656337 7.53135754\n",
      " 7.33638762]\n",
      "scan scan35 mean output: [1.18667069 1.32775589 1.20760566 1.06743625 1.15983699 0.91010288\n",
      " 0.87788923]\n",
      "scan scan37 mean output: [21.1885944  21.17826699 21.25191359 21.18731575 20.97766127 20.14655309\n",
      " 19.91200681]\n",
      "scan scan38 mean output: [1.69360119 1.60652492 1.57134287 1.54112932 1.56236016 1.63116413\n",
      " 1.62020702]\n",
      "scan scan40 mean output: [3.64535844 3.69948315 3.71793726 3.69029421 3.68635351 3.71370282\n",
      " 3.58273512]\n",
      "scan scan43 mean output: [2.2589177  2.24700747 2.22983368 2.24613731 2.19530878 2.33009434\n",
      " 2.42131581]\n",
      "scan scan56 mean output: [2.31583979 2.17296925 2.15377764 2.14338661 2.1395326  2.20913124\n",
      " 2.29832114]\n",
      "scan scan59 mean output: [2.25470706 2.34287849 2.48965601 2.58392481 2.6572768  2.5697732\n",
      " 2.31332584]\n",
      "scan scan66 mean output: [1.92438559 2.08761549 1.80486628 1.61805749 1.56760059 1.44017948\n",
      " 1.4255248 ]\n",
      "scan scan67 mean output: [3.06216342 3.51998134 3.27188233 3.01847513 3.0300974  3.01376892\n",
      " 2.77910937]\n",
      "scan scan82 mean output: [8.87980272 9.1904472  9.19312354 9.1552566  9.26186729 9.03365678\n",
      " 7.82553422]\n",
      "scan scan86 mean output: [16.68869462 13.0623592  11.09205004 10.73961877 10.67555843 10.71248814\n",
      " 11.94098382]\n",
      "scan scan106 mean output: [1.91600927 1.62643204 1.56631822 1.54953243 1.58691446 1.61378269\n",
      " 1.72092495]\n",
      "scan scan117 mean output: [1.6601294  1.54156241 1.50466732 1.4715858  1.46958674 1.49934888\n",
      " 1.62797041]\n"
     ]
    }
   ],
   "source": [
    "val_data = DTUDataset(dataconfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class runfig:\n",
    "    pretrained_model_name_or_path = \"/root/autodl-tmp/ViewDiff/output_var_second/all/subset_all/input_3/train/class6/saved_model_from_checkpoint-15000/\"\n",
    "    n_input_images =3\n",
    "    n_output_noise =3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = config_path = os.path.join(runfig.pretrained_model_name_or_path, \"config.json\")\n",
    "if not os.path.isfile(str(config_path)):\n",
    "        raise ValueError(\"cannot find config.json in \", config_path)\n",
    "with open(config_path, \"r\") as f:\n",
    "    config_data = json.load(f)\n",
    "finetune_config = from_dict(FinetuneConfig, data=config_data, config=Config(cast=[tuple, int]))\n",
    "runfig.cross_frame_attention = finetune_config.cross_frame_attention\n",
    "runfig.model = finetune_config.model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81f9748c1bb747b7894bd6325a4a58fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint were not used when initializing UNet2DConditionCrossFrameInExistingAttnModel: \n",
      " ['down_blocks.0.attentions.0.transformer_blocks.0.attn1.processor.temb_proj.0.bias, down_blocks.0.attentions.0.transformer_blocks.0.attn1.processor.temb_proj.0.weight, down_blocks.0.attentions.0.transformer_blocks.0.attn1.processor.temb_proj.2.bias, down_blocks.0.attentions.0.transformer_blocks.0.attn1.processor.temb_proj.2.weight, down_blocks.0.attentions.0.transformer_blocks.0.attn1.processor.to_k_lora.down.weight, down_blocks.0.attentions.0.transformer_blocks.0.attn1.processor.to_k_lora.up.weight, down_blocks.0.attentions.0.transformer_blocks.0.attn1.processor.to_out_lora.down.weight, down_blocks.0.attentions.0.transformer_blocks.0.attn1.processor.to_out_lora.up.weight, down_blocks.0.attentions.0.transformer_blocks.0.attn1.processor.to_q_lora.down.weight, down_blocks.0.attentions.0.transformer_blocks.0.attn1.processor.to_q_lora.up.weight, down_blocks.0.attentions.0.transformer_blocks.0.attn1.processor.to_v_lora.down.weight, down_blocks.0.attentions.0.transformer_blocks.0.attn1.processor.to_v_lora.up.weight, down_blocks.0.attentions.0.transformer_blocks.0.attn2.processor.to_k_lora.down.weight, down_blocks.0.attentions.0.transformer_blocks.0.attn2.processor.to_k_lora.up.weight, down_blocks.0.attentions.0.transformer_blocks.0.attn2.processor.to_out_lora.down.weight, down_blocks.0.attentions.0.transformer_blocks.0.attn2.processor.to_out_lora.up.weight, down_blocks.0.attentions.0.transformer_blocks.0.attn2.processor.to_q_lora.down.weight, down_blocks.0.attentions.0.transformer_blocks.0.attn2.processor.to_q_lora.up.weight, down_blocks.0.attentions.0.transformer_blocks.0.attn2.processor.to_v_lora.down.weight, down_blocks.0.attentions.0.transformer_blocks.0.attn2.processor.to_v_lora.up.weight, down_blocks.0.attentions.1.transformer_blocks.0.attn1.processor.temb_proj.0.bias, down_blocks.0.attentions.1.transformer_blocks.0.attn1.processor.temb_proj.0.weight, down_blocks.0.attentions.1.transformer_blocks.0.attn1.processor.temb_proj.2.bias, down_blocks.0.attentions.1.transformer_blocks.0.attn1.processor.temb_proj.2.weight, down_blocks.0.attentions.1.transformer_blocks.0.attn1.processor.to_k_lora.down.weight, down_blocks.0.attentions.1.transformer_blocks.0.attn1.processor.to_k_lora.up.weight, down_blocks.0.attentions.1.transformer_blocks.0.attn1.processor.to_out_lora.down.weight, down_blocks.0.attentions.1.transformer_blocks.0.attn1.processor.to_out_lora.up.weight, down_blocks.0.attentions.1.transformer_blocks.0.attn1.processor.to_q_lora.down.weight, down_blocks.0.attentions.1.transformer_blocks.0.attn1.processor.to_q_lora.up.weight, down_blocks.0.attentions.1.transformer_blocks.0.attn1.processor.to_v_lora.down.weight, down_blocks.0.attentions.1.transformer_blocks.0.attn1.processor.to_v_lora.up.weight, down_blocks.0.attentions.1.transformer_blocks.0.attn2.processor.to_k_lora.down.weight, down_blocks.0.attentions.1.transformer_blocks.0.attn2.processor.to_k_lora.up.weight, down_blocks.0.attentions.1.transformer_blocks.0.attn2.processor.to_out_lora.down.weight, down_blocks.0.attentions.1.transformer_blocks.0.attn2.processor.to_out_lora.up.weight, down_blocks.0.attentions.1.transformer_blocks.0.attn2.processor.to_q_lora.down.weight, down_blocks.0.attentions.1.transformer_blocks.0.attn2.processor.to_q_lora.up.weight, down_blocks.0.attentions.1.transformer_blocks.0.attn2.processor.to_v_lora.down.weight, down_blocks.0.attentions.1.transformer_blocks.0.attn2.processor.to_v_lora.up.weight, down_blocks.1.attentions.0.transformer_blocks.0.attn1.processor.temb_proj.0.bias, down_blocks.1.attentions.0.transformer_blocks.0.attn1.processor.temb_proj.0.weight, down_blocks.1.attentions.0.transformer_blocks.0.attn1.processor.temb_proj.2.bias, down_blocks.1.attentions.0.transformer_blocks.0.attn1.processor.temb_proj.2.weight, down_blocks.1.attentions.0.transformer_blocks.0.attn1.processor.to_k_lora.down.weight, down_blocks.1.attentions.0.transformer_blocks.0.attn1.processor.to_k_lora.up.weight, down_blocks.1.attentions.0.transformer_blocks.0.attn1.processor.to_out_lora.down.weight, down_blocks.1.attentions.0.transformer_blocks.0.attn1.processor.to_out_lora.up.weight, down_blocks.1.attentions.0.transformer_blocks.0.attn1.processor.to_q_lora.down.weight, down_blocks.1.attentions.0.transformer_blocks.0.attn1.processor.to_q_lora.up.weight, down_blocks.1.attentions.0.transformer_blocks.0.attn1.processor.to_v_lora.down.weight, down_blocks.1.attentions.0.transformer_blocks.0.attn1.processor.to_v_lora.up.weight, down_blocks.1.attentions.0.transformer_blocks.0.attn2.processor.to_k_lora.down.weight, down_blocks.1.attentions.0.transformer_blocks.0.attn2.processor.to_k_lora.up.weight, down_blocks.1.attentions.0.transformer_blocks.0.attn2.processor.to_out_lora.down.weight, down_blocks.1.attentions.0.transformer_blocks.0.attn2.processor.to_out_lora.up.weight, down_blocks.1.attentions.0.transformer_blocks.0.attn2.processor.to_q_lora.down.weight, down_blocks.1.attentions.0.transformer_blocks.0.attn2.processor.to_q_lora.up.weight, down_blocks.1.attentions.0.transformer_blocks.0.attn2.processor.to_v_lora.down.weight, down_blocks.1.attentions.0.transformer_blocks.0.attn2.processor.to_v_lora.up.weight, down_blocks.1.attentions.1.transformer_blocks.0.attn1.processor.temb_proj.0.bias, down_blocks.1.attentions.1.transformer_blocks.0.attn1.processor.temb_proj.0.weight, down_blocks.1.attentions.1.transformer_blocks.0.attn1.processor.temb_proj.2.bias, down_blocks.1.attentions.1.transformer_blocks.0.attn1.processor.temb_proj.2.weight, down_blocks.1.attentions.1.transformer_blocks.0.attn1.processor.to_k_lora.down.weight, down_blocks.1.attentions.1.transformer_blocks.0.attn1.processor.to_k_lora.up.weight, down_blocks.1.attentions.1.transformer_blocks.0.attn1.processor.to_out_lora.down.weight, down_blocks.1.attentions.1.transformer_blocks.0.attn1.processor.to_out_lora.up.weight, down_blocks.1.attentions.1.transformer_blocks.0.attn1.processor.to_q_lora.down.weight, down_blocks.1.attentions.1.transformer_blocks.0.attn1.processor.to_q_lora.up.weight, down_blocks.1.attentions.1.transformer_blocks.0.attn1.processor.to_v_lora.down.weight, down_blocks.1.attentions.1.transformer_blocks.0.attn1.processor.to_v_lora.up.weight, down_blocks.1.attentions.1.transformer_blocks.0.attn2.processor.to_k_lora.down.weight, down_blocks.1.attentions.1.transformer_blocks.0.attn2.processor.to_k_lora.up.weight, down_blocks.1.attentions.1.transformer_blocks.0.attn2.processor.to_out_lora.down.weight, down_blocks.1.attentions.1.transformer_blocks.0.attn2.processor.to_out_lora.up.weight, down_blocks.1.attentions.1.transformer_blocks.0.attn2.processor.to_q_lora.down.weight, down_blocks.1.attentions.1.transformer_blocks.0.attn2.processor.to_q_lora.up.weight, down_blocks.1.attentions.1.transformer_blocks.0.attn2.processor.to_v_lora.down.weight, down_blocks.1.attentions.1.transformer_blocks.0.attn2.processor.to_v_lora.up.weight, down_blocks.2.attentions.0.transformer_blocks.0.attn1.processor.temb_proj.0.bias, down_blocks.2.attentions.0.transformer_blocks.0.attn1.processor.temb_proj.0.weight, down_blocks.2.attentions.0.transformer_blocks.0.attn1.processor.temb_proj.2.bias, down_blocks.2.attentions.0.transformer_blocks.0.attn1.processor.temb_proj.2.weight, down_blocks.2.attentions.0.transformer_blocks.0.attn1.processor.to_k_lora.down.weight, down_blocks.2.attentions.0.transformer_blocks.0.attn1.processor.to_k_lora.up.weight, down_blocks.2.attentions.0.transformer_blocks.0.attn1.processor.to_out_lora.down.weight, down_blocks.2.attentions.0.transformer_blocks.0.attn1.processor.to_out_lora.up.weight, down_blocks.2.attentions.0.transformer_blocks.0.attn1.processor.to_q_lora.down.weight, down_blocks.2.attentions.0.transformer_blocks.0.attn1.processor.to_q_lora.up.weight, down_blocks.2.attentions.0.transformer_blocks.0.attn1.processor.to_v_lora.down.weight, down_blocks.2.attentions.0.transformer_blocks.0.attn1.processor.to_v_lora.up.weight, down_blocks.2.attentions.0.transformer_blocks.0.attn2.processor.to_k_lora.down.weight, down_blocks.2.attentions.0.transformer_blocks.0.attn2.processor.to_k_lora.up.weight, down_blocks.2.attentions.0.transformer_blocks.0.attn2.processor.to_out_lora.down.weight, down_blocks.2.attentions.0.transformer_blocks.0.attn2.processor.to_out_lora.up.weight, down_blocks.2.attentions.0.transformer_blocks.0.attn2.processor.to_q_lora.down.weight, down_blocks.2.attentions.0.transformer_blocks.0.attn2.processor.to_q_lora.up.weight, down_blocks.2.attentions.0.transformer_blocks.0.attn2.processor.to_v_lora.down.weight, down_blocks.2.attentions.0.transformer_blocks.0.attn2.processor.to_v_lora.up.weight, down_blocks.2.attentions.1.transformer_blocks.0.attn1.processor.temb_proj.0.bias, down_blocks.2.attentions.1.transformer_blocks.0.attn1.processor.temb_proj.0.weight, down_blocks.2.attentions.1.transformer_blocks.0.attn1.processor.temb_proj.2.bias, down_blocks.2.attentions.1.transformer_blocks.0.attn1.processor.temb_proj.2.weight, down_blocks.2.attentions.1.transformer_blocks.0.attn1.processor.to_k_lora.down.weight, down_blocks.2.attentions.1.transformer_blocks.0.attn1.processor.to_k_lora.up.weight, down_blocks.2.attentions.1.transformer_blocks.0.attn1.processor.to_out_lora.down.weight, down_blocks.2.attentions.1.transformer_blocks.0.attn1.processor.to_out_lora.up.weight, down_blocks.2.attentions.1.transformer_blocks.0.attn1.processor.to_q_lora.down.weight, down_blocks.2.attentions.1.transformer_blocks.0.attn1.processor.to_q_lora.up.weight, down_blocks.2.attentions.1.transformer_blocks.0.attn1.processor.to_v_lora.down.weight, down_blocks.2.attentions.1.transformer_blocks.0.attn1.processor.to_v_lora.up.weight, down_blocks.2.attentions.1.transformer_blocks.0.attn2.processor.to_k_lora.down.weight, down_blocks.2.attentions.1.transformer_blocks.0.attn2.processor.to_k_lora.up.weight, down_blocks.2.attentions.1.transformer_blocks.0.attn2.processor.to_out_lora.down.weight, down_blocks.2.attentions.1.transformer_blocks.0.attn2.processor.to_out_lora.up.weight, down_blocks.2.attentions.1.transformer_blocks.0.attn2.processor.to_q_lora.down.weight, down_blocks.2.attentions.1.transformer_blocks.0.attn2.processor.to_q_lora.up.weight, down_blocks.2.attentions.1.transformer_blocks.0.attn2.processor.to_v_lora.down.weight, down_blocks.2.attentions.1.transformer_blocks.0.attn2.processor.to_v_lora.up.weight, mid_block.attentions.0.transformer_blocks.0.attn1.processor.temb_proj.0.bias, mid_block.attentions.0.transformer_blocks.0.attn1.processor.temb_proj.0.weight, mid_block.attentions.0.transformer_blocks.0.attn1.processor.temb_proj.2.bias, mid_block.attentions.0.transformer_blocks.0.attn1.processor.temb_proj.2.weight, mid_block.attentions.0.transformer_blocks.0.attn1.processor.to_k_lora.down.weight, mid_block.attentions.0.transformer_blocks.0.attn1.processor.to_k_lora.up.weight, mid_block.attentions.0.transformer_blocks.0.attn1.processor.to_out_lora.down.weight, mid_block.attentions.0.transformer_blocks.0.attn1.processor.to_out_lora.up.weight, mid_block.attentions.0.transformer_blocks.0.attn1.processor.to_q_lora.down.weight, mid_block.attentions.0.transformer_blocks.0.attn1.processor.to_q_lora.up.weight, mid_block.attentions.0.transformer_blocks.0.attn1.processor.to_v_lora.down.weight, mid_block.attentions.0.transformer_blocks.0.attn1.processor.to_v_lora.up.weight, mid_block.attentions.0.transformer_blocks.0.attn2.processor.to_k_lora.down.weight, mid_block.attentions.0.transformer_blocks.0.attn2.processor.to_k_lora.up.weight, mid_block.attentions.0.transformer_blocks.0.attn2.processor.to_out_lora.down.weight, mid_block.attentions.0.transformer_blocks.0.attn2.processor.to_out_lora.up.weight, mid_block.attentions.0.transformer_blocks.0.attn2.processor.to_q_lora.down.weight, mid_block.attentions.0.transformer_blocks.0.attn2.processor.to_q_lora.up.weight, mid_block.attentions.0.transformer_blocks.0.attn2.processor.to_v_lora.down.weight, mid_block.attentions.0.transformer_blocks.0.attn2.processor.to_v_lora.up.weight, up_blocks.1.attentions.0.transformer_blocks.0.attn1.processor.temb_proj.0.bias, up_blocks.1.attentions.0.transformer_blocks.0.attn1.processor.temb_proj.0.weight, up_blocks.1.attentions.0.transformer_blocks.0.attn1.processor.temb_proj.2.bias, up_blocks.1.attentions.0.transformer_blocks.0.attn1.processor.temb_proj.2.weight, up_blocks.1.attentions.0.transformer_blocks.0.attn1.processor.to_k_lora.down.weight, up_blocks.1.attentions.0.transformer_blocks.0.attn1.processor.to_k_lora.up.weight, up_blocks.1.attentions.0.transformer_blocks.0.attn1.processor.to_out_lora.down.weight, up_blocks.1.attentions.0.transformer_blocks.0.attn1.processor.to_out_lora.up.weight, up_blocks.1.attentions.0.transformer_blocks.0.attn1.processor.to_q_lora.down.weight, up_blocks.1.attentions.0.transformer_blocks.0.attn1.processor.to_q_lora.up.weight, up_blocks.1.attentions.0.transformer_blocks.0.attn1.processor.to_v_lora.down.weight, up_blocks.1.attentions.0.transformer_blocks.0.attn1.processor.to_v_lora.up.weight, up_blocks.1.attentions.0.transformer_blocks.0.attn2.processor.to_k_lora.down.weight, up_blocks.1.attentions.0.transformer_blocks.0.attn2.processor.to_k_lora.up.weight, up_blocks.1.attentions.0.transformer_blocks.0.attn2.processor.to_out_lora.down.weight, up_blocks.1.attentions.0.transformer_blocks.0.attn2.processor.to_out_lora.up.weight, up_blocks.1.attentions.0.transformer_blocks.0.attn2.processor.to_q_lora.down.weight, up_blocks.1.attentions.0.transformer_blocks.0.attn2.processor.to_q_lora.up.weight, up_blocks.1.attentions.0.transformer_blocks.0.attn2.processor.to_v_lora.down.weight, up_blocks.1.attentions.0.transformer_blocks.0.attn2.processor.to_v_lora.up.weight, up_blocks.1.attentions.1.transformer_blocks.0.attn1.processor.temb_proj.0.bias, up_blocks.1.attentions.1.transformer_blocks.0.attn1.processor.temb_proj.0.weight, up_blocks.1.attentions.1.transformer_blocks.0.attn1.processor.temb_proj.2.bias, up_blocks.1.attentions.1.transformer_blocks.0.attn1.processor.temb_proj.2.weight, up_blocks.1.attentions.1.transformer_blocks.0.attn1.processor.to_k_lora.down.weight, up_blocks.1.attentions.1.transformer_blocks.0.attn1.processor.to_k_lora.up.weight, up_blocks.1.attentions.1.transformer_blocks.0.attn1.processor.to_out_lora.down.weight, up_blocks.1.attentions.1.transformer_blocks.0.attn1.processor.to_out_lora.up.weight, up_blocks.1.attentions.1.transformer_blocks.0.attn1.processor.to_q_lora.down.weight, up_blocks.1.attentions.1.transformer_blocks.0.attn1.processor.to_q_lora.up.weight, up_blocks.1.attentions.1.transformer_blocks.0.attn1.processor.to_v_lora.down.weight, up_blocks.1.attentions.1.transformer_blocks.0.attn1.processor.to_v_lora.up.weight, up_blocks.1.attentions.1.transformer_blocks.0.attn2.processor.to_k_lora.down.weight, up_blocks.1.attentions.1.transformer_blocks.0.attn2.processor.to_k_lora.up.weight, up_blocks.1.attentions.1.transformer_blocks.0.attn2.processor.to_out_lora.down.weight, up_blocks.1.attentions.1.transformer_blocks.0.attn2.processor.to_out_lora.up.weight, up_blocks.1.attentions.1.transformer_blocks.0.attn2.processor.to_q_lora.down.weight, up_blocks.1.attentions.1.transformer_blocks.0.attn2.processor.to_q_lora.up.weight, up_blocks.1.attentions.1.transformer_blocks.0.attn2.processor.to_v_lora.down.weight, up_blocks.1.attentions.1.transformer_blocks.0.attn2.processor.to_v_lora.up.weight, up_blocks.1.attentions.2.transformer_blocks.0.attn1.processor.temb_proj.0.bias, up_blocks.1.attentions.2.transformer_blocks.0.attn1.processor.temb_proj.0.weight, up_blocks.1.attentions.2.transformer_blocks.0.attn1.processor.temb_proj.2.bias, up_blocks.1.attentions.2.transformer_blocks.0.attn1.processor.temb_proj.2.weight, up_blocks.1.attentions.2.transformer_blocks.0.attn1.processor.to_k_lora.down.weight, up_blocks.1.attentions.2.transformer_blocks.0.attn1.processor.to_k_lora.up.weight, up_blocks.1.attentions.2.transformer_blocks.0.attn1.processor.to_out_lora.down.weight, up_blocks.1.attentions.2.transformer_blocks.0.attn1.processor.to_out_lora.up.weight, up_blocks.1.attentions.2.transformer_blocks.0.attn1.processor.to_q_lora.down.weight, up_blocks.1.attentions.2.transformer_blocks.0.attn1.processor.to_q_lora.up.weight, up_blocks.1.attentions.2.transformer_blocks.0.attn1.processor.to_v_lora.down.weight, up_blocks.1.attentions.2.transformer_blocks.0.attn1.processor.to_v_lora.up.weight, up_blocks.1.attentions.2.transformer_blocks.0.attn2.processor.to_k_lora.down.weight, up_blocks.1.attentions.2.transformer_blocks.0.attn2.processor.to_k_lora.up.weight, up_blocks.1.attentions.2.transformer_blocks.0.attn2.processor.to_out_lora.down.weight, up_blocks.1.attentions.2.transformer_blocks.0.attn2.processor.to_out_lora.up.weight, up_blocks.1.attentions.2.transformer_blocks.0.attn2.processor.to_q_lora.down.weight, up_blocks.1.attentions.2.transformer_blocks.0.attn2.processor.to_q_lora.up.weight, up_blocks.1.attentions.2.transformer_blocks.0.attn2.processor.to_v_lora.down.weight, up_blocks.1.attentions.2.transformer_blocks.0.attn2.processor.to_v_lora.up.weight, up_blocks.2.attentions.0.transformer_blocks.0.attn1.processor.temb_proj.0.bias, up_blocks.2.attentions.0.transformer_blocks.0.attn1.processor.temb_proj.0.weight, up_blocks.2.attentions.0.transformer_blocks.0.attn1.processor.temb_proj.2.bias, up_blocks.2.attentions.0.transformer_blocks.0.attn1.processor.temb_proj.2.weight, up_blocks.2.attentions.0.transformer_blocks.0.attn1.processor.to_k_lora.down.weight, up_blocks.2.attentions.0.transformer_blocks.0.attn1.processor.to_k_lora.up.weight, up_blocks.2.attentions.0.transformer_blocks.0.attn1.processor.to_out_lora.down.weight, up_blocks.2.attentions.0.transformer_blocks.0.attn1.processor.to_out_lora.up.weight, up_blocks.2.attentions.0.transformer_blocks.0.attn1.processor.to_q_lora.down.weight, up_blocks.2.attentions.0.transformer_blocks.0.attn1.processor.to_q_lora.up.weight, up_blocks.2.attentions.0.transformer_blocks.0.attn1.processor.to_v_lora.down.weight, up_blocks.2.attentions.0.transformer_blocks.0.attn1.processor.to_v_lora.up.weight, up_blocks.2.attentions.0.transformer_blocks.0.attn2.processor.to_k_lora.down.weight, up_blocks.2.attentions.0.transformer_blocks.0.attn2.processor.to_k_lora.up.weight, up_blocks.2.attentions.0.transformer_blocks.0.attn2.processor.to_out_lora.down.weight, up_blocks.2.attentions.0.transformer_blocks.0.attn2.processor.to_out_lora.up.weight, up_blocks.2.attentions.0.transformer_blocks.0.attn2.processor.to_q_lora.down.weight, up_blocks.2.attentions.0.transformer_blocks.0.attn2.processor.to_q_lora.up.weight, up_blocks.2.attentions.0.transformer_blocks.0.attn2.processor.to_v_lora.down.weight, up_blocks.2.attentions.0.transformer_blocks.0.attn2.processor.to_v_lora.up.weight, up_blocks.2.attentions.1.transformer_blocks.0.attn1.processor.temb_proj.0.bias, up_blocks.2.attentions.1.transformer_blocks.0.attn1.processor.temb_proj.0.weight, up_blocks.2.attentions.1.transformer_blocks.0.attn1.processor.temb_proj.2.bias, up_blocks.2.attentions.1.transformer_blocks.0.attn1.processor.temb_proj.2.weight, up_blocks.2.attentions.1.transformer_blocks.0.attn1.processor.to_k_lora.down.weight, up_blocks.2.attentions.1.transformer_blocks.0.attn1.processor.to_k_lora.up.weight, up_blocks.2.attentions.1.transformer_blocks.0.attn1.processor.to_out_lora.down.weight, up_blocks.2.attentions.1.transformer_blocks.0.attn1.processor.to_out_lora.up.weight, up_blocks.2.attentions.1.transformer_blocks.0.attn1.processor.to_q_lora.down.weight, up_blocks.2.attentions.1.transformer_blocks.0.attn1.processor.to_q_lora.up.weight, up_blocks.2.attentions.1.transformer_blocks.0.attn1.processor.to_v_lora.down.weight, up_blocks.2.attentions.1.transformer_blocks.0.attn1.processor.to_v_lora.up.weight, up_blocks.2.attentions.1.transformer_blocks.0.attn2.processor.to_k_lora.down.weight, up_blocks.2.attentions.1.transformer_blocks.0.attn2.processor.to_k_lora.up.weight, up_blocks.2.attentions.1.transformer_blocks.0.attn2.processor.to_out_lora.down.weight, up_blocks.2.attentions.1.transformer_blocks.0.attn2.processor.to_out_lora.up.weight, up_blocks.2.attentions.1.transformer_blocks.0.attn2.processor.to_q_lora.down.weight, up_blocks.2.attentions.1.transformer_blocks.0.attn2.processor.to_q_lora.up.weight, up_blocks.2.attentions.1.transformer_blocks.0.attn2.processor.to_v_lora.down.weight, up_blocks.2.attentions.1.transformer_blocks.0.attn2.processor.to_v_lora.up.weight, up_blocks.2.attentions.2.transformer_blocks.0.attn1.processor.temb_proj.0.bias, up_blocks.2.attentions.2.transformer_blocks.0.attn1.processor.temb_proj.0.weight, up_blocks.2.attentions.2.transformer_blocks.0.attn1.processor.temb_proj.2.bias, up_blocks.2.attentions.2.transformer_blocks.0.attn1.processor.temb_proj.2.weight, up_blocks.2.attentions.2.transformer_blocks.0.attn1.processor.to_k_lora.down.weight, up_blocks.2.attentions.2.transformer_blocks.0.attn1.processor.to_k_lora.up.weight, up_blocks.2.attentions.2.transformer_blocks.0.attn1.processor.to_out_lora.down.weight, up_blocks.2.attentions.2.transformer_blocks.0.attn1.processor.to_out_lora.up.weight, up_blocks.2.attentions.2.transformer_blocks.0.attn1.processor.to_q_lora.down.weight, up_blocks.2.attentions.2.transformer_blocks.0.attn1.processor.to_q_lora.up.weight, up_blocks.2.attentions.2.transformer_blocks.0.attn1.processor.to_v_lora.down.weight, up_blocks.2.attentions.2.transformer_blocks.0.attn1.processor.to_v_lora.up.weight, up_blocks.2.attentions.2.transformer_blocks.0.attn2.processor.to_k_lora.down.weight, up_blocks.2.attentions.2.transformer_blocks.0.attn2.processor.to_k_lora.up.weight, up_blocks.2.attentions.2.transformer_blocks.0.attn2.processor.to_out_lora.down.weight, up_blocks.2.attentions.2.transformer_blocks.0.attn2.processor.to_out_lora.up.weight, up_blocks.2.attentions.2.transformer_blocks.0.attn2.processor.to_q_lora.down.weight, up_blocks.2.attentions.2.transformer_blocks.0.attn2.processor.to_q_lora.up.weight, up_blocks.2.attentions.2.transformer_blocks.0.attn2.processor.to_v_lora.down.weight, up_blocks.2.attentions.2.transformer_blocks.0.attn2.processor.to_v_lora.up.weight, up_blocks.3.attentions.0.transformer_blocks.0.attn1.processor.temb_proj.0.bias, up_blocks.3.attentions.0.transformer_blocks.0.attn1.processor.temb_proj.0.weight, up_blocks.3.attentions.0.transformer_blocks.0.attn1.processor.temb_proj.2.bias, up_blocks.3.attentions.0.transformer_blocks.0.attn1.processor.temb_proj.2.weight, up_blocks.3.attentions.0.transformer_blocks.0.attn1.processor.to_k_lora.down.weight, up_blocks.3.attentions.0.transformer_blocks.0.attn1.processor.to_k_lora.up.weight, up_blocks.3.attentions.0.transformer_blocks.0.attn1.processor.to_out_lora.down.weight, up_blocks.3.attentions.0.transformer_blocks.0.attn1.processor.to_out_lora.up.weight, up_blocks.3.attentions.0.transformer_blocks.0.attn1.processor.to_q_lora.down.weight, up_blocks.3.attentions.0.transformer_blocks.0.attn1.processor.to_q_lora.up.weight, up_blocks.3.attentions.0.transformer_blocks.0.attn1.processor.to_v_lora.down.weight, up_blocks.3.attentions.0.transformer_blocks.0.attn1.processor.to_v_lora.up.weight, up_blocks.3.attentions.0.transformer_blocks.0.attn2.processor.to_k_lora.down.weight, up_blocks.3.attentions.0.transformer_blocks.0.attn2.processor.to_k_lora.up.weight, up_blocks.3.attentions.0.transformer_blocks.0.attn2.processor.to_out_lora.down.weight, up_blocks.3.attentions.0.transformer_blocks.0.attn2.processor.to_out_lora.up.weight, up_blocks.3.attentions.0.transformer_blocks.0.attn2.processor.to_q_lora.down.weight, up_blocks.3.attentions.0.transformer_blocks.0.attn2.processor.to_q_lora.up.weight, up_blocks.3.attentions.0.transformer_blocks.0.attn2.processor.to_v_lora.down.weight, up_blocks.3.attentions.0.transformer_blocks.0.attn2.processor.to_v_lora.up.weight, up_blocks.3.attentions.1.transformer_blocks.0.attn1.processor.temb_proj.0.bias, up_blocks.3.attentions.1.transformer_blocks.0.attn1.processor.temb_proj.0.weight, up_blocks.3.attentions.1.transformer_blocks.0.attn1.processor.temb_proj.2.bias, up_blocks.3.attentions.1.transformer_blocks.0.attn1.processor.temb_proj.2.weight, up_blocks.3.attentions.1.transformer_blocks.0.attn1.processor.to_k_lora.down.weight, up_blocks.3.attentions.1.transformer_blocks.0.attn1.processor.to_k_lora.up.weight, up_blocks.3.attentions.1.transformer_blocks.0.attn1.processor.to_out_lora.down.weight, up_blocks.3.attentions.1.transformer_blocks.0.attn1.processor.to_out_lora.up.weight, up_blocks.3.attentions.1.transformer_blocks.0.attn1.processor.to_q_lora.down.weight, up_blocks.3.attentions.1.transformer_blocks.0.attn1.processor.to_q_lora.up.weight, up_blocks.3.attentions.1.transformer_blocks.0.attn1.processor.to_v_lora.down.weight, up_blocks.3.attentions.1.transformer_blocks.0.attn1.processor.to_v_lora.up.weight, up_blocks.3.attentions.1.transformer_blocks.0.attn2.processor.to_k_lora.down.weight, up_blocks.3.attentions.1.transformer_blocks.0.attn2.processor.to_k_lora.up.weight, up_blocks.3.attentions.1.transformer_blocks.0.attn2.processor.to_out_lora.down.weight, up_blocks.3.attentions.1.transformer_blocks.0.attn2.processor.to_out_lora.up.weight, up_blocks.3.attentions.1.transformer_blocks.0.attn2.processor.to_q_lora.down.weight, up_blocks.3.attentions.1.transformer_blocks.0.attn2.processor.to_q_lora.up.weight, up_blocks.3.attentions.1.transformer_blocks.0.attn2.processor.to_v_lora.down.weight, up_blocks.3.attentions.1.transformer_blocks.0.attn2.processor.to_v_lora.up.weight, up_blocks.3.attentions.2.transformer_blocks.0.attn1.processor.temb_proj.0.bias, up_blocks.3.attentions.2.transformer_blocks.0.attn1.processor.temb_proj.0.weight, up_blocks.3.attentions.2.transformer_blocks.0.attn1.processor.temb_proj.2.bias, up_blocks.3.attentions.2.transformer_blocks.0.attn1.processor.temb_proj.2.weight, up_blocks.3.attentions.2.transformer_blocks.0.attn1.processor.to_k_lora.down.weight, up_blocks.3.attentions.2.transformer_blocks.0.attn1.processor.to_k_lora.up.weight, up_blocks.3.attentions.2.transformer_blocks.0.attn1.processor.to_out_lora.down.weight, up_blocks.3.attentions.2.transformer_blocks.0.attn1.processor.to_out_lora.up.weight, up_blocks.3.attentions.2.transformer_blocks.0.attn1.processor.to_q_lora.down.weight, up_blocks.3.attentions.2.transformer_blocks.0.attn1.processor.to_q_lora.up.weight, up_blocks.3.attentions.2.transformer_blocks.0.attn1.processor.to_v_lora.down.weight, up_blocks.3.attentions.2.transformer_blocks.0.attn1.processor.to_v_lora.up.weight, up_blocks.3.attentions.2.transformer_blocks.0.attn2.processor.to_k_lora.down.weight, up_blocks.3.attentions.2.transformer_blocks.0.attn2.processor.to_k_lora.up.weight, up_blocks.3.attentions.2.transformer_blocks.0.attn2.processor.to_out_lora.down.weight, up_blocks.3.attentions.2.transformer_blocks.0.attn2.processor.to_out_lora.up.weight, up_blocks.3.attentions.2.transformer_blocks.0.attn2.processor.to_q_lora.down.weight, up_blocks.3.attentions.2.transformer_blocks.0.attn2.processor.to_q_lora.up.weight, up_blocks.3.attentions.2.transformer_blocks.0.attn2.processor.to_v_lora.down.weight, up_blocks.3.attentions.2.transformer_blocks.0.attn2.processor.to_v_lora.up.weight']\n"
     ]
    }
   ],
   "source": [
    "pipeline = CustomInstructPix2pixDiffusionPipeline.from_pretrained(\n",
    "        runfig.pretrained_model_name_or_path\n",
    "    )\n",
    "pipeline.scheduler.config.prediction_type = finetune_config.training.noise_prediction_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({},\n",
       " [Parameter containing:\n",
       "  tensor([[-0.0099,  0.0227, -0.0026,  ...,  0.0103,  0.0204, -0.0197],\n",
       "          [ 0.0096,  0.0113, -0.0167,  ..., -0.0195, -0.0239,  0.0010],\n",
       "          [-0.0227,  0.0106, -0.0218,  ...,  0.0096,  0.0126, -0.0190],\n",
       "          ...,\n",
       "          [ 0.0108,  0.0057, -0.0092,  ..., -0.0081,  0.0166,  0.0002],\n",
       "          [ 0.0258,  0.0244,  0.0260,  ...,  0.0214, -0.0111,  0.0096],\n",
       "          [-0.0043,  0.0193, -0.0039,  ..., -0.0172, -0.0243,  0.0164]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-1.6494e-02,  2.3879e-02,  2.6534e-02, -2.2444e-04, -5.4694e-03,\n",
       "           2.1454e-02, -1.9712e-02,  1.5657e-02,  7.5675e-03, -2.6666e-03,\n",
       "           2.7222e-02,  2.3850e-02, -1.2824e-02, -1.0678e-02,  1.6965e-02,\n",
       "          -2.7551e-02, -1.0299e-02,  6.9777e-04,  1.1419e-02,  1.2455e-02,\n",
       "          -2.2354e-02,  2.6076e-02,  7.2746e-03, -1.5490e-02, -1.0398e-02,\n",
       "          -9.1915e-03, -5.5971e-03, -2.6810e-02,  2.3357e-02,  2.2142e-02,\n",
       "          -6.9998e-03, -6.1779e-03, -1.4000e-02,  1.1286e-02,  1.0375e-02,\n",
       "           2.2989e-02, -1.2068e-02,  1.6259e-02, -1.5426e-02, -1.0318e-02,\n",
       "           2.0906e-02,  1.6817e-02, -1.2707e-02, -5.8116e-03,  2.0341e-03,\n",
       "           2.1255e-02, -2.8160e-03, -1.9941e-02, -2.4958e-02, -1.6143e-02,\n",
       "           1.9872e-03,  1.7891e-02, -1.2874e-02, -1.9690e-02,  2.0649e-02,\n",
       "          -2.7014e-02, -1.8491e-02, -1.5045e-02,  1.7166e-02, -2.1016e-03,\n",
       "          -2.5254e-02, -1.9084e-02, -1.0999e-02,  1.9267e-02, -1.3420e-02,\n",
       "           7.5116e-03,  6.6589e-03, -2.4358e-02, -2.7213e-02,  7.9235e-03,\n",
       "          -1.9397e-02,  1.5028e-02, -2.0890e-02,  1.0376e-02,  7.2082e-03,\n",
       "           3.5036e-03,  1.1289e-02, -3.4200e-03,  4.1077e-03,  1.9731e-04,\n",
       "          -8.3782e-03,  1.0818e-02,  1.2789e-02, -2.7375e-02, -5.1175e-03,\n",
       "          -2.3421e-02,  1.1331e-02,  2.2624e-02, -1.2080e-02, -6.1592e-05,\n",
       "           4.6099e-03,  1.9439e-02, -2.4202e-03, -1.7347e-02, -1.0226e-02,\n",
       "          -1.8532e-02,  9.0724e-03,  2.5832e-02,  1.8250e-02, -1.7402e-03,\n",
       "           3.2126e-03,  9.9325e-03,  2.6891e-02,  2.2300e-02, -2.4843e-02,\n",
       "          -5.8765e-04, -2.1592e-02,  8.5804e-03, -1.9114e-02,  2.3252e-02,\n",
       "           1.4484e-02,  1.9951e-02,  2.1318e-02, -1.5414e-02, -1.3134e-02,\n",
       "          -1.7341e-03,  5.7862e-03, -1.8667e-02,  7.1453e-03, -1.0402e-02,\n",
       "           1.5043e-02, -9.0306e-03, -1.9978e-02, -1.9374e-02, -3.4814e-03,\n",
       "           3.4511e-03, -2.0475e-03, -1.8618e-02,  1.7825e-02,  5.5316e-03,\n",
       "          -4.9876e-03, -2.8111e-03,  1.5528e-02, -1.9723e-02,  6.8374e-03,\n",
       "          -1.2441e-02, -3.6488e-03, -1.7093e-02,  9.8329e-03, -2.2704e-02,\n",
       "          -2.7754e-02,  2.0748e-02,  6.4597e-03, -1.7776e-02, -5.3757e-03,\n",
       "          -1.1930e-02,  1.6522e-02,  2.1308e-02,  1.6252e-02, -2.3750e-02,\n",
       "          -1.0460e-02, -8.4505e-03,  2.7895e-02, -2.0766e-02, -1.4298e-02,\n",
       "          -2.2223e-02, -1.6186e-03, -5.5863e-03,  2.0736e-02,  2.5583e-02,\n",
       "           2.5986e-02, -1.0879e-02,  2.4389e-02, -2.7462e-02,  9.1854e-03,\n",
       "          -1.0345e-02,  1.5873e-02,  6.8647e-03, -6.7010e-03,  2.7586e-02,\n",
       "          -2.3653e-02,  1.6570e-02, -2.4709e-03,  1.7821e-02, -1.6912e-02,\n",
       "          -8.8028e-03, -2.0297e-02, -2.6240e-02,  1.9744e-02, -2.3069e-02,\n",
       "           6.7546e-03,  2.5731e-02,  1.2074e-02,  2.7578e-02, -4.1563e-03,\n",
       "          -2.5349e-02,  3.6274e-03, -2.3656e-03,  1.0284e-02,  3.9910e-03,\n",
       "          -1.4245e-02,  1.3970e-02,  1.5525e-03, -3.6848e-03, -1.4614e-03,\n",
       "          -2.2700e-02,  8.7499e-03,  1.7653e-02, -2.2980e-02,  5.9019e-03,\n",
       "          -2.0746e-03, -3.3787e-03,  1.5454e-02, -1.6253e-02, -9.9373e-03,\n",
       "          -1.9880e-02,  1.5963e-02,  6.0681e-03, -4.8764e-04,  1.0279e-02,\n",
       "          -7.8065e-04,  9.8832e-03, -1.6742e-03, -2.5443e-02, -1.9244e-02,\n",
       "          -1.0765e-03,  4.5577e-03,  1.2159e-02,  2.1388e-02,  1.3293e-02,\n",
       "          -1.5697e-02, -1.7039e-02,  9.7376e-03,  2.6500e-02,  9.5079e-03,\n",
       "           1.3557e-02,  2.4007e-03,  2.3075e-02,  1.5058e-02, -2.7431e-02,\n",
       "           9.2443e-03, -4.4589e-03, -1.8260e-02, -2.2357e-02, -7.4792e-03,\n",
       "           2.7089e-02, -3.1141e-03, -1.0583e-02, -3.6922e-03, -2.2932e-03,\n",
       "           1.7460e-02,  9.2654e-04,  1.7700e-02, -1.6349e-02, -2.5994e-02,\n",
       "           1.8546e-02,  2.3954e-02, -1.6944e-02,  2.1797e-02,  8.3385e-03,\n",
       "          -1.1852e-02,  3.3198e-03,  8.1552e-03, -1.0803e-02, -2.4030e-02,\n",
       "          -1.5457e-03, -2.1203e-02, -8.2934e-03, -2.5485e-02,  6.7724e-03,\n",
       "           1.5826e-03, -1.4821e-02, -2.2172e-03,  1.2928e-02,  7.0138e-03,\n",
       "          -1.8900e-02,  2.7927e-02,  1.2516e-02,  1.6319e-02,  2.4163e-02,\n",
       "          -2.3790e-03,  1.9916e-02, -1.5533e-02,  2.1339e-04, -1.7397e-03,\n",
       "          -9.2907e-03, -1.9623e-03, -2.7177e-02, -4.3398e-04, -1.1962e-02,\n",
       "           6.0363e-03, -1.4114e-03,  1.1915e-03,  1.5523e-02, -1.5216e-02,\n",
       "           1.2004e-02, -7.4427e-03, -2.2273e-02, -2.3402e-02, -5.3764e-03,\n",
       "           1.6377e-02, -2.7865e-02,  1.7385e-03, -9.2978e-03, -1.0531e-02,\n",
       "           6.2492e-03,  1.1701e-02,  1.2780e-02, -2.1997e-03,  1.2023e-02,\n",
       "           4.3622e-03, -2.6468e-02,  2.1899e-02, -9.8543e-03,  1.4419e-02,\n",
       "           3.8430e-03, -7.8576e-03, -1.1910e-02, -5.8856e-03, -4.4854e-03,\n",
       "          -1.8601e-02,  2.7163e-02,  2.6424e-02, -8.9480e-03, -2.5605e-02,\n",
       "           1.9453e-02,  1.1560e-02,  2.4655e-03,  5.7228e-03,  1.4308e-02,\n",
       "           1.2692e-02,  2.0749e-02, -1.8964e-02,  8.8047e-03,  2.7534e-02,\n",
       "           2.4436e-02,  9.0997e-03, -8.0438e-05, -2.4687e-02,  2.7112e-02,\n",
       "           2.0154e-02, -1.1729e-02, -3.7207e-03, -3.2890e-03,  1.9310e-02,\n",
       "          -1.1303e-02, -1.5719e-02,  1.0876e-02, -2.4964e-02,  1.0659e-02,\n",
       "          -1.7057e-02, -2.4523e-02, -7.7344e-03,  1.8839e-02, -9.9014e-03,\n",
       "           1.1318e-02,  9.1415e-03, -5.1275e-03, -2.5385e-02, -2.1323e-02,\n",
       "           5.7242e-03, -7.5671e-03,  1.5440e-03, -1.8764e-03,  8.9320e-03,\n",
       "           1.4257e-03, -2.5780e-03, -1.6628e-02, -1.9233e-02, -1.8392e-02,\n",
       "           1.7861e-02,  2.0694e-02,  2.4297e-02,  1.7898e-02,  1.0957e-02,\n",
       "           1.6811e-02,  4.0485e-03,  3.4781e-03, -2.3252e-04, -3.2202e-03,\n",
       "          -2.3565e-02,  2.1501e-02,  1.7742e-02, -1.5824e-02, -7.4658e-03,\n",
       "          -2.4725e-02, -2.4052e-02,  9.4001e-03,  1.7651e-02,  1.8924e-03,\n",
       "          -1.7328e-02,  2.3237e-02, -1.7681e-03,  1.4675e-02,  2.0144e-02,\n",
       "           1.3057e-02,  1.1939e-02, -1.5398e-02, -7.8764e-03, -2.6537e-03,\n",
       "           2.6789e-03, -2.7513e-02, -3.0940e-03,  2.4294e-02,  3.4642e-03,\n",
       "           1.1742e-02, -1.6541e-02,  9.3776e-03,  1.9954e-02, -2.5226e-03,\n",
       "           1.5799e-03,  1.1599e-02,  1.7018e-02, -1.2321e-02, -2.4993e-02,\n",
       "          -2.5871e-02,  1.7167e-02,  2.4527e-02,  1.1914e-02,  3.9817e-03,\n",
       "          -1.1682e-02, -8.2900e-03,  4.6741e-03, -5.3399e-03, -1.0245e-02,\n",
       "           3.6528e-03, -5.9410e-03, -7.9552e-03, -7.7432e-04, -1.7813e-02,\n",
       "          -1.6901e-02, -2.6122e-02,  2.4624e-03, -4.8338e-03, -1.7257e-02,\n",
       "          -7.5003e-06, -2.3178e-02,  7.1890e-03,  1.7601e-02, -2.0284e-02,\n",
       "          -2.3182e-02, -2.6192e-02,  6.8919e-03, -9.0151e-03, -1.4483e-02,\n",
       "           2.1812e-02, -2.2947e-02, -2.2065e-02,  1.1556e-03, -2.1647e-02,\n",
       "           5.5294e-03, -1.1504e-02,  7.4478e-04,  3.5742e-03, -2.2981e-02,\n",
       "           2.7207e-02,  1.6169e-03,  7.7918e-03,  3.9335e-03, -1.4430e-02,\n",
       "          -2.2079e-02,  3.2165e-03,  2.0864e-02, -2.6822e-02, -2.3627e-02,\n",
       "          -1.8778e-02, -1.7384e-02, -6.6041e-03,  2.4546e-02, -1.1815e-02,\n",
       "           2.5494e-02, -1.9782e-02, -1.2503e-02,  2.7008e-02, -8.9553e-03,\n",
       "           9.5866e-04,  2.2721e-02,  1.8878e-02, -1.2573e-02,  1.0703e-02,\n",
       "          -2.1563e-02, -3.3739e-03, -1.1928e-02, -1.3696e-02,  5.7262e-03,\n",
       "           5.7919e-03, -1.7879e-03, -6.7326e-03, -5.6359e-03, -2.7741e-02,\n",
       "          -1.7961e-02,  1.1296e-03, -1.0795e-02, -1.0080e-02, -3.6711e-03,\n",
       "           1.5486e-02,  1.0088e-02,  2.3131e-02, -2.4432e-02, -2.5530e-02,\n",
       "          -5.7990e-03, -5.2201e-03,  1.2838e-02,  2.4916e-02,  1.7779e-02,\n",
       "           2.1654e-02,  5.4052e-03,  4.8430e-03,  1.3918e-02, -6.4122e-03,\n",
       "          -1.1939e-02,  9.3425e-03,  7.9032e-03, -5.0156e-03,  8.0679e-03,\n",
       "          -1.5804e-02,  2.1352e-02,  4.5793e-03,  1.3243e-02, -1.6118e-02,\n",
       "          -2.3366e-02, -2.1161e-02,  1.5034e-02, -6.6106e-03, -2.4349e-03,\n",
       "           1.4584e-02,  6.3245e-03,  1.3524e-02,  2.7818e-02, -1.4455e-02,\n",
       "           1.0005e-02, -1.4553e-02, -1.9889e-02,  1.2543e-02, -1.6461e-03,\n",
       "          -2.5608e-02, -1.9209e-02,  2.6347e-02,  1.0191e-02, -6.1944e-03,\n",
       "           1.8405e-03, -2.5428e-02, -1.0722e-02, -1.9630e-02, -1.8626e-02,\n",
       "           6.4747e-03,  8.0231e-03, -1.1610e-02, -1.8379e-02,  8.6984e-04,\n",
       "           2.0349e-02,  5.0753e-03,  5.0813e-03, -1.8821e-02,  1.6106e-03,\n",
       "          -1.6503e-02,  2.2927e-02, -5.8313e-03,  2.3305e-02, -1.7468e-02,\n",
       "          -1.6720e-02, -1.0182e-03,  7.5934e-03, -6.8013e-03, -2.3376e-02,\n",
       "           2.6427e-02,  2.5426e-02,  1.2383e-02,  2.4663e-02,  1.6778e-02,\n",
       "          -6.7205e-03,  5.6339e-03,  1.4123e-02, -2.2520e-02,  9.4778e-03,\n",
       "          -1.6653e-02, -3.2241e-03, -1.7806e-02,  2.3632e-02,  1.9441e-02,\n",
       "          -1.4796e-02, -1.2487e-02, -1.3772e-02,  5.0662e-03,  1.4785e-02,\n",
       "           2.1617e-02, -2.0278e-02, -2.5174e-02,  1.5841e-02,  2.4793e-02,\n",
       "           2.2213e-02, -2.2340e-02,  1.9412e-02,  1.2829e-02,  2.7528e-02,\n",
       "          -2.2006e-02, -2.5724e-02, -1.7378e-02,  2.1369e-02,  2.4961e-02,\n",
       "          -1.8727e-02,  3.0563e-03, -3.8541e-05,  1.8681e-02, -2.7645e-02,\n",
       "          -1.6948e-02, -6.9065e-03,  5.3228e-03,  9.2172e-03, -2.1725e-02,\n",
       "          -1.6245e-02, -2.0660e-02,  1.8117e-02,  1.9818e-02, -1.3171e-02,\n",
       "           9.8135e-03,  6.7023e-03,  2.7424e-02, -9.4035e-03,  1.9004e-02,\n",
       "          -3.9964e-03,  3.2415e-03,  2.5436e-03,  2.1759e-04,  1.1417e-02,\n",
       "          -2.1081e-02,  4.2379e-04, -8.9567e-03,  1.7703e-02, -1.1624e-02,\n",
       "           2.1000e-02, -2.2870e-02, -1.7322e-02, -1.8617e-02,  1.5030e-02,\n",
       "           1.2251e-02,  4.3864e-03,  2.6433e-02,  1.5180e-02,  8.1828e-03,\n",
       "          -3.8392e-03,  1.4938e-02,  2.4310e-02, -2.0479e-02,  1.5344e-02,\n",
       "          -8.8149e-03,  1.0288e-02, -1.0465e-02, -1.9528e-02, -1.6887e-02],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0277, -0.0002,  0.0136,  ..., -0.0378,  0.0273, -0.0156],\n",
       "          [-0.0350, -0.0351,  0.0272,  ..., -0.0356, -0.0017,  0.0168],\n",
       "          [-0.0374,  0.0174,  0.0095,  ..., -0.0085,  0.0108,  0.0075],\n",
       "          ...,\n",
       "          [-0.0041, -0.0219, -0.0159,  ..., -0.0348, -0.0085,  0.0132],\n",
       "          [-0.0003, -0.0276, -0.0166,  ...,  0.0337, -0.0288, -0.0300],\n",
       "          [ 0.0128,  0.0062,  0.0372,  ..., -0.0213,  0.0034,  0.0127]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.0308,  0.0346, -0.0354, -0.0310, -0.0123, -0.0021, -0.0102,  0.0066],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0191, -0.0189,  0.0094,  ..., -0.0009, -0.0020, -0.0244],\n",
       "          [-0.0140, -0.0098, -0.0135,  ..., -0.0162,  0.0176, -0.0046],\n",
       "          [ 0.0129,  0.0026, -0.0161,  ..., -0.0322, -0.0174,  0.0322],\n",
       "          ...,\n",
       "          [ 0.0152, -0.0070,  0.0126,  ..., -0.0028, -0.0303,  0.0049],\n",
       "          [-0.0078,  0.0207,  0.0052,  ...,  0.0204, -0.0176, -0.0157],\n",
       "          [ 0.0062,  0.0105,  0.0074,  ...,  0.0045, -0.0021, -0.0234]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0211, -0.0129, -0.0029,  ..., -0.0142,  0.0048,  0.0138],\n",
       "          [-0.0081, -0.0085, -0.0303,  ..., -0.0100,  0.0041,  0.0189],\n",
       "          [ 0.0032,  0.0058,  0.0102,  ...,  0.0477,  0.0116, -0.0147],\n",
       "          ...,\n",
       "          [-0.0339,  0.0049,  0.0014,  ...,  0.0035, -0.0202, -0.0274],\n",
       "          [ 0.0218, -0.0027,  0.0163,  ...,  0.0198, -0.0022, -0.0104],\n",
       "          [-0.0150, -0.0004, -0.0152,  ..., -0.0104,  0.0024, -0.0089]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0040,  0.0041, -0.0135,  ..., -0.0053, -0.0152, -0.0258],\n",
       "          [-0.0122,  0.0277,  0.0146,  ..., -0.0296,  0.0311, -0.0010],\n",
       "          [ 0.0011, -0.0179, -0.0282,  ..., -0.0026, -0.0113, -0.0007],\n",
       "          ...,\n",
       "          [-0.0053, -0.0006,  0.0004,  ..., -0.0100,  0.0076, -0.0008],\n",
       "          [ 0.0095, -0.0049, -0.0112,  ...,  0.0080, -0.0016, -0.0076],\n",
       "          [-0.0115, -0.0306,  0.0334,  ..., -0.0056, -0.0050, -0.0006]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0144, -0.0076,  0.0259,  ..., -0.0192, -0.0165,  0.0257],\n",
       "          [ 0.0108,  0.0408, -0.0117,  ..., -0.0167,  0.0099, -0.0274],\n",
       "          [-0.0104, -0.0150, -0.0284,  ..., -0.0140, -0.0148, -0.0025],\n",
       "          ...,\n",
       "          [-0.0111,  0.0047, -0.0051,  ...,  0.0043, -0.0158,  0.0003],\n",
       "          [-0.0009,  0.0160, -0.0111,  ..., -0.0205,  0.0142, -0.0086],\n",
       "          [-0.0111,  0.0053, -0.0020,  ..., -0.0002, -0.0096, -0.0275]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0246,  0.0221, -0.0240,  ..., -0.0156, -0.0059,  0.0277],\n",
       "          [ 0.0130,  0.0006,  0.0159,  ..., -0.0229,  0.0226,  0.0145],\n",
       "          [ 0.0032, -0.0096, -0.0128,  ...,  0.0175, -0.0157,  0.0169],\n",
       "          ...,\n",
       "          [ 0.0151,  0.0098, -0.0227,  ...,  0.0099, -0.0277, -0.0091],\n",
       "          [-0.0151,  0.0149, -0.0071,  ...,  0.0094, -0.0097, -0.0261],\n",
       "          [-0.0233,  0.0170,  0.0279,  ..., -0.0218, -0.0035, -0.0195]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-8.3364e-03, -2.3446e-02,  1.3887e-02, -4.9304e-05, -2.0577e-02,\n",
       "          -4.0622e-03,  2.1539e-02, -1.6217e-02,  2.7846e-02,  1.3813e-02,\n",
       "          -2.3879e-02, -1.1398e-03,  1.7792e-02, -2.0783e-02, -1.1196e-02,\n",
       "          -2.1303e-03, -3.5413e-03,  1.3357e-02,  1.5866e-02, -1.5897e-02,\n",
       "          -2.4426e-02, -2.1552e-02, -2.4208e-02, -1.3172e-02,  2.6894e-02,\n",
       "          -5.8995e-03, -3.1080e-03, -9.8220e-03,  1.9492e-03, -1.2322e-02,\n",
       "           8.7381e-03, -1.7307e-02, -1.7325e-02,  1.3111e-02, -1.5470e-03,\n",
       "           3.7775e-04, -1.2866e-02, -9.0073e-03, -1.2110e-02,  1.9626e-02,\n",
       "          -2.1142e-02, -1.9795e-02,  7.3996e-03,  5.1424e-03,  1.6884e-02,\n",
       "          -1.2677e-02, -1.9700e-02, -2.0679e-02, -1.2029e-02, -1.6950e-02,\n",
       "          -1.7534e-02,  2.3426e-02,  2.2262e-03, -2.6599e-02, -2.4084e-02,\n",
       "          -5.5902e-03,  4.5959e-03, -1.5870e-02, -1.3782e-02, -4.4074e-03,\n",
       "           3.9805e-03,  2.3698e-02,  3.9796e-03, -9.4161e-03, -2.7251e-02,\n",
       "          -2.0455e-02,  5.4749e-03,  1.2416e-02,  2.5898e-02,  9.3401e-03,\n",
       "          -3.6339e-03,  9.0108e-03,  1.5489e-02,  2.7052e-02,  5.2219e-03,\n",
       "           5.3851e-03, -2.7782e-02,  1.5425e-02,  1.8582e-02, -5.7109e-03,\n",
       "          -1.5315e-02,  3.1472e-03,  9.7404e-03,  2.3010e-02,  2.0813e-02,\n",
       "          -2.5426e-02,  2.1278e-02, -2.0865e-02, -1.2314e-03, -8.2962e-03,\n",
       "           1.7164e-03, -6.9025e-03, -7.7066e-03,  1.3729e-02,  3.1071e-03,\n",
       "          -2.5422e-02, -1.7458e-02,  2.3939e-02, -7.6789e-03, -1.6961e-02,\n",
       "           2.4399e-02,  2.7759e-02, -1.5909e-02,  1.9220e-02,  2.1073e-02,\n",
       "           9.3091e-03,  2.7812e-02, -1.0977e-02, -2.6410e-02,  1.5158e-02,\n",
       "           8.8220e-03,  1.4897e-03,  2.5075e-02, -2.0826e-02, -1.9146e-02,\n",
       "          -5.9430e-03, -1.5556e-02, -2.7259e-02, -2.5590e-02,  7.9620e-03,\n",
       "          -8.7035e-03,  1.1270e-02,  7.4775e-03,  1.8548e-02,  1.2147e-02,\n",
       "           2.1088e-02, -1.6711e-02, -1.2276e-02,  2.1552e-02,  2.0751e-02,\n",
       "           1.1960e-02, -2.5888e-02, -1.8761e-02, -1.0498e-02, -1.9086e-02,\n",
       "           1.6803e-03, -9.6288e-03, -2.3444e-02, -2.1053e-02, -3.0680e-03,\n",
       "           2.0325e-04,  4.5850e-03, -1.6641e-02, -3.4916e-03, -2.9623e-03,\n",
       "           2.4981e-02, -6.4363e-03, -2.7489e-02, -9.4960e-03, -9.0703e-03,\n",
       "          -1.0408e-02,  6.1792e-03,  1.0232e-02,  1.3578e-04, -2.0085e-02,\n",
       "           8.5605e-03, -2.6429e-02, -2.2996e-02, -8.2953e-05, -2.2745e-02,\n",
       "           1.0589e-02, -7.8315e-03,  1.3443e-02, -1.4228e-02, -2.3912e-03,\n",
       "          -4.1379e-03, -8.7587e-03,  2.1571e-02, -6.3759e-03, -1.8057e-02,\n",
       "           1.1058e-02,  1.1443e-04, -2.0685e-03, -2.0158e-02, -2.1577e-02,\n",
       "           8.7764e-03,  4.5068e-03,  1.8108e-02, -2.7472e-02,  2.6647e-02,\n",
       "           6.0837e-03, -2.2135e-02, -1.4024e-03, -2.5504e-03,  2.5137e-03,\n",
       "          -2.0415e-02,  1.0919e-02,  1.3494e-02,  3.9966e-04, -2.4056e-02,\n",
       "           9.2691e-03, -2.3385e-02,  1.0820e-02,  1.3139e-02, -1.0216e-02,\n",
       "          -1.9239e-02,  1.3868e-02, -1.9418e-02,  2.0794e-02, -1.0700e-02,\n",
       "           2.2797e-02,  1.0571e-02, -2.1105e-02, -1.6972e-02,  1.1382e-02,\n",
       "          -1.5214e-02,  2.5537e-02,  1.9071e-02,  1.2389e-02, -1.9649e-02,\n",
       "          -1.7964e-02, -1.8640e-02, -1.9595e-02, -1.7328e-03,  2.1829e-02,\n",
       "           8.9771e-03, -2.3114e-02, -2.7516e-02,  1.8632e-02,  2.3759e-02,\n",
       "           2.0179e-02, -2.2651e-02, -1.1150e-02, -2.5175e-02,  2.0933e-02,\n",
       "          -3.3047e-03,  2.2044e-02, -9.5798e-03,  2.2919e-02, -8.7789e-04,\n",
       "          -1.9361e-03, -1.9374e-02,  3.7446e-03,  5.9899e-03, -3.1533e-03,\n",
       "          -4.4596e-03,  1.7599e-02, -2.5890e-02,  1.8887e-02,  2.2733e-02,\n",
       "           6.9662e-03, -8.3707e-03,  1.9715e-02, -1.8385e-02,  1.4593e-02,\n",
       "           2.0958e-02, -1.0114e-02,  9.5419e-03, -9.4980e-03,  2.5291e-02,\n",
       "           1.6312e-02,  9.6591e-03, -1.9192e-02,  7.5398e-03, -1.1621e-02,\n",
       "          -2.3348e-03,  2.1283e-02, -1.8116e-03, -7.4440e-03, -1.8200e-02,\n",
       "          -9.7082e-03,  1.6271e-02,  1.9636e-02,  2.5621e-02, -1.9897e-02,\n",
       "           1.0593e-02, -1.9114e-02,  7.9344e-03, -2.1109e-02,  9.9730e-03,\n",
       "           8.2745e-03, -1.3477e-02,  1.5043e-02,  2.5175e-03,  2.5914e-02,\n",
       "          -1.5527e-02,  2.1018e-02,  2.2276e-04,  6.5802e-03,  4.9171e-03,\n",
       "          -4.0820e-03, -9.4687e-03, -2.2082e-02,  6.6918e-03, -2.6645e-02,\n",
       "          -1.9671e-02, -9.8328e-03,  5.6698e-03,  4.3965e-03, -2.4354e-02,\n",
       "           1.5293e-02,  1.2917e-02,  2.4579e-02, -2.1481e-02,  1.0240e-02,\n",
       "           9.7045e-03, -1.2875e-03,  2.1886e-02,  9.2175e-03,  1.1530e-02,\n",
       "           2.9507e-03, -1.6013e-02, -1.0370e-02,  7.6620e-03, -2.5785e-02,\n",
       "           2.1094e-02,  4.4158e-03,  1.1016e-02, -1.3896e-02, -1.0545e-02,\n",
       "          -6.4761e-03, -2.5246e-02,  1.8680e-02,  2.1145e-02,  2.4323e-02,\n",
       "           2.2996e-02,  1.9689e-02,  5.5351e-03,  3.2709e-04,  2.2013e-02,\n",
       "           4.7904e-03,  1.4607e-02, -1.4555e-02, -4.1989e-03,  2.2652e-02,\n",
       "          -6.2951e-03,  6.2872e-03,  1.1325e-02,  2.0382e-02, -2.8644e-04,\n",
       "           2.5903e-02, -1.8545e-03,  1.5539e-02, -2.3102e-02, -6.1130e-03,\n",
       "           7.3562e-03,  2.2615e-02,  2.2545e-02, -6.2808e-03, -5.9020e-03,\n",
       "          -9.5357e-03,  1.0609e-03,  1.1629e-02, -1.7587e-02, -8.1748e-03,\n",
       "           2.4731e-02, -2.3380e-02, -5.6516e-03, -2.0129e-02,  1.3346e-02,\n",
       "           1.8650e-02,  1.0507e-02,  2.6221e-02,  2.3086e-02, -2.3232e-02,\n",
       "          -4.1980e-03,  2.2045e-03,  2.3465e-02, -2.7182e-02,  2.1202e-02,\n",
       "          -1.3033e-03, -1.4170e-02,  1.1793e-02,  1.7913e-03, -1.9219e-02,\n",
       "           1.5938e-02,  1.0751e-02,  2.0561e-02, -7.2377e-04,  8.3035e-03,\n",
       "           2.4200e-02, -9.2298e-03,  1.7235e-02, -1.6861e-02, -8.9702e-03,\n",
       "           1.6829e-02,  2.3173e-02,  1.2384e-04, -5.9189e-03,  2.3610e-02,\n",
       "           2.4802e-03,  1.3464e-02,  1.2428e-03, -1.5553e-02,  1.9974e-02,\n",
       "           1.7227e-02, -1.5286e-02, -2.1159e-03,  7.1782e-03, -2.8753e-03,\n",
       "           2.1389e-02,  9.6776e-03,  1.4849e-02,  2.3536e-02,  2.7395e-02,\n",
       "          -1.1752e-02, -2.2116e-02, -5.0011e-03,  2.5498e-02, -7.3389e-04,\n",
       "          -1.4416e-02,  5.3294e-03, -2.6983e-02,  2.7892e-04, -1.5942e-02,\n",
       "           1.7650e-02, -5.8173e-03,  1.4477e-02,  2.1799e-02, -1.5512e-02,\n",
       "          -2.0107e-02, -1.4796e-02, -2.0458e-02,  5.1293e-03,  2.3391e-02,\n",
       "           7.4879e-03,  1.5209e-02,  1.9829e-03, -1.4061e-02, -2.3816e-02,\n",
       "           1.2078e-02, -2.5047e-02,  2.0854e-02, -1.9322e-02, -2.4544e-02,\n",
       "           1.5834e-02, -1.3171e-02,  6.9882e-03,  2.1011e-02, -3.1471e-03,\n",
       "           7.8007e-03,  2.0442e-03, -1.2706e-02,  2.3070e-02,  6.2113e-03,\n",
       "          -2.6733e-02,  2.5036e-02, -2.0950e-02,  1.9542e-02, -1.5482e-02,\n",
       "           1.4466e-02, -5.9293e-03, -2.0593e-02,  1.1699e-02,  1.8466e-02,\n",
       "          -2.1838e-02, -8.1795e-03,  2.6083e-02, -2.0840e-02, -6.6642e-03,\n",
       "           1.3631e-02, -2.5557e-02, -2.1506e-02, -8.3980e-03,  1.8176e-02,\n",
       "           6.4325e-03, -1.0439e-02, -7.6433e-03,  2.3846e-02,  1.5939e-02,\n",
       "           1.0755e-02,  7.9450e-03,  2.4854e-02, -2.3681e-02,  1.5926e-02,\n",
       "           2.4335e-02,  2.3532e-02, -1.7514e-02,  1.8196e-03, -1.3949e-02,\n",
       "          -1.9159e-02, -1.8262e-02,  1.4298e-02, -9.8319e-03, -1.6680e-03,\n",
       "           2.0426e-02, -1.4663e-02, -1.3093e-02,  1.5784e-02,  1.8317e-02,\n",
       "          -2.5342e-02, -1.4287e-02,  1.0006e-02, -1.2342e-02,  1.4617e-02,\n",
       "           1.4341e-02,  2.5535e-02,  5.2437e-03,  1.5334e-02, -1.1725e-02,\n",
       "          -2.4444e-03, -2.5182e-02,  1.5455e-02, -8.5928e-03, -2.7412e-02,\n",
       "          -2.6746e-02,  2.5248e-02,  2.1955e-02,  2.9615e-04,  1.1961e-04,\n",
       "           1.9087e-02,  1.9669e-02,  1.1506e-02, -1.5258e-02, -1.6103e-02,\n",
       "           1.9302e-02, -2.5197e-02, -2.6868e-02,  2.1231e-02, -5.5096e-03,\n",
       "          -1.8339e-02, -4.0008e-03,  1.3832e-03, -1.3092e-02, -8.7990e-03,\n",
       "          -1.7601e-02, -2.5008e-02,  1.0333e-02, -3.8096e-03,  2.7177e-02,\n",
       "          -2.0683e-02,  5.8465e-03,  2.0679e-02,  1.5924e-02, -1.7088e-02,\n",
       "           2.6492e-02, -2.4290e-02,  2.1412e-02,  1.9580e-04, -2.2025e-02,\n",
       "          -1.8689e-02, -4.1690e-03, -3.9055e-03, -7.7938e-03, -1.1503e-02,\n",
       "          -1.0787e-02, -1.9330e-02,  1.5198e-02, -2.5644e-02, -1.0741e-03,\n",
       "           5.0185e-03, -1.9105e-02,  7.3865e-03, -3.0062e-03, -1.1217e-02,\n",
       "          -7.9596e-04, -2.4294e-03,  2.6259e-02,  8.3947e-03, -2.2595e-02,\n",
       "          -6.7307e-03, -2.5796e-02, -2.1913e-02, -1.8210e-02,  3.9557e-03,\n",
       "           5.4240e-03,  1.0928e-02, -1.1854e-02,  2.3212e-02,  1.3801e-02,\n",
       "           2.2681e-02,  2.4749e-02, -8.4573e-03,  2.5785e-02, -2.6325e-02,\n",
       "           1.0359e-02, -5.7209e-03, -3.6096e-03,  1.3385e-02,  1.7364e-02,\n",
       "          -1.3379e-02, -2.2728e-04, -2.4486e-02,  1.2516e-02,  1.5398e-02,\n",
       "          -2.2204e-02, -2.4886e-02,  2.6998e-02,  6.0961e-03,  2.7152e-02,\n",
       "           9.7869e-03, -2.0708e-02, -2.0712e-02,  2.2031e-02, -2.0509e-02,\n",
       "          -6.8506e-03, -2.3745e-02, -1.5021e-02,  9.5804e-03, -2.5544e-02,\n",
       "          -1.0222e-02, -1.2515e-02, -1.3371e-02,  1.3568e-02, -4.8643e-03,\n",
       "          -1.2749e-02,  1.6201e-04,  2.1074e-02,  4.6126e-03,  2.4826e-02,\n",
       "           1.8368e-02, -4.5916e-03,  2.3785e-02,  4.4446e-03,  3.0792e-03,\n",
       "           1.0246e-02, -1.6782e-02, -2.4265e-02, -1.3580e-02,  1.0544e-02,\n",
       "          -1.0395e-02,  5.5922e-03,  2.7576e-02, -2.2985e-02,  2.5707e-02,\n",
       "           1.6163e-02,  1.7523e-03,  3.4223e-03,  3.8595e-04,  2.6142e-02,\n",
       "          -1.1765e-02,  2.4981e-02,  1.3804e-02,  1.9699e-02,  2.2337e-02,\n",
       "           8.9356e-03,  2.2229e-02, -1.1829e-02, -1.6160e-02, -1.0345e-02,\n",
       "          -2.2707e-02,  1.6081e-02, -1.3969e-02,  1.6336e-02, -1.1317e-02,\n",
       "          -1.0836e-02, -3.0427e-03, -1.0498e-02, -1.8082e-02,  1.1216e-02],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0022, -0.0003,  0.0249,  ...,  0.0126,  0.0174,  0.0006],\n",
       "          [-0.0393, -0.0069,  0.0359,  ...,  0.0214,  0.0113,  0.0014],\n",
       "          [-0.0029, -0.0024,  0.0112,  ..., -0.0157,  0.0121,  0.0330],\n",
       "          ...,\n",
       "          [ 0.0366,  0.0329,  0.0326,  ...,  0.0383, -0.0250, -0.0217],\n",
       "          [-0.0313, -0.0338,  0.0036,  ..., -0.0283,  0.0277, -0.0113],\n",
       "          [ 0.0331, -0.0166,  0.0332,  ...,  0.0051, -0.0310, -0.0103]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.0325,  0.0230,  0.0123, -0.0150, -0.0361,  0.0074,  0.0107,  0.0008],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0197, -0.0014, -0.0184,  ...,  0.0102,  0.0014,  0.0152],\n",
       "          [ 0.0115,  0.0501, -0.0014,  ...,  0.0100,  0.0202, -0.0153],\n",
       "          [ 0.0089, -0.0005,  0.0112,  ...,  0.0033,  0.0042,  0.0014],\n",
       "          ...,\n",
       "          [ 0.0118, -0.0113, -0.0048,  ...,  0.0170,  0.0090, -0.0007],\n",
       "          [-0.0060,  0.0083, -0.0065,  ...,  0.0028,  0.0002,  0.0011],\n",
       "          [-0.0063, -0.0028, -0.0186,  ...,  0.0137,  0.0175, -0.0062]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0051, -0.0077,  0.0169,  ..., -0.0070, -0.0047, -0.0029],\n",
       "          [-0.0187, -0.0265,  0.0164,  ...,  0.0177,  0.0222,  0.0123],\n",
       "          [ 0.0091, -0.0084, -0.0131,  ..., -0.0169, -0.0311, -0.0232],\n",
       "          ...,\n",
       "          [-0.0348, -0.0010, -0.0156,  ...,  0.0268,  0.0226,  0.0010],\n",
       "          [ 0.0172,  0.0085,  0.0223,  ...,  0.0044,  0.0193,  0.0166],\n",
       "          [ 0.0034, -0.0133,  0.0035,  ...,  0.0012, -0.0100, -0.0177]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0009,  0.0187,  0.0123,  ..., -0.0297,  0.0096, -0.0038],\n",
       "          [-0.0061,  0.0153,  0.0201,  ..., -0.0179,  0.0178,  0.0105],\n",
       "          [-0.0033,  0.0211,  0.0370,  ...,  0.0190, -0.0082, -0.0236],\n",
       "          ...,\n",
       "          [ 0.0046,  0.0296,  0.0016,  ..., -0.0080,  0.0040,  0.0045],\n",
       "          [-0.0024,  0.0040, -0.0008,  ..., -0.0124,  0.0003,  0.0017],\n",
       "          [ 0.0092, -0.0086,  0.0159,  ...,  0.0137, -0.0021,  0.0114]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 2.8365e-03, -9.1591e-03,  3.3872e-02,  ...,  5.6472e-04,\n",
       "            6.7728e-03, -1.7068e-02],\n",
       "          [-4.3221e-04, -4.9025e-03, -2.9287e-02,  ...,  1.0363e-02,\n",
       "            6.2634e-04,  1.3962e-03],\n",
       "          [ 2.7276e-02,  2.6145e-02,  1.0570e-02,  ...,  1.6443e-02,\n",
       "            8.3146e-03, -2.0136e-02],\n",
       "          ...,\n",
       "          [-1.5744e-03, -4.3380e-03,  2.0296e-02,  ..., -2.4564e-03,\n",
       "            2.9855e-03,  4.6820e-03],\n",
       "          [ 1.9208e-02, -1.7225e-02, -4.1817e-03,  ..., -2.0952e-03,\n",
       "            6.1430e-03,  4.9662e-05],\n",
       "          [ 8.1085e-04, -1.6133e-02,  1.2513e-02,  ..., -1.8051e-02,\n",
       "            1.9239e-02, -2.0497e-03]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0174, -0.0108, -0.0124,  ...,  0.0223, -0.0267, -0.0061],\n",
       "          [-0.0019,  0.0226, -0.0049,  ...,  0.0128,  0.0130, -0.0191],\n",
       "          [ 0.0136, -0.0150,  0.0248,  ..., -0.0047, -0.0003, -0.0143],\n",
       "          ...,\n",
       "          [ 0.0185, -0.0272, -0.0093,  ...,  0.0172, -0.0019, -0.0102],\n",
       "          [ 0.0135,  0.0050, -0.0079,  ..., -0.0098, -0.0002, -0.0044],\n",
       "          [-0.0134, -0.0111, -0.0054,  ..., -0.0100, -0.0020,  0.0036]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 1.6481e-02, -2.0653e-02,  2.6260e-02, -2.1327e-02,  1.6174e-02,\n",
       "           1.2584e-02, -3.1405e-03, -1.5375e-02, -4.5864e-03, -1.6910e-02,\n",
       "          -1.4543e-03, -2.4571e-02,  1.3633e-02,  5.9516e-03,  2.4513e-02,\n",
       "           7.1602e-03, -2.2746e-02,  2.0574e-02,  1.7535e-02,  2.7888e-02,\n",
       "           8.4386e-03, -5.7697e-03,  4.9686e-03, -2.0861e-03, -1.8990e-02,\n",
       "          -1.3997e-02,  2.1205e-02,  8.9935e-03,  2.7479e-02,  2.1193e-02,\n",
       "           1.5122e-02,  2.6843e-02,  1.0471e-02,  1.0246e-02, -2.3992e-02,\n",
       "           1.6081e-03,  2.0385e-02,  1.9745e-02, -2.5970e-02,  2.5648e-02,\n",
       "          -6.7267e-03, -2.7323e-02,  1.9173e-02, -2.6896e-02, -2.3117e-02,\n",
       "          -9.6870e-04,  2.8002e-03,  1.0968e-02, -5.4161e-03,  1.2342e-02,\n",
       "           2.1260e-02, -1.7946e-02,  3.4726e-03,  4.7901e-04,  2.7689e-02,\n",
       "          -3.3092e-03, -1.8674e-03, -4.0737e-03, -1.1990e-02,  3.7121e-03,\n",
       "          -5.7000e-03, -1.9145e-02, -4.2241e-03,  2.6725e-02, -1.1958e-03,\n",
       "          -5.4547e-03,  2.5979e-02,  1.4042e-03,  1.0296e-02, -2.6269e-02,\n",
       "          -8.4450e-03, -1.7420e-02,  6.6744e-03,  1.3327e-02, -1.0196e-02,\n",
       "           1.8739e-03, -1.8992e-02,  1.9233e-03,  2.5667e-02, -1.2924e-02,\n",
       "          -4.2381e-03, -2.2472e-02, -1.0317e-02, -9.4861e-04,  2.2797e-02,\n",
       "           2.5982e-02, -1.5387e-02, -2.4343e-02, -2.4516e-02,  6.2859e-03,\n",
       "          -2.6675e-02,  2.0066e-03,  1.4494e-02, -2.6366e-02, -1.0491e-03,\n",
       "          -1.3298e-02,  1.1044e-02,  4.1024e-03, -2.7742e-02,  1.1597e-03,\n",
       "           7.1801e-04, -8.0270e-03,  8.4012e-03,  9.7128e-04,  2.7319e-02,\n",
       "          -1.5359e-02,  7.6304e-03, -7.6215e-03,  2.0861e-02, -2.4340e-02,\n",
       "           2.0773e-02, -1.2888e-02,  1.3794e-02,  2.1924e-02, -3.7806e-03,\n",
       "          -1.1065e-02, -1.7886e-02,  2.2793e-02, -2.2835e-02,  2.3986e-02,\n",
       "          -1.0727e-02,  1.0919e-02,  5.6635e-03, -1.8576e-02, -1.7635e-02,\n",
       "           1.3565e-02,  1.6913e-02,  2.3346e-02, -2.2619e-02,  2.1390e-03,\n",
       "           2.6796e-03,  9.4758e-03, -1.8943e-02,  1.0635e-02, -1.4934e-02,\n",
       "          -1.5903e-03,  9.6979e-03,  1.3143e-02, -4.1683e-04, -2.5375e-02,\n",
       "           5.4804e-03,  2.5482e-02, -2.6162e-02,  1.8853e-02, -2.5483e-02,\n",
       "          -6.6370e-03, -9.6120e-03, -1.1463e-02,  2.5577e-02, -2.5784e-02,\n",
       "          -2.3407e-03, -2.5929e-02,  7.9406e-03,  1.0084e-02,  1.4685e-02,\n",
       "          -1.0195e-02,  1.5405e-02, -6.8664e-03, -1.5293e-02,  1.0427e-02,\n",
       "          -1.4596e-02, -1.7434e-02,  5.7879e-04,  6.4592e-03,  5.8915e-03,\n",
       "          -1.1532e-02, -1.8230e-02, -1.0695e-03,  2.2617e-02, -9.0463e-03,\n",
       "           2.4362e-03,  1.3373e-02,  1.0146e-02, -1.3019e-02, -2.0095e-02,\n",
       "           1.6036e-03, -2.1966e-02, -6.2818e-03, -3.9244e-03, -1.0620e-02,\n",
       "           2.2371e-02, -2.7518e-02, -1.5887e-02, -7.1824e-03, -2.0265e-03,\n",
       "           1.9229e-02, -2.2226e-02, -5.9892e-03,  1.4751e-02, -1.9914e-02,\n",
       "           2.6912e-02,  1.4675e-02,  1.9182e-02,  2.1865e-02, -1.6589e-02,\n",
       "           6.0269e-03,  5.8130e-03, -1.4567e-02, -1.5224e-02, -2.6236e-02,\n",
       "           5.7356e-03,  2.6025e-03,  6.1098e-03,  2.0900e-02,  3.2456e-03,\n",
       "          -9.8753e-03,  1.3180e-02, -1.1944e-02, -2.5926e-02, -5.8841e-03,\n",
       "           1.9835e-02,  2.5795e-02,  2.7156e-02, -1.3872e-02, -1.4226e-02,\n",
       "          -7.3615e-03,  6.9325e-03, -7.5517e-03, -5.9221e-03, -2.2158e-02,\n",
       "          -2.4323e-02, -7.1170e-03, -1.5526e-02, -2.1417e-02, -7.7168e-03,\n",
       "          -2.4319e-02,  1.6878e-02, -3.2257e-03,  6.5838e-03, -6.0791e-03,\n",
       "           1.9969e-02,  2.5820e-02,  8.7658e-03, -1.3945e-02,  2.2518e-02,\n",
       "           1.2994e-03,  2.6542e-02,  1.2958e-02, -2.4607e-02,  4.2242e-03,\n",
       "           1.5678e-02, -2.6347e-02,  2.9241e-03,  2.1518e-02,  1.5648e-02,\n",
       "           8.7873e-03, -2.3006e-02, -2.5695e-02, -8.9476e-03,  7.1448e-03,\n",
       "          -1.4126e-04,  1.6656e-02,  5.9525e-03, -2.7620e-02,  1.5539e-02,\n",
       "           1.7118e-02,  1.5869e-02, -1.1011e-02, -2.4833e-02,  2.0263e-02,\n",
       "          -1.5462e-02, -1.1150e-02,  1.1830e-02, -8.8843e-03, -7.7590e-03,\n",
       "          -2.6127e-02,  2.0793e-02,  1.0851e-02, -2.0066e-02,  2.1046e-02,\n",
       "          -2.4463e-02, -1.4403e-02,  1.3907e-02,  1.3740e-03,  7.9232e-03,\n",
       "           2.2281e-02, -1.7563e-02,  1.5589e-02,  1.4290e-02, -2.4651e-02,\n",
       "          -7.6785e-03,  1.5345e-02, -4.5190e-03, -4.5531e-03, -6.4975e-03,\n",
       "           1.3550e-02,  3.8251e-03, -7.6608e-03, -2.0730e-02, -2.4764e-02,\n",
       "           1.8676e-02,  1.7713e-02, -5.4565e-03, -1.2378e-02, -2.7154e-02,\n",
       "          -2.1261e-02,  1.3495e-02,  1.3597e-02, -2.2975e-02,  2.2534e-02,\n",
       "          -2.6022e-02,  4.8853e-03, -1.1339e-03,  1.0775e-02,  2.3270e-02,\n",
       "           2.5954e-02, -1.9117e-02, -1.6143e-02,  9.3978e-03, -8.2363e-03,\n",
       "          -1.5816e-02, -2.6315e-02, -4.8042e-03, -1.4533e-02, -2.5379e-02,\n",
       "          -3.4656e-03,  2.3083e-02, -5.4706e-03, -4.7085e-03,  1.7735e-02,\n",
       "           2.7255e-02, -2.2628e-02, -2.1922e-02,  2.3423e-02, -1.6414e-02,\n",
       "           1.9797e-02,  2.4035e-02,  1.6249e-03, -7.3651e-03, -1.9916e-02,\n",
       "           6.8157e-03, -1.2329e-02, -7.7593e-03,  1.8231e-02,  1.6073e-02,\n",
       "          -2.1603e-02,  2.7414e-02, -3.2541e-03, -1.3296e-02, -5.5024e-03,\n",
       "           2.6356e-02,  9.6223e-03,  1.3272e-02,  1.8539e-02, -2.6633e-02,\n",
       "          -1.9155e-02, -1.9784e-02, -1.8091e-03,  2.6491e-02, -5.9909e-03,\n",
       "           2.0241e-02, -1.3923e-02, -2.7848e-02, -1.7912e-02,  2.2244e-02,\n",
       "           2.4367e-02,  6.4820e-03, -2.2686e-02, -4.1992e-03, -1.5037e-02,\n",
       "          -2.6022e-02, -1.0901e-02,  1.9905e-02,  1.7064e-02, -9.0724e-04,\n",
       "          -1.6958e-03, -1.5048e-02, -7.4251e-03,  1.1890e-04, -8.9449e-03,\n",
       "           1.3958e-02,  1.1548e-02, -1.9248e-02,  3.7479e-03,  1.3196e-02,\n",
       "           2.3710e-02, -2.1933e-02, -2.0210e-02,  1.7352e-02, -2.3802e-02,\n",
       "           2.3267e-02,  3.0025e-03, -1.8090e-02,  3.4993e-04, -9.5058e-04,\n",
       "           1.8412e-02,  2.0877e-02,  2.6933e-02,  1.8404e-03, -5.8678e-03,\n",
       "           7.8002e-03, -2.5736e-02, -2.5323e-02, -2.1903e-03,  2.5430e-02,\n",
       "           1.4701e-02,  5.2953e-04,  2.7363e-03,  2.3521e-02,  5.9856e-03,\n",
       "          -9.6980e-03, -2.9055e-03, -2.5381e-02,  1.6217e-02, -2.1625e-02,\n",
       "           6.3894e-03, -1.5817e-02,  1.9766e-02,  1.7429e-02,  1.3216e-03,\n",
       "           2.2325e-02, -2.3556e-02, -6.2728e-03,  1.3193e-02,  9.7473e-03,\n",
       "           2.0883e-02,  3.6050e-03, -1.2824e-02,  1.8334e-02,  2.1998e-02,\n",
       "          -9.9371e-03, -6.6531e-03,  1.2191e-02,  2.6375e-02, -1.8267e-02,\n",
       "           1.0553e-02, -1.4192e-02, -1.1228e-03,  2.4425e-02, -9.5478e-03,\n",
       "           1.9377e-02,  9.4756e-04,  1.4102e-02,  1.6241e-02, -4.6254e-04,\n",
       "          -1.2007e-02, -8.9306e-03,  2.4815e-02,  2.6440e-02, -9.6978e-03,\n",
       "           1.4623e-02,  2.3043e-03, -1.0876e-02,  4.2041e-03,  9.3419e-03,\n",
       "          -2.0747e-02, -1.4230e-02,  2.3117e-02,  1.5254e-02,  7.8649e-03,\n",
       "          -1.0209e-02,  1.2614e-02, -1.7200e-02, -5.7349e-04, -2.4229e-02,\n",
       "          -2.4898e-04, -1.4274e-02, -7.8166e-03, -1.3597e-02, -7.4707e-03,\n",
       "           6.6303e-03,  2.1588e-02,  2.3905e-02, -7.4750e-03,  2.2703e-02,\n",
       "           5.2340e-03,  1.0281e-03, -1.4561e-02,  1.8392e-02, -1.6769e-03,\n",
       "          -1.6391e-02,  2.3809e-02, -1.4125e-02,  1.9640e-02,  2.7699e-02,\n",
       "          -2.8494e-03,  1.2917e-02,  1.5249e-02,  1.8916e-02,  1.1404e-02,\n",
       "          -1.5388e-02,  9.9521e-03,  2.0874e-02, -1.5520e-02,  8.1604e-03,\n",
       "           8.2464e-03,  1.6704e-02, -1.4398e-02,  2.3642e-02, -5.9291e-03,\n",
       "          -1.7250e-02, -1.3497e-03, -1.7570e-02,  1.2535e-02,  7.4202e-03,\n",
       "           4.3501e-04,  1.2994e-02, -4.9602e-03, -7.1808e-03,  2.7679e-02,\n",
       "           1.9586e-02,  1.4868e-02,  2.5779e-03,  2.6742e-03, -2.1204e-02,\n",
       "           1.9159e-02,  1.8415e-02, -2.7525e-02, -2.0187e-02, -2.0324e-02,\n",
       "           2.4350e-02, -4.4016e-03, -6.9148e-03, -2.1048e-02, -1.0094e-02,\n",
       "           2.0591e-02, -1.4024e-02,  1.5321e-02,  3.5632e-04,  9.5417e-03,\n",
       "           2.7541e-02,  4.2050e-04, -1.9547e-02,  2.3280e-02, -1.7315e-02,\n",
       "          -2.7928e-02,  6.0229e-03, -1.2076e-02,  2.8200e-03, -5.1560e-03,\n",
       "           9.7428e-03,  2.5656e-03, -9.5448e-03, -1.3754e-02, -2.0655e-02,\n",
       "           1.6543e-02,  1.3396e-02,  1.6295e-02,  2.5465e-02,  1.9942e-02,\n",
       "          -2.4788e-02,  1.3119e-02,  1.4972e-02, -2.0727e-02, -1.9932e-02,\n",
       "           2.3551e-02, -1.7396e-02,  5.6467e-03, -1.0262e-02,  1.9363e-02,\n",
       "           2.3197e-02, -7.2519e-03, -2.5183e-02,  1.9876e-02, -2.2986e-02,\n",
       "           2.3044e-02,  2.0310e-02,  6.1037e-03,  9.0021e-03, -1.1865e-02,\n",
       "          -1.9645e-02, -6.1321e-03,  2.4705e-02, -2.1066e-02, -4.2984e-03,\n",
       "          -1.2444e-03,  2.1562e-02, -1.8091e-02,  8.3858e-03, -9.6593e-03,\n",
       "           4.3185e-03,  5.7428e-03, -1.0672e-02, -1.1119e-02, -2.4543e-02,\n",
       "           6.7034e-03,  1.0708e-02, -1.8858e-04,  2.0911e-02, -1.7601e-02,\n",
       "          -2.1096e-02,  1.3870e-03,  2.9031e-03, -8.2574e-03,  8.6855e-03,\n",
       "          -1.2158e-02,  2.4452e-02,  3.4113e-05,  8.1432e-04,  7.9351e-03,\n",
       "          -1.9386e-02,  2.3456e-02, -7.6226e-03,  2.2090e-02,  1.6955e-02,\n",
       "          -2.0692e-02,  8.7772e-03, -7.8719e-03,  2.0855e-02, -1.3120e-02,\n",
       "          -1.8109e-02, -8.6082e-03,  1.1775e-02, -2.5803e-02,  1.2427e-03,\n",
       "          -1.1704e-02,  1.1381e-02, -2.4530e-02,  2.5753e-02,  1.3640e-02,\n",
       "           2.3340e-02,  2.6938e-02,  1.6785e-02, -1.1155e-02,  1.0424e-02,\n",
       "           1.8764e-02, -5.6724e-03, -4.8751e-03, -1.7717e-02, -1.4460e-02,\n",
       "          -1.5417e-02,  2.7062e-02, -1.8054e-02,  4.7188e-03, -2.0000e-02,\n",
       "          -2.1244e-02, -6.9345e-03,  1.7859e-02, -1.6651e-02, -2.4618e-02,\n",
       "           1.0287e-02, -4.5564e-03,  3.1708e-03,  1.9531e-02, -1.1085e-02,\n",
       "           7.1302e-03,  1.9995e-02, -2.0094e-02,  1.6960e-02, -2.5432e-02],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0328,  0.0160,  0.0302,  ..., -0.0307, -0.0320,  0.0063],\n",
       "          [-0.0187, -0.0166, -0.0115,  ...,  0.0109,  0.0185,  0.0296],\n",
       "          [-0.0363,  0.0047,  0.0306,  ...,  0.0387,  0.0041, -0.0227],\n",
       "          ...,\n",
       "          [ 0.0315, -0.0225, -0.0024,  ..., -0.0096, -0.0184,  0.0306],\n",
       "          [-0.0274,  0.0014,  0.0204,  ..., -0.0188, -0.0065,  0.0131],\n",
       "          [-0.0108,  0.0245, -0.0322,  ...,  0.0350, -0.0268,  0.0382]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0299, -0.0192, -0.0138, -0.0350, -0.0199, -0.0252,  0.0234,  0.0041],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0070, -0.0023,  0.0041,  ...,  0.0070, -0.0138, -0.0040],\n",
       "          [-0.0007,  0.0241,  0.0208,  ...,  0.0057, -0.0274, -0.0150],\n",
       "          [-0.0157,  0.0011,  0.0284,  ...,  0.0155,  0.0155,  0.0071],\n",
       "          ...,\n",
       "          [ 0.0068, -0.0126, -0.0275,  ...,  0.0091,  0.0284,  0.0245],\n",
       "          [-0.0037, -0.0229,  0.0222,  ..., -0.0013, -0.0040, -0.0101],\n",
       "          [-0.0108,  0.0082, -0.0013,  ...,  0.0310, -0.0028,  0.0109]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0314, -0.0024,  0.0279,  ..., -0.0111,  0.0111, -0.0138],\n",
       "          [ 0.0103, -0.0090, -0.0021,  ...,  0.0458, -0.0176,  0.0274],\n",
       "          [-0.0011, -0.0067,  0.0004,  ...,  0.0093, -0.0254,  0.0155],\n",
       "          ...,\n",
       "          [ 0.0097, -0.0117, -0.0277,  ...,  0.0156,  0.0192, -0.0144],\n",
       "          [ 0.0180, -0.0134,  0.0025,  ...,  0.0059, -0.0229,  0.0054],\n",
       "          [-0.0037,  0.0035,  0.0023,  ...,  0.0068, -0.0065,  0.0133]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0101, -0.0028, -0.0214,  ...,  0.0295, -0.0162,  0.0112],\n",
       "          [ 0.0083,  0.0059,  0.0248,  ..., -0.0193, -0.0111, -0.0055],\n",
       "          [ 0.0050,  0.0005,  0.0161,  ...,  0.0118, -0.0187, -0.0019],\n",
       "          ...,\n",
       "          [ 0.0155, -0.0148, -0.0199,  ..., -0.0045,  0.0049,  0.0066],\n",
       "          [-0.0042, -0.0156,  0.0248,  ...,  0.0182, -0.0213,  0.0261],\n",
       "          [-0.0101,  0.0182, -0.0130,  ...,  0.0330,  0.0097, -0.0044]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0071,  0.0023,  0.0036,  ..., -0.0071, -0.0081, -0.0094],\n",
       "          [-0.0030, -0.0192,  0.0316,  ...,  0.0178,  0.0073,  0.0100],\n",
       "          [ 0.0100, -0.0087, -0.0179,  ..., -0.0039,  0.0302,  0.0058],\n",
       "          ...,\n",
       "          [ 0.0193, -0.0318,  0.0139,  ...,  0.0136, -0.0273, -0.0193],\n",
       "          [ 0.0311, -0.0231, -0.0091,  ..., -0.0150,  0.0076,  0.0102],\n",
       "          [ 0.0064, -0.0190, -0.0184,  ...,  0.0290, -0.0138, -0.0150]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0233, -0.0257,  0.0254,  ..., -0.0016, -0.0081,  0.0025],\n",
       "          [-0.0223,  0.0148,  0.0124,  ...,  0.0164, -0.0099, -0.0056],\n",
       "          [-0.0168,  0.0270,  0.0094,  ..., -0.0128,  0.0186,  0.0196],\n",
       "          ...,\n",
       "          [-0.0010,  0.0085, -0.0197,  ..., -0.0200,  0.0157,  0.0157],\n",
       "          [ 0.0080,  0.0220, -0.0262,  ..., -0.0004,  0.0023,  0.0236],\n",
       "          [ 0.0009,  0.0126, -0.0234,  ..., -0.0054, -0.0095,  0.0068]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.0127,  0.0156, -0.0117, -0.0194, -0.0003,  0.0226,  0.0076,  0.0054,\n",
       "           0.0209, -0.0119,  0.0096,  0.0229,  0.0136, -0.0252,  0.0164,  0.0236,\n",
       "           0.0062,  0.0139, -0.0114,  0.0155, -0.0174,  0.0159, -0.0120,  0.0122,\n",
       "           0.0055, -0.0026, -0.0102,  0.0047, -0.0042,  0.0150, -0.0160,  0.0214,\n",
       "           0.0049, -0.0271, -0.0219,  0.0067, -0.0005, -0.0164,  0.0010,  0.0041,\n",
       "          -0.0081,  0.0081, -0.0127,  0.0113, -0.0272,  0.0140, -0.0209, -0.0173,\n",
       "          -0.0062,  0.0016, -0.0071,  0.0148,  0.0013,  0.0137, -0.0249, -0.0148,\n",
       "           0.0195,  0.0068,  0.0107, -0.0211, -0.0096, -0.0133,  0.0256, -0.0118,\n",
       "          -0.0147, -0.0063, -0.0180, -0.0164,  0.0004, -0.0250,  0.0160,  0.0260,\n",
       "           0.0047,  0.0028, -0.0237, -0.0186, -0.0239, -0.0213, -0.0263, -0.0064,\n",
       "           0.0185, -0.0262, -0.0084, -0.0010,  0.0268,  0.0167, -0.0021, -0.0228,\n",
       "           0.0131, -0.0156,  0.0149, -0.0062,  0.0153,  0.0146, -0.0004,  0.0012,\n",
       "           0.0119, -0.0126,  0.0124, -0.0252,  0.0104, -0.0047,  0.0248,  0.0022,\n",
       "          -0.0031, -0.0185,  0.0180,  0.0091, -0.0143,  0.0147, -0.0089, -0.0069,\n",
       "           0.0269, -0.0238, -0.0036, -0.0122, -0.0025, -0.0224,  0.0012, -0.0021,\n",
       "           0.0038,  0.0246,  0.0065,  0.0182,  0.0103,  0.0100,  0.0132,  0.0092,\n",
       "           0.0270,  0.0080,  0.0160,  0.0090,  0.0197, -0.0046,  0.0112, -0.0058,\n",
       "           0.0255,  0.0207, -0.0265,  0.0059,  0.0120,  0.0082, -0.0205,  0.0166,\n",
       "           0.0085,  0.0102, -0.0171,  0.0046, -0.0015, -0.0136, -0.0203, -0.0202,\n",
       "           0.0057,  0.0045,  0.0017,  0.0080, -0.0200, -0.0067,  0.0043,  0.0253,\n",
       "           0.0156,  0.0030,  0.0185,  0.0277,  0.0127, -0.0262,  0.0019,  0.0024,\n",
       "           0.0071, -0.0004,  0.0269,  0.0223,  0.0130, -0.0179,  0.0121,  0.0040,\n",
       "          -0.0233,  0.0195,  0.0058,  0.0026, -0.0029, -0.0133, -0.0245, -0.0181,\n",
       "          -0.0190,  0.0119,  0.0279,  0.0194, -0.0105, -0.0040,  0.0169, -0.0213,\n",
       "           0.0230, -0.0181, -0.0037, -0.0277,  0.0082,  0.0185, -0.0041, -0.0045,\n",
       "           0.0239, -0.0216, -0.0109,  0.0130,  0.0119, -0.0070, -0.0096,  0.0187,\n",
       "          -0.0078,  0.0186, -0.0233, -0.0032, -0.0063, -0.0065, -0.0081,  0.0003,\n",
       "          -0.0225,  0.0019,  0.0079,  0.0275,  0.0153, -0.0168, -0.0098, -0.0104,\n",
       "          -0.0196, -0.0078,  0.0129, -0.0026,  0.0132,  0.0063,  0.0243,  0.0008,\n",
       "           0.0207,  0.0086, -0.0194,  0.0035,  0.0256, -0.0014, -0.0265,  0.0238,\n",
       "           0.0262,  0.0153, -0.0068, -0.0064, -0.0188, -0.0083, -0.0068,  0.0074,\n",
       "          -0.0049, -0.0277,  0.0218, -0.0257, -0.0200, -0.0273, -0.0212, -0.0195,\n",
       "          -0.0105, -0.0211,  0.0209,  0.0200, -0.0017, -0.0115,  0.0266, -0.0125,\n",
       "           0.0223, -0.0160,  0.0098,  0.0254,  0.0198, -0.0225, -0.0151, -0.0260,\n",
       "           0.0036, -0.0014, -0.0151, -0.0275, -0.0121,  0.0238, -0.0085, -0.0175,\n",
       "          -0.0059,  0.0029, -0.0174,  0.0017,  0.0196, -0.0168, -0.0155, -0.0086,\n",
       "          -0.0197, -0.0038, -0.0232, -0.0223, -0.0121, -0.0037, -0.0270, -0.0064,\n",
       "           0.0112,  0.0040,  0.0274,  0.0275, -0.0125,  0.0193, -0.0019,  0.0043,\n",
       "          -0.0229, -0.0065, -0.0012,  0.0126,  0.0113, -0.0268,  0.0178, -0.0250,\n",
       "          -0.0278, -0.0239,  0.0212,  0.0265, -0.0157, -0.0144,  0.0060, -0.0083,\n",
       "          -0.0077, -0.0191, -0.0258,  0.0220, -0.0194,  0.0206,  0.0070,  0.0261,\n",
       "           0.0078, -0.0160, -0.0240, -0.0068,  0.0093, -0.0145, -0.0044,  0.0260,\n",
       "           0.0268,  0.0056,  0.0001,  0.0013, -0.0037, -0.0248, -0.0224,  0.0089,\n",
       "           0.0041, -0.0106, -0.0191, -0.0175, -0.0061,  0.0049, -0.0044, -0.0017,\n",
       "          -0.0073,  0.0251,  0.0089, -0.0097,  0.0013,  0.0187, -0.0168,  0.0216,\n",
       "           0.0234, -0.0061, -0.0102, -0.0159, -0.0013,  0.0110,  0.0034, -0.0049,\n",
       "          -0.0174,  0.0133, -0.0241,  0.0101, -0.0047, -0.0220,  0.0255,  0.0167,\n",
       "           0.0055,  0.0275, -0.0012,  0.0222, -0.0207,  0.0184,  0.0241, -0.0250,\n",
       "           0.0078, -0.0052,  0.0065, -0.0136, -0.0087,  0.0045, -0.0078,  0.0110,\n",
       "          -0.0244,  0.0196,  0.0007,  0.0198,  0.0027, -0.0115,  0.0115, -0.0232,\n",
       "          -0.0050,  0.0080,  0.0067,  0.0036,  0.0223,  0.0067,  0.0183, -0.0009,\n",
       "          -0.0173,  0.0231,  0.0114, -0.0152,  0.0211, -0.0199, -0.0248,  0.0017,\n",
       "          -0.0249, -0.0223,  0.0090, -0.0143, -0.0185, -0.0226, -0.0157, -0.0118,\n",
       "          -0.0029,  0.0154,  0.0180, -0.0069,  0.0041, -0.0058,  0.0003,  0.0210,\n",
       "          -0.0036, -0.0057, -0.0127, -0.0041, -0.0234,  0.0227, -0.0226,  0.0134,\n",
       "           0.0099, -0.0271,  0.0238,  0.0064, -0.0062,  0.0200, -0.0042,  0.0119,\n",
       "           0.0060, -0.0151, -0.0228, -0.0152, -0.0221,  0.0115,  0.0103, -0.0254,\n",
       "          -0.0260,  0.0131,  0.0190, -0.0266, -0.0140, -0.0121,  0.0187,  0.0035,\n",
       "           0.0178,  0.0254,  0.0004, -0.0099,  0.0184, -0.0265, -0.0273,  0.0182,\n",
       "           0.0275,  0.0018, -0.0180, -0.0200,  0.0045, -0.0058,  0.0170,  0.0251,\n",
       "          -0.0098, -0.0199,  0.0020,  0.0128,  0.0093,  0.0259,  0.0138,  0.0080,\n",
       "           0.0134, -0.0156,  0.0190,  0.0218, -0.0178, -0.0268, -0.0241, -0.0078,\n",
       "           0.0172, -0.0052,  0.0048, -0.0165,  0.0244, -0.0106,  0.0101,  0.0226,\n",
       "          -0.0185, -0.0272,  0.0243,  0.0006, -0.0159,  0.0236,  0.0098,  0.0078,\n",
       "           0.0255, -0.0058, -0.0041, -0.0251, -0.0023, -0.0071, -0.0051, -0.0018,\n",
       "          -0.0079,  0.0089,  0.0031,  0.0220, -0.0057,  0.0161, -0.0034, -0.0107,\n",
       "           0.0018,  0.0213,  0.0140, -0.0196, -0.0020,  0.0264, -0.0104,  0.0165,\n",
       "          -0.0019,  0.0218,  0.0171, -0.0261,  0.0070,  0.0244,  0.0054,  0.0251,\n",
       "           0.0106,  0.0080, -0.0094,  0.0088, -0.0052, -0.0186,  0.0221, -0.0269,\n",
       "           0.0140, -0.0037,  0.0220,  0.0165, -0.0031,  0.0125,  0.0191, -0.0228,\n",
       "           0.0257,  0.0274, -0.0029,  0.0208,  0.0201,  0.0225, -0.0238,  0.0019,\n",
       "          -0.0123, -0.0003,  0.0216, -0.0179, -0.0114,  0.0079,  0.0156, -0.0120,\n",
       "          -0.0162, -0.0181, -0.0277, -0.0098, -0.0078, -0.0060,  0.0097, -0.0055,\n",
       "           0.0137, -0.0056, -0.0129,  0.0028,  0.0241,  0.0115, -0.0128, -0.0238,\n",
       "          -0.0100, -0.0043, -0.0060,  0.0091,  0.0165,  0.0020, -0.0071, -0.0004,\n",
       "          -0.0007,  0.0009,  0.0240,  0.0224, -0.0009,  0.0104,  0.0075, -0.0224,\n",
       "           0.0016,  0.0035, -0.0257, -0.0026, -0.0132,  0.0072, -0.0225,  0.0149,\n",
       "          -0.0273,  0.0243,  0.0048, -0.0168,  0.0072, -0.0114,  0.0052, -0.0220,\n",
       "           0.0088,  0.0182,  0.0164,  0.0024,  0.0240, -0.0206, -0.0104, -0.0133,\n",
       "           0.0261, -0.0262, -0.0183, -0.0112,  0.0035, -0.0151,  0.0077,  0.0174],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0189,  0.0082, -0.0046,  ...,  0.0373,  0.0008, -0.0192],\n",
       "          [-0.0355,  0.0053,  0.0182,  ..., -0.0120, -0.0082,  0.0062],\n",
       "          [ 0.0095, -0.0218,  0.0165,  ..., -0.0185, -0.0149, -0.0162],\n",
       "          ...,\n",
       "          [ 0.0271, -0.0011,  0.0008,  ..., -0.0174,  0.0284,  0.0264],\n",
       "          [ 0.0044, -0.0041,  0.0382,  ..., -0.0357,  0.0020, -0.0137],\n",
       "          [-0.0230,  0.0330,  0.0216,  ...,  0.0349,  0.0028, -0.0111]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0024,  0.0154,  0.0207, -0.0281,  0.0240, -0.0012,  0.0274,  0.0160],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0136,  0.0016, -0.0060,  ...,  0.0005, -0.0098, -0.0203],\n",
       "          [ 0.0162, -0.0128, -0.0069,  ..., -0.0245,  0.0221, -0.0189],\n",
       "          [-0.0118,  0.0221, -0.0076,  ..., -0.0080, -0.0164,  0.0265],\n",
       "          ...,\n",
       "          [ 0.0309, -0.0019, -0.0092,  ..., -0.0089, -0.0237,  0.0109],\n",
       "          [ 0.0219, -0.0065,  0.0243,  ...,  0.0081, -0.0028,  0.0414],\n",
       "          [ 0.0014,  0.0069,  0.0104,  ...,  0.0030,  0.0304,  0.0122]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0205,  0.0084, -0.0229,  ..., -0.0316,  0.0106,  0.0097],\n",
       "          [ 0.0105, -0.0125,  0.0333,  ...,  0.0181,  0.0004,  0.0019],\n",
       "          [-0.0129,  0.0064, -0.0014,  ..., -0.0035,  0.0043,  0.0087],\n",
       "          ...,\n",
       "          [ 0.0050,  0.0157, -0.0151,  ...,  0.0337, -0.0077,  0.0084],\n",
       "          [ 0.0264,  0.0018,  0.0224,  ..., -0.0140, -0.0063,  0.0115],\n",
       "          [-0.0022,  0.0185, -0.0093,  ...,  0.0031,  0.0100, -0.0081]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0216,  0.0200, -0.0155,  ...,  0.0146,  0.0087,  0.0254],\n",
       "          [-0.0212, -0.0158,  0.0034,  ...,  0.0261, -0.0194, -0.0124],\n",
       "          [-0.0032, -0.0043, -0.0318,  ..., -0.0122,  0.0361, -0.0093],\n",
       "          ...,\n",
       "          [-0.0034,  0.0208,  0.0013,  ..., -0.0047, -0.0173, -0.0226],\n",
       "          [-0.0124, -0.0024, -0.0021,  ...,  0.0067, -0.0232,  0.0120],\n",
       "          [-0.0127, -0.0006,  0.0081,  ...,  0.0158, -0.0208, -0.0006]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0067, -0.0300, -0.0084,  ...,  0.0100, -0.0019, -0.0179],\n",
       "          [ 0.0187, -0.0189, -0.0191,  ..., -0.0204, -0.0092, -0.0043],\n",
       "          [-0.0006, -0.0063, -0.0067,  ...,  0.0037, -0.0076,  0.0095],\n",
       "          ...,\n",
       "          [ 0.0047,  0.0001,  0.0033,  ..., -0.0115, -0.0372,  0.0135],\n",
       "          [-0.0008,  0.0254, -0.0219,  ...,  0.0078, -0.0233,  0.0255],\n",
       "          [ 0.0036, -0.0134, -0.0087,  ..., -0.0097,  0.0050, -0.0084]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0243,  0.0015, -0.0258,  ...,  0.0088, -0.0042,  0.0078],\n",
       "          [-0.0077,  0.0231, -0.0019,  ...,  0.0201, -0.0007, -0.0047],\n",
       "          [ 0.0092,  0.0131,  0.0137,  ..., -0.0243,  0.0104, -0.0080],\n",
       "          ...,\n",
       "          [ 0.0019,  0.0194, -0.0114,  ..., -0.0032, -0.0027,  0.0130],\n",
       "          [-0.0202,  0.0125,  0.0021,  ...,  0.0011, -0.0227,  0.0130],\n",
       "          [ 0.0227, -0.0008,  0.0237,  ..., -0.0225,  0.0207, -0.0163]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-1.6399e-02,  1.1913e-02, -2.7269e-03, -2.7653e-02, -1.6921e-02,\n",
       "          -3.2753e-03, -2.5062e-02, -1.2117e-02,  2.0174e-02, -1.8429e-02,\n",
       "          -1.7576e-02, -7.1563e-03, -3.1289e-03,  1.5807e-02,  3.6996e-03,\n",
       "          -9.8505e-03,  3.0602e-03,  1.3355e-02, -1.7031e-02, -1.2516e-02,\n",
       "           5.9225e-03,  1.8781e-02, -3.9526e-03,  2.4692e-02, -1.8781e-02,\n",
       "           1.5079e-02, -1.0448e-02,  1.8204e-03, -1.6066e-02, -2.0968e-02,\n",
       "           2.6519e-02, -5.5239e-03, -1.8413e-02,  3.1929e-04,  2.5579e-02,\n",
       "          -1.7683e-02, -1.3007e-03, -1.8584e-02, -4.3718e-03, -2.2538e-02,\n",
       "           2.3580e-02,  1.7426e-02,  7.0522e-03,  1.1457e-02, -1.7684e-02,\n",
       "          -2.3545e-02,  1.7538e-02, -2.7489e-02, -5.0580e-03, -2.7568e-02,\n",
       "           2.4807e-02, -2.2162e-02,  1.7230e-02, -5.2597e-03, -4.4422e-03,\n",
       "           2.6056e-02,  2.4677e-02, -2.5407e-02,  7.7154e-03, -1.0127e-02,\n",
       "           2.5845e-02, -1.7792e-02, -1.9655e-02,  1.3919e-02,  2.1606e-02,\n",
       "           6.1647e-03, -1.4066e-02, -1.0742e-02,  2.4037e-02,  2.2339e-02,\n",
       "          -7.3991e-03, -1.1424e-03,  8.2014e-03, -1.6035e-02,  1.5716e-03,\n",
       "           2.1297e-02, -2.1211e-02, -1.3907e-02, -1.5287e-02, -7.8311e-03,\n",
       "          -3.0335e-03,  7.0026e-03, -1.5737e-02,  2.6192e-02,  9.0063e-04,\n",
       "          -2.0442e-02,  7.4468e-03, -2.7406e-02, -1.9308e-02,  2.6565e-02,\n",
       "           1.5164e-02, -7.2480e-03,  2.4833e-02, -2.6448e-02, -1.5686e-02,\n",
       "          -1.8433e-02, -5.8956e-03, -1.3898e-02,  2.2516e-02, -2.7379e-02,\n",
       "           2.6914e-02, -5.9318e-03,  1.1337e-03,  7.4055e-03, -6.1316e-03,\n",
       "          -5.2713e-03,  1.8459e-02,  2.4420e-02,  1.6637e-02, -2.3785e-02,\n",
       "          -1.3113e-02,  1.5720e-02,  1.8766e-02, -2.2301e-02, -1.8364e-02,\n",
       "          -7.3269e-03, -2.3607e-02, -1.7976e-02,  4.5651e-03,  9.9252e-03,\n",
       "          -2.2008e-02,  2.0538e-02,  2.2452e-02, -8.2740e-03,  2.0378e-03,\n",
       "           2.2702e-02,  4.1325e-04,  2.5034e-02,  9.3081e-03, -1.1744e-02,\n",
       "          -2.4093e-02,  4.6897e-03, -8.2035e-03,  1.1161e-02,  2.6839e-02,\n",
       "           1.8784e-02, -1.0032e-04, -2.0233e-02,  8.2525e-03, -9.8300e-03,\n",
       "          -1.2260e-02,  7.8513e-03,  1.9379e-02,  2.5996e-02,  1.9128e-02,\n",
       "           3.8700e-03, -2.6317e-03, -1.6343e-02,  1.4761e-03, -7.1004e-03,\n",
       "           1.4230e-02, -1.1246e-02,  7.7609e-03,  2.1024e-02, -1.4070e-02,\n",
       "          -2.2074e-02, -4.2008e-03,  5.4778e-04, -8.6893e-03,  5.2415e-03,\n",
       "           8.9468e-03, -1.3788e-02, -1.9100e-02,  1.9610e-02, -5.5549e-04,\n",
       "          -1.0282e-02,  1.6860e-02,  8.9952e-03,  1.7917e-02,  2.5386e-02,\n",
       "          -4.9627e-03, -1.9618e-02, -2.3500e-02,  2.4483e-02,  6.3628e-03,\n",
       "          -1.1236e-03, -1.3136e-03,  1.9348e-02,  2.3110e-02,  8.3030e-03,\n",
       "           1.0056e-02, -1.5285e-02,  9.1770e-03, -2.6611e-02, -7.1960e-03,\n",
       "           1.2055e-03,  1.6951e-02, -2.3627e-02, -2.2661e-02, -1.1948e-02,\n",
       "           1.7492e-02,  2.4770e-02, -5.8389e-03,  7.3810e-03,  2.1685e-02,\n",
       "           2.5818e-03,  2.6160e-02,  2.0027e-02,  1.9628e-02, -1.2977e-03,\n",
       "           2.7141e-03, -5.2149e-03,  7.7122e-03,  1.3461e-02, -2.2450e-02,\n",
       "          -1.5704e-02, -7.2858e-03, -5.7056e-03,  1.0975e-02, -1.9629e-02,\n",
       "          -1.7236e-02,  1.6368e-02, -1.5030e-02, -2.4489e-02, -9.4239e-03,\n",
       "          -1.1202e-02, -3.4562e-04, -1.9309e-02,  4.8933e-04,  2.3706e-02,\n",
       "           1.0283e-02, -2.2118e-02, -2.5556e-02, -6.6329e-03, -9.1100e-04,\n",
       "          -1.1149e-02,  5.3723e-03, -1.2887e-02, -7.3570e-03,  7.7697e-03,\n",
       "           6.6549e-03, -2.2532e-02, -2.7566e-02, -2.3970e-02, -2.8029e-03,\n",
       "          -2.3073e-03,  1.6068e-02,  1.5939e-02,  1.4006e-02,  2.2479e-02,\n",
       "          -8.0784e-03,  1.0124e-02, -8.1478e-03,  2.5522e-02,  7.3074e-03,\n",
       "           2.6816e-03, -1.7963e-02,  2.3421e-02,  7.9932e-03, -2.6331e-02,\n",
       "           4.9353e-03, -5.1623e-03, -6.5791e-03, -2.3428e-03, -1.7307e-02,\n",
       "           2.7582e-02,  2.6039e-02,  2.5945e-02,  8.1565e-03,  5.5846e-03,\n",
       "           1.6010e-02, -1.1659e-05, -1.6039e-02,  1.6343e-02, -1.3480e-02,\n",
       "           2.2716e-02,  2.4143e-02,  5.2073e-03, -2.5595e-02, -2.2423e-02,\n",
       "          -1.4424e-02,  1.1060e-02,  2.5745e-02, -1.7266e-02, -7.7744e-03,\n",
       "          -8.5452e-03, -2.1905e-02,  2.3910e-02,  8.1397e-03,  4.2528e-03,\n",
       "          -1.5182e-02,  2.4261e-02,  7.7596e-03,  1.7121e-02,  2.6459e-02,\n",
       "           1.0491e-02, -1.3334e-02, -3.4034e-03,  2.5398e-02, -2.3381e-02,\n",
       "           6.0193e-03, -2.0722e-02,  5.9264e-04, -2.6045e-02,  5.7306e-03,\n",
       "           2.1972e-02, -2.2667e-02, -7.5271e-03,  4.7142e-03,  2.6705e-02,\n",
       "           1.2017e-03,  1.9544e-02, -1.0116e-02,  7.6246e-03, -2.5768e-02,\n",
       "           1.2494e-02, -7.3129e-03, -1.3804e-02,  1.2986e-02,  1.0286e-02,\n",
       "          -4.6523e-03,  1.0946e-02,  9.0503e-04, -2.6022e-02,  1.4975e-02,\n",
       "           1.9535e-02, -2.4013e-02, -1.8054e-02,  2.5296e-02,  1.4763e-02,\n",
       "          -5.5845e-03,  1.0262e-02,  4.8061e-03, -9.6526e-03, -1.9415e-02,\n",
       "          -2.3911e-02, -1.3035e-02,  1.7587e-02,  6.3237e-03, -9.8353e-03,\n",
       "           1.2047e-03, -3.0664e-03,  2.0329e-02,  1.3134e-03, -1.8747e-02,\n",
       "          -2.7744e-03,  2.3215e-03,  1.0693e-02, -1.9720e-02, -3.3216e-03,\n",
       "           1.6671e-02, -1.3572e-02,  9.8380e-03, -2.0294e-02, -1.9983e-02,\n",
       "          -3.7357e-03, -6.8089e-03,  1.3367e-02, -2.7807e-02,  1.9888e-02,\n",
       "           5.2188e-03, -9.1477e-03,  2.4152e-02, -2.6528e-02, -1.1054e-02,\n",
       "           1.9587e-02, -3.4399e-03,  2.5213e-02,  1.4168e-03,  2.6348e-02,\n",
       "          -8.9236e-03,  1.4425e-02,  9.1153e-03, -1.0815e-02, -1.1684e-02,\n",
       "           1.6441e-03,  1.5450e-02, -2.5799e-02,  2.1378e-02, -1.1931e-02,\n",
       "          -2.1420e-02, -2.2780e-02,  2.0964e-02, -2.4730e-02,  5.8138e-03,\n",
       "          -1.9745e-02,  1.9227e-02,  5.8198e-03,  6.2058e-03,  1.0151e-02,\n",
       "          -1.0263e-02, -8.3439e-03,  2.5386e-02,  9.5678e-03, -1.1483e-02,\n",
       "           4.6041e-03,  7.2940e-03,  1.7676e-02,  2.1608e-03,  3.7631e-03,\n",
       "          -2.5692e-02,  8.1936e-03, -3.5912e-03, -2.5495e-02, -2.3236e-02,\n",
       "           1.5743e-03,  2.0490e-02, -7.3408e-03, -1.8130e-02, -2.4687e-02,\n",
       "          -1.0101e-02,  2.7581e-02,  2.6557e-03, -1.2706e-02,  2.3292e-02,\n",
       "           7.6896e-03, -2.4599e-02, -5.9297e-03, -2.4501e-02, -9.3121e-03,\n",
       "           1.9531e-02, -2.4915e-02,  1.2759e-02, -1.6245e-02,  2.7487e-02,\n",
       "           1.7718e-02,  1.4242e-02, -2.7652e-02, -2.7928e-02, -2.4015e-02,\n",
       "           9.4338e-03, -8.4800e-03, -6.5675e-03,  4.9627e-05,  2.5106e-02,\n",
       "           1.7323e-02,  9.2864e-03,  2.3486e-02,  4.0591e-04,  9.8638e-03,\n",
       "          -8.7053e-03,  1.0735e-02,  1.7186e-02,  1.3730e-02, -1.0173e-03,\n",
       "          -5.0778e-03,  8.6426e-03,  1.0603e-02,  2.3199e-02,  2.0705e-02,\n",
       "           5.2008e-03,  6.0966e-03,  5.1868e-03, -3.9029e-03,  9.8149e-03,\n",
       "           1.3178e-03,  1.7968e-02,  2.4384e-02, -1.2692e-02, -2.6361e-02,\n",
       "           1.3970e-02,  1.7920e-02,  1.5616e-02, -9.8851e-03, -1.1107e-02,\n",
       "          -1.3226e-02,  8.6265e-03,  8.9800e-03, -7.9883e-03,  1.3973e-02,\n",
       "          -2.0775e-02,  9.5984e-04,  2.5157e-02, -1.2125e-02,  1.6171e-02,\n",
       "          -2.1082e-02, -5.9175e-03,  5.3422e-04,  1.4977e-02,  2.3422e-02,\n",
       "          -1.0580e-02,  1.0728e-02,  2.7131e-02, -2.7736e-02, -1.3324e-02,\n",
       "           2.3827e-02,  7.7588e-03, -1.6503e-02,  2.6594e-02, -2.4881e-02,\n",
       "           1.6717e-02,  9.7474e-03, -1.6097e-02,  7.7231e-03,  2.1273e-03,\n",
       "           1.9513e-02,  1.9226e-02, -1.8080e-04,  1.4881e-02, -2.3911e-02,\n",
       "          -1.8516e-02, -1.6809e-02, -4.0606e-03, -8.8525e-03,  6.5793e-03,\n",
       "          -8.7834e-03, -1.0516e-02, -1.1502e-02, -1.5852e-02, -1.0270e-02,\n",
       "          -1.6917e-02, -2.1289e-02, -1.2187e-02, -4.1932e-03, -2.3133e-02,\n",
       "           1.5031e-02,  2.5000e-03,  9.3214e-03, -1.4223e-02, -1.9555e-02,\n",
       "          -7.6157e-03, -3.7393e-03,  1.2609e-02,  2.4267e-02,  2.0156e-02,\n",
       "           6.3663e-03, -1.2320e-02,  9.9471e-03,  2.2957e-02,  2.5624e-03,\n",
       "          -2.3736e-02,  1.9943e-02, -1.8257e-02,  1.5992e-02,  5.7574e-03,\n",
       "          -9.6133e-03,  2.2930e-02,  2.5915e-02, -1.6015e-02, -1.8348e-02,\n",
       "           2.2240e-02,  1.0148e-02,  2.6107e-02,  1.5273e-02,  9.8512e-04,\n",
       "          -1.1417e-02, -1.5474e-02, -3.1561e-03, -2.2636e-02,  1.1897e-02,\n",
       "          -1.2251e-02, -2.1086e-03, -2.5356e-02,  2.4082e-02,  2.4437e-02,\n",
       "          -8.6923e-03, -1.1612e-02, -1.5321e-02,  1.3512e-02,  1.7875e-02,\n",
       "          -2.7860e-02, -1.4694e-02,  7.2496e-03,  1.5102e-02,  2.3693e-03,\n",
       "           9.0965e-03, -1.5290e-03,  6.4615e-03,  2.1576e-02,  1.3324e-02,\n",
       "           8.7784e-03,  1.9157e-02,  2.2870e-03,  1.2313e-02,  1.2525e-02,\n",
       "           2.9222e-03,  1.5404e-02, -1.5859e-02,  1.1027e-02,  2.8822e-03,\n",
       "          -2.3716e-02, -2.2908e-02,  1.3557e-02, -2.3828e-02,  1.7286e-02,\n",
       "          -2.0522e-02, -3.1042e-03,  2.0429e-02, -1.1723e-02, -2.7362e-02,\n",
       "          -2.0121e-02, -2.5430e-02,  2.5103e-02,  2.6390e-02,  6.0741e-03,\n",
       "          -4.8679e-03, -1.7486e-02, -2.1596e-02, -5.4782e-03,  1.0343e-02,\n",
       "           7.4146e-03,  6.1953e-03,  6.9676e-03, -2.3786e-02,  3.5909e-03,\n",
       "          -1.4493e-02, -6.6210e-03, -3.9694e-04,  1.4092e-02, -1.2702e-02,\n",
       "           1.4644e-02,  1.3062e-03,  2.0097e-02,  2.1737e-02, -3.2509e-03,\n",
       "          -1.1816e-02, -1.4794e-02,  1.0272e-02,  2.6937e-03, -9.5473e-03,\n",
       "          -5.1659e-03,  2.6566e-02, -2.4665e-02,  2.1689e-02, -1.4133e-02,\n",
       "          -4.6888e-03,  1.0021e-02, -1.8206e-02,  2.5668e-02,  2.4818e-02,\n",
       "           7.9142e-03,  1.5877e-02,  2.2339e-02,  4.3215e-03, -1.8281e-02,\n",
       "          -3.7315e-03, -2.5049e-02,  1.4147e-03,  6.9360e-03,  1.6867e-02,\n",
       "          -1.4177e-02, -6.5757e-03, -2.4854e-02, -2.4869e-03, -2.5325e-02,\n",
       "          -1.1201e-02,  2.2509e-02, -2.1718e-02, -2.7594e-02,  4.2815e-03],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-1.0774e-02,  2.0526e-02,  6.2838e-03,  ..., -2.9361e-02,\n",
       "            3.3841e-02,  3.2721e-02],\n",
       "          [ 3.0505e-03, -3.3485e-02, -1.4942e-02,  ...,  2.2162e-02,\n",
       "            1.5777e-02,  1.1797e-02],\n",
       "          [-3.9419e-02,  3.5123e-02,  1.2688e-02,  ..., -1.5978e-02,\n",
       "            2.7077e-02,  2.2994e-02],\n",
       "          ...,\n",
       "          [ 3.3302e-02, -4.9450e-03, -3.7970e-02,  ..., -2.4573e-02,\n",
       "           -7.1959e-05,  4.8582e-03],\n",
       "          [ 3.1548e-02, -2.5772e-02,  2.5946e-02,  ...,  1.2066e-02,\n",
       "            1.1253e-02, -1.3805e-02],\n",
       "          [ 2.2286e-02,  1.6670e-02,  2.4012e-02,  ..., -2.0263e-02,\n",
       "            1.3427e-02,  4.0591e-03]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0071,  0.0217,  0.0059, -0.0024,  0.0125, -0.0178,  0.0181, -0.0368],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-2.2766e-03,  5.8112e-05,  7.6026e-03,  ..., -1.7812e-02,\n",
       "            2.4863e-02, -1.5102e-02],\n",
       "          [-3.1153e-03, -2.8265e-02, -1.6842e-02,  ...,  4.1569e-03,\n",
       "            1.3114e-02, -1.3892e-02],\n",
       "          [ 2.2794e-03,  2.5302e-02,  5.5276e-03,  ...,  4.4934e-03,\n",
       "            3.0780e-03,  1.4729e-02],\n",
       "          ...,\n",
       "          [-6.6468e-03,  1.5089e-02,  1.8405e-02,  ..., -5.4808e-03,\n",
       "            6.2906e-03, -1.2011e-02],\n",
       "          [ 8.9020e-03,  7.1728e-03, -7.5860e-03,  ..., -9.3744e-03,\n",
       "            1.2563e-02, -8.5497e-04],\n",
       "          [-3.5103e-03,  8.5989e-03,  2.6509e-02,  ..., -1.0944e-02,\n",
       "           -1.9733e-02, -5.9586e-03]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0024, -0.0109,  0.0050,  ...,  0.0272,  0.0012,  0.0295],\n",
       "          [-0.0016,  0.0201,  0.0041,  ..., -0.0003, -0.0054, -0.0299],\n",
       "          [ 0.0093,  0.0235, -0.0154,  ...,  0.0039, -0.0006, -0.0283],\n",
       "          ...,\n",
       "          [ 0.0273,  0.0120, -0.0022,  ..., -0.0201,  0.0113, -0.0026],\n",
       "          [-0.0168, -0.0006, -0.0007,  ...,  0.0028,  0.0370,  0.0089],\n",
       "          [ 0.0104, -0.0215, -0.0186,  ...,  0.0093,  0.0021,  0.0104]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0006, -0.0036,  0.0068,  ...,  0.0020, -0.0010, -0.0041],\n",
       "          [-0.0063,  0.0195, -0.0040,  ..., -0.0004, -0.0094, -0.0069],\n",
       "          [-0.0332, -0.0172,  0.0004,  ..., -0.0097,  0.0186, -0.0072],\n",
       "          ...,\n",
       "          [ 0.0028, -0.0029, -0.0306,  ..., -0.0111, -0.0035, -0.0236],\n",
       "          [-0.0129,  0.0051, -0.0343,  ...,  0.0157, -0.0033, -0.0121],\n",
       "          [ 0.0137,  0.0015,  0.0126,  ..., -0.0021, -0.0186, -0.0143]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 5.6021e-03,  1.9962e-02,  5.9987e-03,  ..., -2.8443e-02,\n",
       "            7.3587e-03, -6.4518e-03],\n",
       "          [-2.6672e-04,  3.5699e-03, -9.9877e-04,  ...,  2.0207e-02,\n",
       "           -5.1576e-03, -1.9270e-02],\n",
       "          [-1.4763e-02, -1.9404e-03, -4.3768e-03,  ...,  2.9797e-04,\n",
       "            4.6088e-03,  6.2766e-03],\n",
       "          ...,\n",
       "          [-1.6483e-02,  2.5905e-02,  2.8375e-02,  ..., -4.0478e-03,\n",
       "           -8.4251e-03, -2.7831e-03],\n",
       "          [ 1.2626e-02,  7.0304e-03,  2.0448e-02,  ..., -8.2796e-03,\n",
       "           -4.8655e-03, -9.5646e-03],\n",
       "          [ 3.7143e-03, -3.4960e-03,  1.9266e-02,  ..., -1.6238e-05,\n",
       "            1.9750e-02, -1.8141e-02]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0020, -0.0165, -0.0104,  ...,  0.0088,  0.0227,  0.0070],\n",
       "          [ 0.0116, -0.0211, -0.0122,  ...,  0.0088,  0.0247, -0.0108],\n",
       "          [-0.0085, -0.0097, -0.0155,  ...,  0.0005, -0.0253,  0.0209],\n",
       "          ...,\n",
       "          [ 0.0109,  0.0103, -0.0168,  ...,  0.0123,  0.0072,  0.0141],\n",
       "          [-0.0026,  0.0254, -0.0066,  ...,  0.0262,  0.0223, -0.0008],\n",
       "          [-0.0138, -0.0032,  0.0279,  ..., -0.0014, -0.0089, -0.0154]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-1.2456e-02,  2.1819e-02,  5.9526e-03,  1.3836e-02, -3.9333e-03,\n",
       "           7.5705e-03, -1.3484e-02,  1.0331e-02, -3.1520e-03, -2.6787e-02,\n",
       "          -2.6202e-03, -1.9403e-02, -2.1934e-02, -2.5178e-02,  2.2012e-02,\n",
       "          -2.4339e-02, -2.5041e-02, -2.1323e-02,  3.5654e-03,  1.8318e-02,\n",
       "          -1.8387e-02,  2.3501e-02, -1.0863e-02, -2.3850e-02, -1.4748e-02,\n",
       "           7.2928e-03,  2.5721e-02,  1.8893e-02, -1.3444e-02, -7.7500e-03,\n",
       "          -1.8921e-02, -5.6041e-03, -5.4808e-03, -2.5422e-02, -1.7515e-02,\n",
       "           2.4693e-02,  2.5371e-03, -2.1721e-02,  2.6202e-02, -3.0501e-03,\n",
       "           5.5580e-03, -1.9710e-03,  2.0767e-02,  2.2263e-02,  1.8312e-02,\n",
       "           1.9943e-02, -1.1347e-02, -2.2602e-02,  1.3898e-02,  2.2791e-02,\n",
       "           2.0793e-02, -2.2399e-02,  1.6497e-02,  1.5026e-02,  6.2876e-03,\n",
       "          -9.7818e-03, -2.0213e-02,  1.9552e-03, -5.1523e-05, -2.7904e-02,\n",
       "           1.5979e-02,  1.1064e-02, -2.4970e-02,  8.6316e-03,  1.4586e-02,\n",
       "           3.1147e-03, -2.4486e-02, -4.6687e-03, -2.0717e-02, -2.7339e-02,\n",
       "          -1.2756e-02, -2.5991e-02,  1.8738e-02, -1.1338e-02,  2.3452e-02,\n",
       "           1.5022e-02, -1.5772e-02, -1.8608e-02,  5.6143e-03,  1.2583e-02,\n",
       "           2.2748e-02,  2.1830e-02,  2.4256e-02,  4.0281e-03, -3.8369e-03,\n",
       "          -1.9736e-03,  1.7463e-02, -1.4281e-02, -1.2202e-02, -1.7374e-02,\n",
       "           9.9801e-03, -2.7799e-02, -6.8375e-04, -2.4332e-02, -2.9623e-03,\n",
       "           1.3340e-02, -2.1600e-02,  1.1232e-03,  1.8755e-02,  1.4420e-02,\n",
       "           9.4418e-03,  7.7890e-03, -1.8150e-02, -1.5803e-02,  4.4741e-03,\n",
       "           2.7873e-02, -1.4014e-02, -4.3232e-03,  6.7722e-03, -1.7063e-02,\n",
       "          -2.4275e-02,  1.2868e-02, -2.1631e-03, -1.1073e-02, -1.6188e-02,\n",
       "           1.2768e-02,  1.7988e-02, -1.7188e-02,  2.3351e-02, -1.5090e-02,\n",
       "           2.1434e-02,  4.6551e-04, -1.0785e-02, -1.9403e-02, -1.2434e-02,\n",
       "           2.0340e-02, -6.2357e-03,  1.5480e-02, -2.5691e-02,  2.1621e-03,\n",
       "          -4.4052e-03,  4.8489e-03, -4.2240e-05, -8.4614e-03, -5.8371e-03,\n",
       "          -1.0554e-02,  1.3500e-02,  1.6028e-02, -9.7511e-03,  4.1988e-03,\n",
       "          -1.0787e-02,  1.8114e-02,  1.9356e-02, -1.6575e-02,  2.0928e-02,\n",
       "           2.6644e-03, -6.7664e-03,  1.3337e-02, -1.8501e-02, -2.0037e-02,\n",
       "           1.6018e-02, -2.7713e-04,  7.3132e-03, -1.3373e-02,  2.9451e-03,\n",
       "          -2.9372e-03, -1.0866e-02,  4.5610e-03, -9.6246e-03, -2.3871e-02,\n",
       "          -2.7433e-02, -5.2077e-03, -9.2759e-03,  1.1169e-02,  3.7520e-03,\n",
       "           1.1634e-02, -5.7337e-03, -2.1580e-03,  3.9904e-03,  1.6236e-02,\n",
       "           2.7380e-02, -2.5113e-02,  1.0558e-02,  2.2486e-02, -2.6952e-02,\n",
       "           1.4527e-02,  1.4980e-02,  6.4347e-03,  3.4747e-03, -5.1725e-03,\n",
       "          -1.8597e-02,  1.0364e-03, -2.7309e-02,  2.6040e-02,  2.5576e-02,\n",
       "          -1.2645e-02, -1.4351e-02, -1.7868e-02,  8.6611e-03, -8.3206e-04,\n",
       "           2.1923e-03, -2.0892e-02,  4.5514e-03, -1.7072e-02,  2.4661e-02,\n",
       "           2.3052e-02, -2.4660e-02, -1.5120e-03,  1.0797e-02, -1.4221e-02,\n",
       "           9.7692e-04, -4.8026e-03, -1.2067e-02,  9.3940e-03, -1.3940e-04,\n",
       "           3.4395e-03, -7.4937e-03,  2.2997e-02, -2.1206e-03,  1.9616e-02,\n",
       "           8.2847e-03, -2.4424e-02,  1.9044e-02, -1.4473e-02, -1.2633e-04,\n",
       "          -1.2327e-02,  1.6238e-02, -2.4712e-02,  2.9070e-03,  2.0876e-02,\n",
       "           1.5740e-02,  9.9288e-03,  1.7645e-02,  2.2075e-02, -2.6523e-02,\n",
       "          -2.3836e-02, -1.6894e-02, -2.1221e-02,  1.2285e-02,  7.8213e-03,\n",
       "           4.7610e-03,  1.6320e-02, -3.2433e-03, -1.4133e-02, -1.2656e-02,\n",
       "           9.1655e-04,  3.9024e-03, -1.2906e-02, -2.1518e-02,  4.7763e-03,\n",
       "          -6.3609e-03, -1.3074e-02,  1.3900e-02, -2.3939e-02,  1.7023e-02,\n",
       "           2.3088e-02,  1.7302e-02, -4.5465e-03, -2.3460e-02,  3.8889e-03,\n",
       "           3.8721e-04,  2.9857e-03,  1.5125e-02, -2.2917e-02,  2.4165e-02,\n",
       "           1.5618e-02,  2.0661e-02,  1.3938e-02, -2.3352e-02, -1.8432e-03,\n",
       "           1.1427e-02, -2.3420e-03, -4.9062e-03,  1.3367e-02,  1.8598e-02,\n",
       "          -1.2610e-03, -1.7709e-02,  1.6090e-02,  7.1127e-03, -2.6068e-02,\n",
       "           6.9008e-03, -1.8985e-02,  1.3975e-02,  1.5995e-02,  1.4238e-02,\n",
       "          -6.5402e-03,  1.8914e-02, -2.0985e-03,  2.7265e-02, -1.8225e-02,\n",
       "          -1.3450e-02, -7.8704e-03,  1.4658e-02, -1.6346e-02, -8.5840e-03,\n",
       "           1.6400e-02,  1.0971e-02,  1.6876e-02, -1.6295e-02, -1.0784e-03,\n",
       "           1.7447e-02, -2.0845e-02,  2.4365e-02, -1.6501e-02, -2.6956e-03,\n",
       "           2.2114e-02, -1.9946e-02, -3.0478e-03,  2.7026e-03,  3.4338e-03,\n",
       "          -1.9660e-02, -2.5214e-02, -9.0276e-03, -5.4028e-03, -1.4761e-02,\n",
       "          -2.5005e-02, -6.9062e-05,  2.3646e-02, -1.0671e-02,  1.9658e-02,\n",
       "           1.5614e-02, -1.6869e-02, -1.9357e-02,  3.3436e-03,  1.9816e-02,\n",
       "           1.2725e-02, -2.3774e-02, -2.7555e-02, -6.9901e-03,  7.7985e-03,\n",
       "          -2.2783e-02,  9.5218e-03, -2.3153e-02,  2.0178e-02,  4.6886e-03,\n",
       "           1.7538e-02,  1.2516e-02,  5.3866e-03,  1.0111e-02, -2.2783e-02,\n",
       "           1.3751e-02, -2.0554e-02, -3.8654e-03,  2.2276e-02,  1.5411e-02,\n",
       "          -2.5935e-02, -1.3488e-02, -5.8117e-03,  2.0815e-02, -5.3905e-03,\n",
       "          -3.6687e-03, -2.9827e-03, -2.9867e-04,  1.5625e-02,  2.1125e-02,\n",
       "           5.4186e-04, -2.0371e-03, -2.2773e-02,  2.1681e-02,  1.6131e-02,\n",
       "          -3.7189e-03,  2.7296e-02, -2.4640e-02, -1.8766e-02,  1.8750e-02,\n",
       "           2.4344e-02, -1.0879e-03, -4.8680e-03,  2.7343e-02, -9.4522e-03,\n",
       "           4.3392e-03,  1.7115e-02,  2.6169e-02,  2.5913e-02,  2.6880e-02,\n",
       "          -2.4218e-02, -2.1969e-02,  2.2197e-02, -1.9495e-02, -7.9808e-03,\n",
       "          -8.2673e-03, -1.9308e-02, -1.7425e-02, -1.8047e-03, -7.0981e-03,\n",
       "          -8.1710e-03,  1.2662e-02, -1.6037e-02, -1.1350e-02,  2.1117e-02,\n",
       "          -1.5577e-02, -7.5187e-03,  4.4928e-03, -9.9843e-03, -2.6131e-02,\n",
       "          -8.9561e-03,  2.1193e-02, -1.4744e-02,  1.1458e-02,  5.3752e-04,\n",
       "           2.5728e-02,  1.1624e-02,  6.4686e-03, -6.6099e-03, -1.0456e-02,\n",
       "          -1.1837e-02,  1.2309e-02,  1.5788e-02,  2.6597e-03,  2.7757e-02,\n",
       "           6.3691e-03,  1.4194e-02,  9.0257e-03,  1.5846e-02, -7.7127e-03,\n",
       "           1.9575e-02, -2.8179e-03, -1.3374e-02,  1.6747e-03,  1.3308e-02,\n",
       "           5.9978e-03,  1.2834e-02, -1.0478e-02,  1.4396e-02,  1.6887e-04,\n",
       "           4.3934e-03,  1.5127e-05, -1.3015e-03,  8.8801e-03, -1.5785e-02,\n",
       "           1.3572e-02, -1.6867e-02, -1.1559e-02,  1.0947e-02, -2.1616e-02,\n",
       "          -1.7800e-03,  2.2532e-02,  1.3029e-02,  2.1777e-02, -1.7743e-02,\n",
       "          -2.2530e-02, -3.9779e-03, -5.8037e-05,  2.5080e-02, -2.6236e-02,\n",
       "          -9.6205e-03,  1.6481e-03,  2.2223e-02,  2.3242e-02, -1.6045e-02,\n",
       "          -1.9405e-02,  2.2366e-02,  1.8814e-02,  1.0414e-02, -1.7071e-02,\n",
       "           5.6390e-03,  1.0617e-02,  5.4926e-03, -4.6121e-03,  1.4653e-02,\n",
       "           2.5741e-02,  8.4848e-03, -2.0206e-02,  1.7249e-02, -1.3219e-02,\n",
       "          -4.7945e-03,  1.9783e-02, -1.3872e-02,  3.5176e-03,  7.1960e-03,\n",
       "           7.9879e-03, -1.2060e-02,  7.1297e-03, -3.2388e-03, -6.0094e-03,\n",
       "           1.9749e-02, -1.4521e-02, -7.9404e-03, -8.4678e-03, -2.5732e-02,\n",
       "          -9.4446e-03,  1.6720e-02,  2.2801e-02, -2.1794e-03, -1.1409e-02,\n",
       "          -1.8565e-03,  2.1343e-02,  1.1147e-02, -1.1730e-02,  9.5234e-03,\n",
       "          -1.6732e-02, -2.6493e-02,  1.2146e-02,  2.5933e-02, -1.7144e-02,\n",
       "           8.0751e-03, -1.1288e-02,  9.2034e-03,  2.5681e-02,  1.7489e-02,\n",
       "          -2.5505e-02,  9.0800e-03, -2.4143e-02, -1.8494e-02, -2.3926e-02,\n",
       "           1.9768e-02,  1.6406e-02, -5.9968e-03, -2.3478e-02, -1.4495e-02,\n",
       "          -1.7366e-02, -7.2641e-03, -1.7451e-02, -4.0883e-03, -4.0650e-03,\n",
       "          -2.1973e-02, -4.0872e-03,  2.7908e-03, -1.6934e-02,  7.5602e-03,\n",
       "           2.0290e-02,  9.0813e-03,  2.3021e-02, -2.7259e-02, -1.7395e-02,\n",
       "           1.9654e-02,  2.9200e-03, -6.3900e-03, -2.5354e-02, -1.8209e-02,\n",
       "           3.7433e-03, -1.8974e-02, -2.4186e-02,  1.8516e-02,  1.1224e-02,\n",
       "          -3.7335e-04,  1.7025e-02, -2.1104e-02,  1.8345e-02, -2.3240e-02,\n",
       "          -2.2061e-02, -2.3127e-02,  1.8924e-03,  2.1200e-02, -2.6105e-02,\n",
       "          -1.4510e-02, -1.5182e-02, -1.6909e-02, -7.8095e-03,  3.5605e-03,\n",
       "           2.3611e-02,  1.4217e-02,  1.6983e-02,  1.4616e-02,  1.5669e-02,\n",
       "           1.0301e-02, -2.4813e-03,  2.5216e-02, -1.8420e-02,  1.1918e-02,\n",
       "          -1.5354e-02, -9.2167e-03, -1.1304e-03, -2.7555e-02,  8.3165e-03,\n",
       "           1.7286e-02,  2.2480e-02,  6.8173e-04, -2.6505e-02, -8.3249e-03,\n",
       "          -3.3840e-05, -2.7048e-02,  1.8180e-03, -2.3507e-02, -7.6080e-03,\n",
       "           9.7538e-03,  7.1778e-03,  9.5991e-03, -9.0150e-03,  1.7327e-02,\n",
       "          -2.2289e-03, -1.4069e-02,  4.6632e-03,  2.7638e-02,  4.0280e-04,\n",
       "           8.8232e-03,  1.2553e-03, -9.5135e-03, -2.6428e-02,  1.2492e-02,\n",
       "          -2.5993e-02,  1.2468e-02,  1.7901e-02,  1.5668e-02, -2.0227e-02,\n",
       "           3.2237e-03, -1.6862e-02, -8.4397e-03,  4.9741e-03,  1.4391e-02,\n",
       "          -5.3766e-03, -2.7676e-02, -1.2246e-02,  1.7417e-02,  1.6494e-02,\n",
       "           3.5582e-05,  8.6314e-03,  2.2453e-02, -2.5498e-02,  1.5731e-02,\n",
       "           1.2917e-02, -5.5026e-03, -9.7791e-03,  2.5332e-02,  2.4936e-02,\n",
       "          -2.5094e-03,  1.2061e-02,  1.9590e-02, -1.0974e-02, -9.4471e-03,\n",
       "           1.8712e-02, -1.2006e-02, -8.0561e-03, -2.0893e-02, -2.2648e-02,\n",
       "          -2.5062e-02,  3.9854e-05, -2.0470e-02, -1.6265e-03, -6.8218e-03,\n",
       "           1.0412e-02, -2.4068e-02, -2.5315e-02,  5.6870e-03, -1.7754e-02,\n",
       "          -2.3420e-02, -1.2623e-03, -8.8535e-03, -6.7935e-03, -1.3126e-02,\n",
       "           1.7551e-02,  1.9167e-02, -1.2902e-02, -1.1744e-02,  1.7020e-02,\n",
       "          -1.9961e-02, -1.5625e-02,  1.5746e-02,  5.8556e-03, -2.2581e-02],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0051,  0.0334,  0.0309,  ..., -0.0178,  0.0228,  0.0279],\n",
       "          [ 0.0174,  0.0019, -0.0240,  ..., -0.0081, -0.0051, -0.0253],\n",
       "          [ 0.0162,  0.0241, -0.0060,  ..., -0.0219,  0.0381, -0.0295],\n",
       "          ...,\n",
       "          [ 0.0177,  0.0341,  0.0061,  ...,  0.0205, -0.0326,  0.0204],\n",
       "          [ 0.0267,  0.0202, -0.0138,  ...,  0.0387, -0.0376, -0.0371],\n",
       "          [-0.0093,  0.0219,  0.0145,  ..., -0.0085,  0.0392, -0.0305]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0176,  0.0239, -0.0331, -0.0065, -0.0103, -0.0381, -0.0139,  0.0212],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0160,  0.0078,  0.0163,  ..., -0.0112, -0.0029, -0.0145],\n",
       "          [-0.0110, -0.0081,  0.0320,  ..., -0.0236, -0.0019, -0.0207],\n",
       "          [ 0.0071, -0.0104,  0.0031,  ...,  0.0037, -0.0022, -0.0465],\n",
       "          ...,\n",
       "          [ 0.0153, -0.0197, -0.0249,  ...,  0.0142, -0.0219, -0.0100],\n",
       "          [ 0.0028,  0.0294,  0.0067,  ..., -0.0022,  0.0215, -0.0077],\n",
       "          [-0.0020, -0.0049,  0.0420,  ...,  0.0061,  0.0192, -0.0167]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-1.1618e-02,  2.6695e-02, -5.4487e-03,  ..., -1.2466e-02,\n",
       "            2.4508e-02,  6.0136e-03],\n",
       "          [-1.9191e-02,  6.8443e-03, -8.7187e-03,  ..., -2.7563e-03,\n",
       "            6.5534e-05,  3.9082e-03],\n",
       "          [-1.2566e-02,  2.6903e-02,  1.3595e-02,  ..., -2.0210e-02,\n",
       "            1.5958e-02, -3.1471e-03],\n",
       "          ...,\n",
       "          [-3.0073e-02,  2.9292e-02,  9.6012e-03,  ..., -1.0666e-02,\n",
       "           -3.6464e-03,  4.1844e-02],\n",
       "          [ 1.6225e-03, -3.5819e-03,  1.2244e-02,  ..., -2.5287e-02,\n",
       "            3.2757e-02, -8.3601e-03],\n",
       "          [ 7.9757e-03,  1.1842e-02, -2.9317e-02,  ..., -1.7827e-03,\n",
       "            9.9965e-03,  3.8935e-03]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0155,  0.0102, -0.0084,  ...,  0.0362, -0.0098, -0.0053],\n",
       "          [ 0.0043, -0.0076,  0.0048,  ..., -0.0046,  0.0054,  0.0272],\n",
       "          [ 0.0039,  0.0055,  0.0066,  ...,  0.0122,  0.0144,  0.0131],\n",
       "          ...,\n",
       "          [-0.0023,  0.0027, -0.0276,  ..., -0.0118,  0.0220, -0.0093],\n",
       "          [ 0.0093, -0.0014,  0.0110,  ..., -0.0163,  0.0127,  0.0160],\n",
       "          [-0.0317,  0.0229,  0.0100,  ...,  0.0212, -0.0005,  0.0156]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0154,  0.0163, -0.0079,  ..., -0.0048,  0.0113, -0.0081],\n",
       "          [-0.0223,  0.0111,  0.0023,  ..., -0.0163,  0.0062,  0.0506],\n",
       "          [ 0.0337,  0.0001,  0.0157,  ...,  0.0177, -0.0021,  0.0377],\n",
       "          ...,\n",
       "          [-0.0113, -0.0177,  0.0088,  ..., -0.0325,  0.0070, -0.0087],\n",
       "          [-0.0047, -0.0046,  0.0399,  ...,  0.0058,  0.0110,  0.0004],\n",
       "          [-0.0155,  0.0196, -0.0061,  ...,  0.0143, -0.0249, -0.0209]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0210,  0.0249,  0.0187,  ...,  0.0245,  0.0156,  0.0077],\n",
       "          [-0.0041,  0.0179,  0.0269,  ...,  0.0061, -0.0160,  0.0079],\n",
       "          [-0.0150, -0.0107,  0.0107,  ...,  0.0279,  0.0083,  0.0126],\n",
       "          ...,\n",
       "          [-0.0163, -0.0085,  0.0200,  ...,  0.0180,  0.0099, -0.0073],\n",
       "          [-0.0188, -0.0275,  0.0107,  ...,  0.0084, -0.0268,  0.0048],\n",
       "          [ 0.0212, -0.0132,  0.0039,  ..., -0.0112,  0.0063,  0.0158]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-2.3211e-02,  1.4495e-02,  2.1546e-02,  8.7499e-04,  2.5867e-02,\n",
       "           1.8079e-02, -1.4901e-03, -2.7407e-02, -2.2004e-02, -2.3405e-03,\n",
       "           8.1921e-03, -2.2061e-03,  1.2352e-02, -1.4055e-03, -1.5955e-03,\n",
       "          -1.1149e-02,  1.3242e-02,  1.7604e-03,  1.7222e-02, -1.2456e-02,\n",
       "           1.4140e-02, -2.5090e-02, -1.5379e-02,  2.2035e-02, -1.1573e-03,\n",
       "           1.4004e-02, -1.7726e-03,  7.2939e-03, -2.1508e-02, -1.1498e-02,\n",
       "           2.5407e-03,  4.5823e-03, -2.5881e-02,  1.5494e-02, -1.3589e-02,\n",
       "          -2.1121e-02, -6.4836e-03, -2.5441e-02,  2.7150e-02, -7.6030e-03,\n",
       "          -2.7010e-02,  4.7759e-03,  2.3251e-02,  2.5650e-02,  1.6851e-02,\n",
       "           2.3720e-02, -5.0820e-04, -1.1330e-02,  4.3555e-03, -1.5881e-02,\n",
       "           6.9585e-03,  8.4277e-03,  1.5392e-02, -1.1945e-02, -2.6504e-02,\n",
       "          -2.7745e-02, -2.7114e-02,  2.6546e-02,  2.4903e-02, -2.8771e-03,\n",
       "          -4.8604e-03,  2.2510e-02, -2.1430e-02,  8.1233e-03,  2.9500e-03,\n",
       "          -2.7060e-02,  2.6201e-02,  1.7711e-02,  2.2847e-02, -2.7639e-02,\n",
       "          -3.0941e-03, -1.1038e-02,  9.1090e-03, -7.7650e-03, -6.1806e-03,\n",
       "          -1.7085e-03,  9.5551e-03,  6.6741e-04, -2.1271e-02, -7.1759e-03,\n",
       "          -1.5874e-02,  2.3654e-02, -2.5922e-02, -2.2482e-02, -1.0324e-02,\n",
       "           1.6851e-02,  2.2942e-02,  1.6685e-02, -3.4462e-03,  4.5189e-03,\n",
       "          -1.3390e-02, -2.2320e-03,  2.6341e-02, -2.4950e-02, -1.7902e-04,\n",
       "           1.2402e-02,  5.3062e-03,  1.9436e-02,  2.4557e-02,  8.8862e-03,\n",
       "          -2.3115e-02,  6.4461e-03, -1.9557e-02,  7.6626e-03, -3.3532e-03,\n",
       "           2.6309e-04, -2.1891e-02, -2.7007e-02, -4.6804e-03, -2.2616e-02,\n",
       "          -1.1141e-02, -2.5989e-02, -2.0289e-02, -2.1186e-02,  2.1863e-02,\n",
       "          -1.1731e-02,  2.7927e-03,  2.2606e-02, -1.3236e-02, -8.1446e-03,\n",
       "          -2.6908e-02, -1.7362e-02, -1.2863e-02,  1.7392e-02,  5.6981e-04,\n",
       "           6.9514e-03, -8.5208e-03,  4.1960e-03, -2.5570e-02, -2.3953e-02,\n",
       "           4.5798e-03,  1.0644e-02,  1.5723e-02,  1.2552e-03,  2.4299e-02,\n",
       "          -1.3499e-03,  1.4932e-02,  2.5207e-03, -1.0904e-02,  2.6410e-02,\n",
       "           2.2755e-02,  2.2745e-02,  8.5172e-03, -1.3956e-02,  6.8621e-03,\n",
       "          -5.2813e-03, -1.9656e-02,  1.7153e-02, -1.7816e-02,  1.8088e-02,\n",
       "           1.3402e-02, -2.1866e-02, -1.5191e-02, -2.4248e-03,  2.6515e-02,\n",
       "           2.0686e-02,  1.4009e-02,  5.2858e-03, -1.8442e-03, -6.8810e-03,\n",
       "           1.7149e-02,  2.4180e-03, -1.1700e-02,  1.0415e-02, -6.6552e-03,\n",
       "           1.8616e-03, -1.3736e-02,  7.3823e-03, -7.9280e-03,  1.0703e-02,\n",
       "          -4.5078e-03,  2.2734e-04, -1.3426e-02, -2.2459e-04,  2.3429e-04,\n",
       "          -1.8582e-02, -2.6748e-02, -6.3834e-04, -1.0358e-02, -5.7610e-03,\n",
       "           4.1362e-03,  7.9432e-03, -1.5243e-02,  2.5980e-02,  1.7400e-02,\n",
       "          -6.8006e-03, -2.5745e-02, -3.4205e-03, -1.3666e-02,  1.9143e-02,\n",
       "           3.5332e-04, -1.0594e-03,  2.6575e-02, -2.7603e-02,  8.9709e-04,\n",
       "          -1.8356e-02,  2.4438e-02, -1.3512e-02, -3.3559e-03,  7.2148e-03,\n",
       "          -9.2283e-03, -3.3359e-03, -8.4215e-03,  1.7482e-03, -1.7430e-02,\n",
       "          -1.3037e-03, -1.8070e-02,  5.3475e-05,  3.4330e-04, -2.3896e-02,\n",
       "           1.8530e-03,  2.5440e-03,  9.1316e-03,  1.0643e-02,  3.2255e-03,\n",
       "           6.6701e-03, -1.3517e-02,  7.8312e-04, -1.8395e-02,  1.8237e-02,\n",
       "          -3.0054e-03,  1.1304e-02, -1.4148e-02, -3.3386e-03, -1.5234e-02,\n",
       "           1.8679e-02,  2.5983e-02, -9.8749e-03, -1.1070e-02, -2.2498e-02,\n",
       "           1.6287e-02,  2.7762e-02, -2.7864e-03,  3.7316e-03, -2.7430e-02,\n",
       "          -4.8282e-03,  1.3098e-02, -1.5579e-02,  2.7796e-02,  7.7698e-03,\n",
       "          -3.0557e-03,  1.9811e-02,  5.8107e-03,  2.2666e-03,  7.4837e-05,\n",
       "           7.8001e-03, -2.0036e-02, -2.0886e-02,  5.9815e-03, -2.7548e-02,\n",
       "           5.3892e-03, -5.7616e-03, -1.5706e-02, -1.4868e-02,  2.2325e-03,\n",
       "           2.1441e-02,  2.7397e-02, -1.5997e-02,  1.0412e-02, -1.8401e-02,\n",
       "           2.4949e-02,  1.5458e-02, -7.0415e-03, -2.7385e-02,  1.6891e-02,\n",
       "           1.2403e-02,  9.5698e-03,  9.6330e-03, -8.2392e-03,  2.3269e-02,\n",
       "          -1.0205e-02,  1.7976e-02, -6.6862e-03,  2.5439e-02,  5.2350e-03,\n",
       "           1.6790e-02, -5.2626e-03, -8.5370e-03, -6.8228e-03, -1.2451e-02,\n",
       "           1.8587e-03, -1.8136e-02,  1.2481e-02, -2.4763e-02, -1.7360e-02,\n",
       "           9.7642e-03, -1.3809e-02, -6.2684e-04, -3.3379e-03,  1.2711e-02,\n",
       "          -2.4401e-02, -8.9415e-03, -7.0982e-03,  1.0336e-02,  2.1690e-03,\n",
       "           6.4031e-03, -8.9389e-03, -9.9852e-03, -7.2461e-03,  2.4600e-04,\n",
       "           2.7145e-03,  1.2984e-02, -2.7232e-02, -1.7999e-02, -1.4423e-02,\n",
       "           5.3651e-03,  2.0349e-02,  2.9050e-03,  2.7814e-02, -2.2556e-02,\n",
       "           2.2429e-02,  1.7031e-02,  2.4274e-02,  2.1314e-02,  3.1540e-03,\n",
       "           2.0583e-02, -4.4874e-03, -1.8221e-02, -1.3236e-03, -1.5698e-02,\n",
       "          -2.4643e-02, -1.6629e-02,  1.4607e-02, -8.5398e-03, -1.2182e-02,\n",
       "           3.1282e-03,  5.7505e-03, -8.1546e-03, -2.4761e-02, -2.5734e-02,\n",
       "           2.2401e-03, -1.3454e-02,  2.2361e-04, -2.1325e-02,  1.5108e-02,\n",
       "          -1.3086e-02,  8.6984e-03,  2.3127e-02,  7.5837e-03, -1.5151e-02,\n",
       "           1.3397e-02, -2.5960e-02, -1.6854e-02,  2.1545e-02,  9.2152e-04,\n",
       "          -1.1891e-02, -2.7654e-02,  2.5074e-02, -2.5549e-02,  3.6373e-03,\n",
       "           2.1376e-04,  2.1810e-02, -2.4954e-02,  1.8889e-02,  2.2483e-02,\n",
       "           2.2918e-02, -1.1376e-02,  2.1229e-02,  1.0142e-02,  1.5661e-03,\n",
       "           8.7569e-03, -7.6487e-03,  5.1776e-03, -1.3658e-02, -2.5478e-02,\n",
       "          -1.6830e-02,  5.1675e-03, -9.7573e-03, -2.4821e-02, -1.5444e-02,\n",
       "          -1.2415e-02,  1.5655e-02, -1.8071e-02,  1.1986e-02,  1.7639e-03,\n",
       "           2.0954e-02, -2.7601e-02,  1.6438e-02,  9.6219e-03, -1.7288e-02,\n",
       "           1.7744e-02, -1.1666e-02,  2.6807e-02,  5.4160e-03,  2.0803e-03,\n",
       "           1.9483e-02, -1.8563e-02,  1.8795e-02,  2.4495e-02, -1.8298e-02,\n",
       "           9.9211e-04,  7.1065e-04,  2.1781e-02, -1.7466e-02, -2.4256e-02,\n",
       "          -5.7756e-03, -2.2900e-02,  6.3767e-03, -2.4827e-02, -2.3250e-02,\n",
       "          -1.2254e-02,  2.1618e-02, -2.2694e-02, -2.3362e-02, -2.2296e-02,\n",
       "           1.3143e-02,  1.7130e-02,  1.7570e-02, -1.0256e-02, -5.5206e-03,\n",
       "           7.8665e-03,  1.7654e-02,  2.1978e-02,  6.4787e-03, -2.2071e-02,\n",
       "           1.5417e-02, -2.8781e-03,  2.5296e-02, -3.2707e-03, -1.3601e-02,\n",
       "          -1.7396e-02, -1.0176e-02,  1.6859e-02,  2.2696e-03, -1.9863e-02,\n",
       "           2.3091e-02, -1.5995e-02, -2.2874e-02,  6.2923e-03, -1.5016e-02,\n",
       "           1.3076e-02, -5.0345e-03,  1.5815e-02,  2.2081e-02,  1.9367e-02,\n",
       "          -8.5412e-03,  2.5562e-02, -2.2240e-02,  3.7175e-03,  1.7217e-02,\n",
       "           2.2987e-02, -4.6288e-03, -4.6445e-03,  1.0788e-02,  3.1608e-03,\n",
       "          -1.7255e-02,  2.4430e-02, -2.5795e-02,  2.2855e-02, -1.5761e-02,\n",
       "          -2.6645e-02, -1.5935e-02,  3.6887e-03, -9.1272e-03,  4.7581e-03,\n",
       "          -5.6213e-03,  1.4273e-02, -1.4211e-02,  1.8568e-02,  1.5703e-03,\n",
       "           7.6748e-04,  7.0726e-04,  3.4301e-03,  1.2983e-02,  7.4027e-04,\n",
       "           2.0434e-02, -2.0868e-02, -5.9316e-03, -9.3085e-03, -2.5534e-02,\n",
       "           1.5278e-02, -1.8565e-02,  7.8031e-03,  1.0414e-02,  2.7349e-02,\n",
       "           9.7955e-03, -9.0961e-03,  2.7451e-02, -1.2600e-02, -1.9463e-02,\n",
       "           1.6684e-02,  1.7483e-02,  1.7050e-02,  7.3073e-03, -1.5486e-02,\n",
       "          -1.9723e-02, -2.7213e-02, -3.4922e-03,  2.7528e-02, -1.9290e-02,\n",
       "          -1.0159e-02,  1.0430e-02,  1.7130e-02, -2.9157e-03, -1.2032e-02,\n",
       "          -2.7465e-02,  3.8466e-03,  2.7631e-02, -1.0971e-02,  1.3103e-02,\n",
       "           1.2284e-02, -9.6908e-03, -5.2796e-03, -1.6888e-02, -2.5112e-03,\n",
       "          -2.4732e-02,  1.1634e-02, -6.2411e-03, -5.6032e-03, -4.6897e-03,\n",
       "          -1.3835e-02, -1.9400e-02,  2.5477e-02,  2.6432e-02, -1.8348e-02,\n",
       "           8.9589e-03, -2.7073e-02,  1.4955e-02,  2.2870e-02,  3.1312e-03,\n",
       "          -2.0496e-02, -1.2012e-02,  1.4303e-02,  1.5332e-02, -2.0313e-02,\n",
       "          -7.9427e-03,  2.4239e-02,  2.2557e-02, -1.8252e-02,  5.5562e-03,\n",
       "           2.9021e-03,  5.4483e-04,  2.6467e-02, -1.9002e-02,  2.4190e-02,\n",
       "           2.4544e-02,  2.1511e-04, -1.7007e-02,  1.3267e-02, -1.6814e-02,\n",
       "           2.1656e-03,  1.1883e-02, -2.4341e-02, -2.6797e-02,  2.4995e-02,\n",
       "           6.6438e-03, -3.6720e-03, -1.5796e-03,  3.4630e-04,  9.4510e-03,\n",
       "          -1.2004e-02, -8.1349e-03, -2.1892e-02,  3.4796e-03,  1.2787e-03,\n",
       "          -2.6144e-02,  2.7772e-02, -2.5413e-02,  3.1040e-03, -5.6433e-03,\n",
       "          -8.0915e-03, -2.5307e-02, -9.1497e-03,  2.7756e-02,  4.5967e-03,\n",
       "          -2.1109e-02,  2.6553e-02, -1.7095e-02,  1.5085e-02,  2.5211e-02,\n",
       "           1.3592e-02,  1.0853e-02,  1.1907e-02, -1.8994e-02,  6.7376e-03,\n",
       "          -2.4040e-02,  1.2738e-02,  2.6378e-02,  3.0771e-03, -1.3537e-02,\n",
       "          -7.8464e-04,  3.6557e-03,  1.0838e-02, -1.4944e-02,  6.1764e-03,\n",
       "           3.0615e-03, -2.5422e-04, -3.3881e-03, -8.7737e-03,  5.7636e-03,\n",
       "           2.0689e-02,  1.9504e-02,  2.3263e-03, -1.6803e-02,  1.8794e-02,\n",
       "          -9.8577e-03,  2.0624e-02,  1.1292e-02, -1.9013e-03, -4.0220e-03,\n",
       "          -5.8024e-03, -1.2744e-02,  1.0877e-02,  2.6411e-02,  2.4356e-02,\n",
       "           1.1836e-02,  7.6414e-03,  9.1955e-03, -2.2473e-02, -1.9668e-02,\n",
       "           9.0119e-03, -2.7461e-02, -8.5690e-03, -1.7883e-03, -1.4758e-02,\n",
       "           1.7045e-03,  1.5413e-02,  1.9096e-02,  6.4734e-03,  3.3870e-03,\n",
       "          -7.6779e-03,  2.2223e-03, -1.7560e-02, -1.1423e-02,  8.2358e-03,\n",
       "          -2.6688e-02,  7.4737e-03,  4.5489e-03,  1.3956e-03, -1.6770e-02,\n",
       "          -5.8844e-03,  6.3408e-03,  1.7563e-03,  1.1165e-02,  5.0633e-03,\n",
       "           2.4365e-02,  2.4778e-02, -6.3496e-03, -9.5085e-03, -9.6504e-03],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0334, -0.0255,  0.0224,  ..., -0.0298,  0.0175, -0.0275],\n",
       "          [-0.0001,  0.0069,  0.0256,  ..., -0.0012,  0.0291,  0.0046],\n",
       "          [ 0.0348,  0.0269, -0.0273,  ..., -0.0158,  0.0378, -0.0269],\n",
       "          ...,\n",
       "          [ 0.0157,  0.0096, -0.0025,  ..., -0.0011, -0.0133,  0.0333],\n",
       "          [ 0.0366, -0.0136, -0.0358,  ...,  0.0177,  0.0078,  0.0039],\n",
       "          [-0.0301,  0.0178,  0.0210,  ..., -0.0292,  0.0256, -0.0191]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0209, -0.0115, -0.0202, -0.0382,  0.0238,  0.0278,  0.0060, -0.0367],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0027, -0.0132, -0.0091,  ..., -0.0116, -0.0145,  0.0268],\n",
       "          [ 0.0242,  0.0130, -0.0044,  ...,  0.0173,  0.0061, -0.0045],\n",
       "          [-0.0057, -0.0064,  0.0056,  ..., -0.0056, -0.0031,  0.0230],\n",
       "          ...,\n",
       "          [ 0.0106, -0.0302, -0.0157,  ..., -0.0096, -0.0035,  0.0158],\n",
       "          [ 0.0062,  0.0028,  0.0089,  ...,  0.0111,  0.0031,  0.0007],\n",
       "          [-0.0032, -0.0221,  0.0056,  ..., -0.0055, -0.0060, -0.0169]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0112,  0.0148,  0.0120,  ..., -0.0072, -0.0212,  0.0177],\n",
       "          [ 0.0088, -0.0346,  0.0312,  ..., -0.0056,  0.0017, -0.0060],\n",
       "          [-0.0054, -0.0139, -0.0181,  ...,  0.0018, -0.0085, -0.0034],\n",
       "          ...,\n",
       "          [-0.0086, -0.0115,  0.0127,  ..., -0.0046,  0.0407, -0.0094],\n",
       "          [ 0.0106,  0.0152,  0.0133,  ..., -0.0224, -0.0108, -0.0043],\n",
       "          [ 0.0097, -0.0084,  0.0182,  ..., -0.0020,  0.0012,  0.0042]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 1.6812e-02,  2.8577e-02, -1.7853e-02,  ...,  3.6059e-03,\n",
       "           -1.6207e-03,  5.2992e-03],\n",
       "          [ 8.7373e-06,  1.9817e-03, -3.3749e-02,  ..., -7.3311e-03,\n",
       "           -1.0117e-02,  1.8793e-03],\n",
       "          [-6.4879e-03, -3.6467e-02, -2.6362e-02,  ...,  1.4349e-04,\n",
       "           -6.5945e-04, -2.1434e-02],\n",
       "          ...,\n",
       "          [ 3.5056e-02, -2.4004e-02, -3.1579e-03,  ...,  9.9624e-03,\n",
       "            1.3421e-02, -2.8985e-02],\n",
       "          [ 8.9252e-03, -2.7795e-02, -1.0038e-02,  ..., -1.9647e-02,\n",
       "           -3.1254e-02,  4.3446e-03],\n",
       "          [-2.0234e-02, -1.2188e-02, -1.3960e-02,  ..., -4.0365e-03,\n",
       "           -1.0732e-02, -6.3264e-03]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0012,  0.0164, -0.0115,  ..., -0.0071, -0.0061,  0.0131],\n",
       "          [-0.0032, -0.0070, -0.0032,  ...,  0.0108,  0.0099, -0.0035],\n",
       "          [ 0.0072,  0.0086,  0.0196,  ..., -0.0004, -0.0076, -0.0220],\n",
       "          ...,\n",
       "          [-0.0128,  0.0032,  0.0137,  ...,  0.0068,  0.0146, -0.0017],\n",
       "          [-0.0234, -0.0263,  0.0010,  ..., -0.0241,  0.0146, -0.0088],\n",
       "          [ 0.0098,  0.0030,  0.0306,  ...,  0.0100,  0.0014,  0.0235]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0271,  0.0225,  0.0008,  ...,  0.0011,  0.0153,  0.0025],\n",
       "          [ 0.0255,  0.0188,  0.0005,  ..., -0.0138,  0.0118, -0.0014],\n",
       "          [ 0.0016, -0.0207, -0.0125,  ...,  0.0173, -0.0115,  0.0258],\n",
       "          ...,\n",
       "          [-0.0206,  0.0153,  0.0191,  ...,  0.0151, -0.0242, -0.0274],\n",
       "          [ 0.0146,  0.0251, -0.0054,  ..., -0.0133, -0.0020,  0.0092],\n",
       "          [-0.0259,  0.0152,  0.0081,  ...,  0.0256, -0.0134,  0.0091]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 2.4065e-02,  8.4979e-04,  1.2220e-02, -4.9165e-03, -1.5894e-02,\n",
       "          -2.5326e-03,  4.6341e-03, -2.7520e-02,  2.2444e-02, -1.2899e-02,\n",
       "          -1.9464e-02,  1.6985e-02, -2.1180e-03, -2.4578e-02,  2.1651e-02,\n",
       "           1.4063e-02, -9.9889e-03,  1.6507e-02, -1.7412e-02,  2.6599e-02,\n",
       "          -1.2454e-02, -2.2274e-02,  2.6661e-02, -1.1306e-03, -3.2335e-03,\n",
       "          -1.2934e-02,  2.6815e-02,  1.7045e-02,  6.0954e-03, -9.4265e-03,\n",
       "           8.2273e-03, -1.7296e-02, -2.4052e-02, -1.4091e-02,  1.3740e-02,\n",
       "          -1.5699e-02,  2.0273e-02,  1.0783e-02, -1.9785e-02, -1.7532e-02,\n",
       "           9.9890e-04, -1.1513e-02, -4.9870e-03,  2.2501e-02,  4.2743e-03,\n",
       "           2.6764e-03,  5.6349e-03,  1.0777e-02,  1.8046e-02,  2.4519e-02,\n",
       "          -3.0037e-03, -4.9462e-03,  2.1695e-02, -2.6184e-02,  1.4043e-02,\n",
       "          -1.0308e-02, -1.8318e-02,  2.6622e-02, -6.3420e-03, -1.3171e-02,\n",
       "           2.6238e-02, -1.6025e-03,  1.8303e-02, -4.7332e-03,  2.2491e-03,\n",
       "          -8.8357e-03,  4.0641e-03,  2.6437e-02,  1.7147e-03,  2.4806e-02,\n",
       "          -1.6988e-02,  1.4637e-02,  1.2888e-02,  2.0937e-02,  2.7258e-02,\n",
       "          -8.2167e-03, -1.1958e-02, -7.7241e-03,  2.5835e-02, -2.2037e-02,\n",
       "           1.1848e-02, -2.4203e-02,  2.1811e-02, -6.7234e-03, -2.6404e-02,\n",
       "           2.1092e-03, -2.3183e-02,  9.7423e-03, -3.0993e-03, -3.5037e-03,\n",
       "           3.8536e-03,  2.3720e-02, -1.7987e-02,  2.3358e-03,  1.0444e-02,\n",
       "           2.2649e-03, -1.0155e-02,  7.0545e-05, -2.3054e-02, -1.5221e-02,\n",
       "          -1.9819e-03,  8.6476e-03, -2.2978e-02,  1.2486e-02, -9.8240e-03,\n",
       "           1.5821e-03, -2.3773e-02,  6.4611e-03, -9.5589e-03, -4.8601e-03,\n",
       "           1.8699e-02, -1.4446e-02,  2.5278e-02,  4.8004e-03,  2.3848e-02,\n",
       "          -1.8085e-02, -2.7939e-02, -2.4092e-02, -5.7409e-03,  1.7260e-02,\n",
       "           8.3379e-03, -3.2250e-03, -6.7761e-04,  4.6763e-03, -3.1406e-03,\n",
       "           2.5975e-02, -2.0682e-02, -7.0325e-03, -2.3878e-02,  1.7716e-02,\n",
       "           2.5920e-03,  1.2142e-02,  1.2356e-02,  8.6534e-03, -1.2713e-02,\n",
       "          -1.5325e-02, -7.6702e-03, -5.2821e-03, -2.7269e-02, -1.8058e-02,\n",
       "          -3.0495e-03, -3.2148e-03, -2.1735e-02,  9.9341e-03, -6.1429e-03,\n",
       "           1.7825e-02,  2.4555e-02,  2.5248e-02,  1.7023e-02,  9.1750e-03,\n",
       "          -3.3828e-03,  1.3918e-02,  1.4338e-02, -5.9198e-03, -5.8575e-03,\n",
       "          -1.5762e-02, -1.2835e-02,  5.9174e-03,  2.4112e-03, -6.6589e-03,\n",
       "          -2.7716e-02,  1.2132e-03, -8.7799e-03,  1.1746e-02,  4.9339e-03,\n",
       "           7.4690e-03,  1.8477e-02, -6.9531e-03, -6.4810e-03,  2.2240e-02,\n",
       "          -1.2951e-02,  2.9943e-03,  1.2914e-02,  5.6967e-03, -2.4077e-02,\n",
       "           2.6759e-02, -1.6238e-02,  1.0557e-03, -1.3823e-02, -1.7011e-02,\n",
       "          -4.1664e-03, -2.4578e-02, -9.0339e-03, -2.7490e-02, -1.5466e-02,\n",
       "          -1.2172e-02, -1.0136e-02, -6.2674e-03,  1.0012e-02, -2.3124e-03,\n",
       "           2.2005e-02, -2.5352e-02,  1.9422e-02,  2.1462e-02,  4.5770e-03,\n",
       "           8.7932e-03,  1.1759e-02,  1.0539e-02,  1.9822e-02,  2.1694e-02,\n",
       "          -2.3856e-02,  2.7285e-03,  3.6375e-03, -1.0204e-02, -1.6062e-02,\n",
       "           3.3601e-03, -1.1473e-02,  1.6791e-02, -2.6161e-02, -1.5701e-03,\n",
       "           4.5427e-03, -1.4624e-02, -1.3080e-02,  2.2012e-02, -8.0324e-03,\n",
       "          -1.9857e-02, -1.7610e-02,  2.3047e-02,  5.9072e-03, -1.9971e-02,\n",
       "          -2.2868e-02, -1.6478e-02, -1.0121e-02, -1.2574e-02,  1.6585e-02,\n",
       "          -1.7422e-02,  1.6711e-02,  3.3798e-03, -1.6351e-02,  5.2830e-03,\n",
       "           9.7374e-03, -1.3347e-02,  1.6805e-02, -1.8418e-02,  6.6689e-03,\n",
       "          -2.3009e-02,  6.2194e-03,  5.4868e-03,  2.4320e-02, -3.8738e-03,\n",
       "           1.1467e-02,  1.4051e-02, -1.8948e-02,  1.3477e-02, -2.6492e-02,\n",
       "           2.3734e-02, -1.1415e-02, -1.5476e-02,  1.6692e-02,  4.3335e-03,\n",
       "           1.9762e-03, -1.2922e-02,  2.4077e-02, -2.4191e-02, -2.5485e-02,\n",
       "          -1.3832e-02,  2.6894e-03,  2.4907e-02, -1.8638e-02,  7.2480e-03,\n",
       "          -2.0402e-02, -2.3686e-02, -5.4009e-03, -1.6034e-02,  7.7704e-04,\n",
       "           1.7395e-02,  4.1762e-03,  2.4347e-02,  2.2031e-02, -2.5723e-02,\n",
       "           2.6615e-02,  2.4372e-02, -1.5705e-02, -7.6217e-03,  2.6163e-02,\n",
       "           2.4889e-02,  2.4390e-02,  2.6657e-02, -1.6164e-02,  1.1207e-02,\n",
       "           2.4905e-02,  4.9047e-03,  1.5574e-02,  1.6242e-02,  2.0541e-02,\n",
       "           1.0315e-02,  1.6878e-02,  1.5459e-02,  1.1199e-02, -1.4640e-02,\n",
       "           1.1350e-02, -1.6995e-02, -1.3632e-02, -1.1997e-02, -1.3251e-03,\n",
       "           1.9543e-02, -2.6226e-02,  1.6128e-02, -6.4816e-03,  5.3825e-03,\n",
       "           1.8719e-02, -2.4179e-02,  2.1388e-03,  1.6103e-02, -2.4079e-02,\n",
       "           1.8448e-02,  2.3911e-02, -1.9630e-02,  2.3853e-02,  1.8281e-02,\n",
       "          -1.2453e-02,  4.7235e-03,  4.0942e-03, -1.7813e-02, -5.0884e-04,\n",
       "           2.3428e-02, -6.1973e-03,  8.9154e-03, -8.5767e-03,  1.8950e-02,\n",
       "          -2.0218e-02, -1.7355e-03, -7.6845e-03, -2.5301e-02, -1.4777e-04,\n",
       "           1.0164e-02, -1.1639e-02, -1.4738e-02,  1.7451e-02,  2.8940e-03,\n",
       "          -1.3466e-02, -1.4349e-02,  4.5749e-04,  5.5063e-04,  1.9302e-02,\n",
       "           2.7801e-03,  2.7413e-02, -1.3554e-02, -3.6614e-04, -2.5738e-02,\n",
       "           5.1211e-04,  3.9814e-03, -1.3133e-02, -2.7272e-02, -1.4023e-02,\n",
       "          -1.8705e-02, -1.9464e-02,  2.2726e-02,  1.5680e-02,  1.9516e-02,\n",
       "           2.1507e-02, -1.8324e-03,  5.7477e-03,  2.0782e-02,  2.3493e-02,\n",
       "           1.5777e-02, -1.3382e-03,  1.9259e-02, -6.1058e-04,  9.3321e-03,\n",
       "          -7.8883e-03, -2.3051e-02,  1.3887e-02, -1.9326e-02, -1.2264e-02,\n",
       "          -2.1650e-02,  5.8309e-03, -8.4852e-03,  1.8031e-02,  9.5517e-03,\n",
       "          -1.3592e-02, -1.6311e-02,  4.3460e-03,  1.6179e-02, -2.0394e-02,\n",
       "          -1.0030e-02, -2.7803e-02, -2.2604e-02,  1.9737e-02, -5.6721e-03,\n",
       "          -1.1313e-03, -3.5232e-03,  1.3718e-02,  9.6434e-03, -3.5078e-04,\n",
       "           1.9668e-02, -1.5690e-02, -1.6819e-02, -1.5063e-03, -2.5342e-02,\n",
       "           7.8747e-03,  1.1518e-02,  1.5735e-02, -2.3725e-02,  1.4093e-02,\n",
       "           2.7409e-02, -1.9782e-02,  1.3681e-02,  2.4304e-02,  5.6957e-03,\n",
       "           1.5589e-02, -5.8140e-03,  3.5908e-03, -2.5980e-02, -9.3360e-03,\n",
       "           1.4453e-02, -2.2061e-02, -1.4444e-02, -5.2080e-03,  2.7248e-02,\n",
       "           1.9960e-02,  2.6360e-03, -2.5486e-02, -2.3790e-02, -2.3262e-02,\n",
       "           1.2177e-02, -2.2428e-03,  1.4600e-02, -1.1038e-02, -8.3190e-03,\n",
       "           2.2027e-02,  1.4809e-02,  2.0661e-02, -1.1127e-02, -1.3980e-02,\n",
       "          -1.2406e-02,  3.1498e-03,  2.7006e-02,  1.7787e-02,  9.5483e-03,\n",
       "          -8.3678e-03,  1.5976e-02, -1.4895e-02,  1.2307e-02,  2.2470e-02,\n",
       "          -3.1904e-04,  2.5288e-03,  1.7884e-02,  1.8563e-02, -2.5366e-03,\n",
       "          -4.1185e-03,  2.1038e-02, -1.3507e-02, -1.6950e-03,  5.5246e-03,\n",
       "           4.8575e-03,  3.2822e-04,  1.4680e-02, -3.0591e-03,  2.5552e-02,\n",
       "          -1.4823e-02,  1.0358e-03, -1.9396e-02,  8.6423e-03,  1.9868e-02,\n",
       "          -8.2847e-03,  9.7901e-03, -2.0651e-02, -1.2426e-02, -6.9802e-04,\n",
       "           1.0641e-02,  1.4698e-02,  1.0097e-02,  2.1348e-02,  2.6457e-02,\n",
       "          -6.6166e-03,  2.3988e-02,  2.1474e-03, -2.3021e-02, -1.4006e-02,\n",
       "           2.3718e-02, -1.9839e-02,  1.9473e-02, -1.2758e-02,  1.4504e-02,\n",
       "          -2.4189e-02, -4.6506e-04, -3.3203e-03,  7.8118e-03,  8.1363e-03,\n",
       "          -5.4684e-03,  9.0118e-03, -3.1596e-03,  9.6304e-03, -1.6487e-02,\n",
       "           2.6749e-02, -1.0108e-02,  8.4667e-03, -5.1969e-03,  1.2375e-02,\n",
       "           1.2206e-02,  2.5307e-02, -2.6050e-02, -1.0290e-02,  8.8021e-03,\n",
       "          -1.7165e-02, -1.8144e-02,  2.7119e-02,  9.8961e-03,  1.4088e-02,\n",
       "           5.0385e-03, -4.1687e-03, -3.1463e-03,  2.7432e-02, -1.9245e-02,\n",
       "           1.0919e-02,  1.3689e-02, -5.4888e-03, -2.6243e-02,  1.6367e-02,\n",
       "          -2.4061e-02,  2.5281e-02,  2.2198e-02,  1.4788e-03, -4.6085e-03,\n",
       "          -2.4511e-02, -6.0219e-03, -1.7615e-03, -2.2354e-03,  2.6022e-02,\n",
       "           1.2447e-02, -1.0260e-02, -5.0051e-04, -1.6437e-02,  8.7820e-03,\n",
       "           8.2812e-03,  1.9620e-02, -1.8203e-02, -1.4952e-02, -1.2854e-02,\n",
       "          -1.9432e-02,  1.7725e-02, -5.9708e-03, -1.7887e-02,  6.0800e-03,\n",
       "           1.3819e-02, -9.5781e-03, -3.1367e-03,  2.3700e-02,  2.2019e-02,\n",
       "          -1.4734e-02, -2.0303e-02,  3.8696e-03, -7.9410e-03, -7.6754e-03,\n",
       "           7.7446e-03,  1.8718e-02,  2.2730e-02, -6.3004e-03,  1.4156e-03,\n",
       "           5.2187e-03, -2.7769e-02, -2.0772e-02, -2.6100e-02,  1.5112e-02,\n",
       "          -1.2242e-02,  1.1740e-02,  9.2061e-03,  3.1952e-03, -1.6162e-02,\n",
       "           1.7782e-02, -8.1780e-03, -2.0120e-02, -1.3581e-02, -1.7698e-02,\n",
       "           2.2465e-02,  1.8971e-02, -6.2275e-04, -1.1362e-02,  2.5944e-03,\n",
       "           8.2893e-04, -2.4217e-02, -2.0067e-02,  3.6829e-03,  2.5151e-02,\n",
       "          -2.2769e-02,  6.2888e-03, -2.4040e-02, -1.0787e-03,  2.3002e-02,\n",
       "           4.3190e-04, -7.3954e-04, -2.6656e-02, -1.2624e-02,  7.6314e-03,\n",
       "           1.7215e-02, -1.2938e-02, -1.5595e-02, -2.6189e-02, -1.0064e-02,\n",
       "           9.3573e-03,  6.0157e-03, -6.1333e-03, -1.3738e-02, -2.2717e-02,\n",
       "          -9.1885e-03, -2.5095e-02, -2.4045e-02,  2.2125e-02,  3.4540e-03,\n",
       "           7.1359e-03, -2.6053e-02,  1.5578e-02, -2.2042e-02, -4.9597e-03,\n",
       "           5.2330e-04,  1.8082e-02,  2.5870e-02, -8.8299e-03, -1.2975e-02,\n",
       "          -5.3550e-03, -7.6777e-03, -2.1196e-02,  2.0907e-02,  9.2387e-03,\n",
       "           1.7149e-02,  6.5564e-03,  5.5254e-03, -7.1239e-03,  7.2949e-03,\n",
       "           8.3557e-03, -2.7201e-02,  1.6364e-02,  2.6308e-02,  2.5616e-02,\n",
       "           1.3953e-02, -3.3659e-03, -1.7086e-02,  1.3587e-02, -2.3522e-02,\n",
       "           2.6085e-02, -5.7570e-03,  1.4847e-02, -2.5565e-02, -1.3050e-03,\n",
       "          -7.3579e-03,  1.5547e-02,  3.8817e-04,  2.5850e-03, -1.3430e-02],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0139, -0.0295, -0.0060,  ..., -0.0238,  0.0006,  0.0215],\n",
       "          [-0.0148,  0.0110, -0.0093,  ..., -0.0019, -0.0239, -0.0283],\n",
       "          [-0.0039, -0.0262,  0.0004,  ...,  0.0111, -0.0161, -0.0356],\n",
       "          ...,\n",
       "          [-0.0041,  0.0149,  0.0032,  ...,  0.0165,  0.0083,  0.0310],\n",
       "          [ 0.0361, -0.0321, -0.0388,  ...,  0.0212, -0.0011, -0.0068],\n",
       "          [ 0.0103, -0.0290,  0.0148,  ..., -0.0011, -0.0375, -0.0203]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0393, -0.0300, -0.0353,  0.0394, -0.0058,  0.0194,  0.0325, -0.0170],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0161, -0.0439, -0.0023,  ..., -0.0111,  0.0035,  0.0126],\n",
       "          [ 0.0217, -0.0114, -0.0184,  ..., -0.0046,  0.0313,  0.0070],\n",
       "          [ 0.0034,  0.0269,  0.0140,  ...,  0.0029,  0.0163,  0.0003],\n",
       "          ...,\n",
       "          [-0.0100, -0.0179,  0.0110,  ..., -0.0028, -0.0227, -0.0042],\n",
       "          [-0.0518, -0.0041,  0.0023,  ...,  0.0029,  0.0549, -0.0402],\n",
       "          [-0.0199, -0.0002,  0.0067,  ...,  0.0148, -0.0263, -0.0139]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0082, -0.0029,  0.0084,  ..., -0.0474,  0.0175,  0.0029],\n",
       "          [ 0.0220,  0.0326, -0.0061,  ...,  0.0016,  0.0036, -0.0049],\n",
       "          [-0.0194, -0.0025, -0.0023,  ..., -0.0224,  0.0156, -0.0162],\n",
       "          ...,\n",
       "          [ 0.0209, -0.0053, -0.0137,  ...,  0.0233, -0.0032, -0.0175],\n",
       "          [ 0.0024, -0.0349,  0.0112,  ...,  0.0114,  0.0019, -0.0078],\n",
       "          [-0.0153, -0.0158, -0.0282,  ..., -0.0077,  0.0144, -0.0273]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 1.5039e-02,  9.7256e-03,  1.1632e-02,  ..., -1.7103e-02,\n",
       "           -4.7645e-03, -1.5172e-02],\n",
       "          [-3.1249e-02, -9.7266e-03, -1.8018e-02,  ..., -7.4647e-04,\n",
       "            2.7220e-03, -5.0758e-03],\n",
       "          [-1.4831e-02,  2.1613e-02, -1.2659e-02,  ..., -6.4980e-04,\n",
       "           -1.6962e-02,  2.1163e-02],\n",
       "          ...,\n",
       "          [ 6.2552e-03, -4.9238e-03,  4.3951e-03,  ...,  1.7166e-02,\n",
       "            3.4175e-04,  1.6925e-02],\n",
       "          [ 2.0453e-02, -7.1415e-05,  2.4380e-02,  ..., -4.2309e-03,\n",
       "            1.6651e-02, -2.1687e-02],\n",
       "          [-1.5769e-02,  9.5703e-03,  2.4998e-03,  ..., -3.0439e-02,\n",
       "            1.1407e-02, -1.9005e-02]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0107, -0.0103, -0.0224,  ...,  0.0017, -0.0007,  0.0055],\n",
       "          [ 0.0293, -0.0125, -0.0137,  ...,  0.0280,  0.0198, -0.0219],\n",
       "          [-0.0214, -0.0088,  0.0091,  ...,  0.0109,  0.0209,  0.0023],\n",
       "          ...,\n",
       "          [ 0.0248, -0.0059,  0.0139,  ..., -0.0018, -0.0186,  0.0143],\n",
       "          [-0.0175, -0.0072, -0.0283,  ..., -0.0265,  0.0134,  0.0052],\n",
       "          [ 0.0090, -0.0059, -0.0075,  ...,  0.0047,  0.0164,  0.0037]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0248,  0.0030, -0.0183,  ...,  0.0255,  0.0125, -0.0209],\n",
       "          [ 0.0249, -0.0214, -0.0141,  ..., -0.0263, -0.0047, -0.0005],\n",
       "          [ 0.0048,  0.0008, -0.0118,  ..., -0.0263,  0.0106, -0.0082],\n",
       "          ...,\n",
       "          [-0.0199,  0.0161,  0.0277,  ...,  0.0204, -0.0151,  0.0205],\n",
       "          [-0.0045, -0.0071,  0.0266,  ...,  0.0088, -0.0259,  0.0141],\n",
       "          [ 0.0242,  0.0120, -0.0222,  ..., -0.0248,  0.0067, -0.0219]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-1.6323e-02,  1.0356e-03, -2.4184e-02,  2.1497e-03, -9.1703e-05,\n",
       "           2.5370e-04, -1.3424e-02,  1.0656e-02, -1.7227e-02,  2.1992e-02,\n",
       "           1.1231e-02,  2.6956e-02, -1.1063e-02, -1.6557e-03, -1.9320e-02,\n",
       "          -2.7293e-02, -2.1271e-02,  3.1962e-03, -1.8857e-02,  2.7749e-02,\n",
       "           1.9418e-02, -1.6606e-02,  3.1902e-03, -2.0174e-02,  8.6835e-03,\n",
       "          -9.3618e-03,  4.6038e-03, -1.5372e-02, -1.3599e-02,  1.7314e-03,\n",
       "           4.5989e-04,  1.4102e-02, -1.4769e-02,  7.7585e-03,  1.2781e-02,\n",
       "           1.9227e-02, -3.8444e-04, -2.6396e-02,  1.9393e-02, -1.1584e-03,\n",
       "           4.9945e-03, -1.7623e-03, -2.0019e-02, -1.1939e-02,  1.7065e-02,\n",
       "          -1.4961e-02,  1.4211e-02,  5.7386e-03,  1.3503e-02, -7.1778e-03,\n",
       "           4.3870e-03,  4.5403e-03,  1.8276e-03,  1.8225e-02,  7.8803e-03,\n",
       "          -1.5351e-02, -1.9265e-02, -1.4815e-02,  1.3503e-03,  1.4467e-02,\n",
       "          -2.0391e-02,  2.4601e-03, -2.0524e-02,  1.0074e-03,  1.0328e-02,\n",
       "           1.9606e-02, -7.8726e-03, -2.6237e-02, -2.4789e-02,  5.2671e-03,\n",
       "          -1.4841e-02,  2.3571e-02, -1.7521e-02,  2.3699e-02, -1.9119e-02,\n",
       "          -2.7885e-02,  1.4672e-02, -8.4157e-03, -2.4912e-03, -1.8597e-02,\n",
       "          -8.0670e-03, -6.5579e-03,  1.2719e-02,  1.4464e-02, -6.0414e-03,\n",
       "          -1.8959e-02,  9.3153e-03,  1.9943e-02, -2.6894e-02, -1.3122e-02,\n",
       "          -1.4954e-02, -2.6046e-02, -1.4715e-02,  1.9997e-02, -1.6725e-02,\n",
       "           5.0521e-04, -2.5607e-02,  2.7862e-02, -1.8177e-02,  1.5651e-02,\n",
       "           1.3384e-02,  6.1566e-03, -6.5164e-03, -2.0804e-02,  1.7407e-02,\n",
       "           1.9818e-03,  1.8303e-02,  3.4334e-03,  1.3294e-02, -8.3388e-03,\n",
       "          -1.7284e-02,  9.2606e-04, -1.2578e-02,  1.6368e-02,  1.2684e-02,\n",
       "          -2.0894e-02, -1.8033e-02, -1.3451e-02,  2.5860e-02, -2.6144e-02,\n",
       "          -5.1203e-04, -4.8074e-03,  1.1901e-02,  7.1298e-03,  7.8153e-03,\n",
       "           8.1277e-03, -9.3717e-03, -1.8211e-02,  2.5762e-02, -3.6675e-04,\n",
       "           1.0219e-02,  1.2343e-02, -7.6213e-03, -2.2197e-02, -3.7572e-04,\n",
       "          -2.4884e-02, -8.2045e-03,  1.7212e-02,  1.0256e-02, -1.6101e-02,\n",
       "          -2.0174e-02, -2.1583e-02,  2.1883e-02,  9.2462e-04, -2.1870e-02,\n",
       "           2.2766e-02,  3.6465e-03, -1.9991e-02, -1.8631e-02,  1.0750e-02,\n",
       "          -8.4091e-03, -7.0755e-03,  2.1934e-02, -1.4354e-02, -1.1602e-02,\n",
       "           1.6221e-02, -1.4094e-02, -8.9625e-03, -3.2445e-03,  1.3366e-03,\n",
       "          -3.9976e-03, -1.0365e-02, -3.1796e-03, -2.1847e-02, -1.2364e-03,\n",
       "          -2.3703e-02,  1.7117e-02, -1.8593e-02, -1.7004e-02, -2.5145e-03,\n",
       "           2.9419e-03,  2.5849e-02,  1.9835e-02, -8.3256e-03,  4.7598e-03,\n",
       "          -4.1157e-04,  5.8225e-03,  6.7220e-03,  3.5235e-03, -2.6547e-02,\n",
       "           1.2478e-02, -2.4353e-02,  9.1846e-03, -1.4649e-02,  6.9989e-03,\n",
       "           1.3286e-02, -1.9435e-02,  1.5825e-02, -2.1542e-02,  2.4733e-02,\n",
       "          -1.4049e-02,  1.5639e-02, -1.9482e-02,  2.1070e-02, -1.3619e-02,\n",
       "           2.4623e-02, -2.0692e-02, -2.1763e-02,  1.1387e-02, -2.1534e-02,\n",
       "           1.6950e-02,  8.5125e-03,  6.9050e-03, -1.1808e-02, -2.0732e-02,\n",
       "          -8.1098e-03, -2.6249e-02,  1.1681e-02,  8.5727e-03, -7.3657e-03,\n",
       "          -7.3313e-03,  2.5604e-02,  5.0990e-03,  1.3087e-02, -3.6521e-03,\n",
       "          -1.3671e-02,  2.6997e-02, -6.0760e-03,  1.2383e-02, -2.3756e-02,\n",
       "           1.5010e-02,  2.4507e-02, -2.3766e-02, -2.7893e-02,  9.1983e-03,\n",
       "          -1.1246e-02,  5.3388e-03,  3.8882e-03,  3.1439e-03, -2.2488e-02,\n",
       "          -2.2454e-02,  1.8182e-02, -5.5534e-03, -1.2097e-02, -2.4584e-02,\n",
       "           2.0630e-02, -1.3452e-03,  1.4686e-02, -2.1815e-02, -2.4601e-02,\n",
       "          -1.3001e-02, -1.8104e-02, -2.1106e-02,  2.7350e-02, -1.2220e-02,\n",
       "          -3.9358e-03,  1.4421e-02, -2.3213e-03, -5.4076e-03,  1.4152e-02,\n",
       "          -9.9646e-03,  1.3159e-02,  1.0875e-02,  2.4586e-02,  2.3139e-02,\n",
       "          -2.7290e-02,  1.0086e-02,  1.6444e-02,  2.0954e-02,  9.5423e-03,\n",
       "           2.6158e-02,  1.0665e-02, -1.1725e-02,  1.4429e-02, -1.4651e-02,\n",
       "          -2.6998e-02,  2.7927e-02, -1.3181e-02, -6.9512e-03,  2.1282e-02,\n",
       "          -1.4864e-02, -6.0913e-03, -2.1015e-02,  1.5903e-02,  8.4003e-03,\n",
       "          -9.6691e-04,  1.9013e-03, -1.4462e-03,  4.5605e-03,  1.5508e-02,\n",
       "           1.6285e-02, -3.2644e-03,  3.2540e-03, -1.2251e-02, -1.7252e-02,\n",
       "          -2.7262e-02, -6.4479e-03,  4.2686e-03,  1.7908e-02,  8.7545e-03,\n",
       "           2.3829e-02, -2.0230e-03,  2.7523e-02,  2.6855e-02, -2.5242e-02,\n",
       "          -2.7291e-02,  2.0067e-02,  1.6309e-02, -7.5495e-03,  9.0205e-03,\n",
       "           1.2438e-02, -3.1167e-03,  2.6913e-02,  1.2835e-02, -2.6465e-02,\n",
       "           4.3312e-03,  2.6485e-02, -4.4630e-03,  9.1494e-03,  1.4689e-02,\n",
       "           2.3303e-02,  6.4913e-03, -3.1993e-04, -8.5718e-03, -4.9678e-03,\n",
       "           2.1773e-02, -1.9206e-02,  2.1119e-02, -1.9983e-02,  1.4396e-03,\n",
       "          -1.6215e-02, -1.7030e-02,  1.2486e-02, -1.6979e-02,  7.9754e-03,\n",
       "           2.6374e-02, -2.0977e-02,  3.5115e-03,  1.4196e-04,  8.2573e-03,\n",
       "           2.8069e-03,  3.7750e-04,  1.1012e-02,  4.7809e-03,  2.4787e-02,\n",
       "          -1.7500e-02,  2.1509e-02, -2.5920e-03,  1.0682e-02, -2.0632e-02,\n",
       "          -6.5285e-03,  2.4053e-02, -2.7629e-02, -1.8685e-02,  4.5826e-03,\n",
       "          -3.5997e-04, -2.0868e-02, -2.5504e-02,  7.7803e-03,  1.0244e-02,\n",
       "           1.5297e-02, -4.7553e-03,  1.1492e-02,  2.2951e-02,  7.8363e-03,\n",
       "           2.8049e-03,  3.8779e-03, -2.0583e-02, -1.7956e-02, -2.0794e-02,\n",
       "           2.4988e-02, -9.5916e-03, -1.2286e-02,  3.3189e-03, -5.3322e-03,\n",
       "          -1.3866e-02,  1.3328e-02, -3.9071e-03,  1.0526e-02, -1.0335e-02,\n",
       "           3.5648e-04, -1.4166e-02,  2.3561e-03, -8.4655e-03, -2.6355e-02,\n",
       "          -1.3226e-03,  1.4713e-03, -2.5070e-03,  3.6398e-03,  1.2547e-02,\n",
       "          -1.9972e-02,  2.1103e-02,  6.3633e-03,  4.1572e-03, -1.7441e-02,\n",
       "          -1.8898e-02, -4.7711e-05, -7.6371e-03, -1.5406e-02,  1.2575e-02,\n",
       "           1.2769e-02, -2.3119e-02,  5.0219e-03, -1.8792e-02,  1.7444e-02,\n",
       "          -5.5101e-03, -7.6878e-03,  2.3536e-02,  1.8806e-02, -1.7467e-02,\n",
       "          -9.3417e-03, -2.2977e-02, -2.2540e-02, -5.0157e-03, -1.0279e-02,\n",
       "           1.0300e-03,  2.3134e-02,  8.2390e-03,  1.7822e-02,  1.6129e-02,\n",
       "           2.2885e-02, -7.9701e-04, -2.8313e-03, -2.1261e-02,  2.5238e-02,\n",
       "          -2.5434e-02, -8.5198e-03,  2.7147e-02,  4.7493e-03,  4.0641e-03,\n",
       "           1.1708e-02,  2.3588e-02,  1.7316e-02, -7.9215e-03,  1.1137e-02,\n",
       "           1.7703e-02, -1.1352e-02, -2.1163e-02,  1.0046e-02, -1.7165e-02,\n",
       "           3.9397e-03,  2.1940e-02, -6.7060e-03,  1.1761e-03, -1.9771e-02,\n",
       "           1.3470e-03, -1.6453e-02, -2.8814e-04, -2.6409e-02,  2.3847e-02,\n",
       "          -1.3261e-02,  3.1608e-04,  1.7677e-02, -1.5423e-02,  1.7061e-02,\n",
       "           8.4375e-03, -5.5393e-03,  1.7588e-02, -2.5232e-02,  3.9784e-05,\n",
       "           7.9325e-03, -1.0886e-02,  2.6067e-02,  2.7220e-02,  7.6282e-03,\n",
       "          -1.4881e-02,  8.6843e-03, -4.6049e-03, -2.2607e-02,  2.5188e-02,\n",
       "          -4.5517e-03,  2.1909e-02,  1.9774e-02,  4.1602e-03, -9.6819e-03,\n",
       "          -9.5967e-03,  1.2818e-03, -1.5956e-03, -1.2183e-02, -8.2400e-03,\n",
       "           1.2682e-02, -2.2300e-02,  6.8632e-03,  1.9664e-02,  4.1703e-03,\n",
       "          -2.4460e-02,  1.0193e-02, -1.6869e-02, -4.4232e-04,  1.9216e-02,\n",
       "          -2.0910e-02, -4.6015e-03,  1.3915e-02,  7.2895e-03, -7.0110e-03,\n",
       "           2.4271e-02, -2.2268e-02,  2.1993e-03, -2.4122e-02,  8.4282e-03,\n",
       "          -6.7236e-03,  2.1206e-02,  2.7598e-02, -2.4055e-02,  1.3546e-02,\n",
       "           5.4377e-03, -1.9286e-02,  1.1371e-02,  7.5993e-03, -2.0244e-02,\n",
       "           1.9636e-02,  2.6343e-02,  9.9217e-03,  1.3173e-02, -2.3153e-02,\n",
       "           1.8842e-03,  2.6879e-02, -2.7786e-02, -7.8717e-03,  2.5714e-02,\n",
       "           1.9953e-02,  3.0727e-03,  1.8878e-02, -1.9224e-02,  1.3764e-02,\n",
       "           8.5790e-03,  2.2684e-02,  1.4717e-03, -6.9549e-03,  6.7000e-03,\n",
       "           2.5281e-02,  1.9071e-02, -2.7832e-02,  9.6172e-03,  2.3306e-02,\n",
       "          -9.7618e-03,  4.6786e-03, -1.8094e-02, -6.2239e-03, -2.6910e-02,\n",
       "          -8.8207e-03, -7.8090e-03, -2.2209e-02,  1.0979e-02,  2.9128e-03,\n",
       "          -1.0323e-02,  1.1029e-02,  7.0894e-03, -3.3587e-03,  4.2048e-03,\n",
       "           1.4378e-02,  2.1741e-03, -2.1088e-02, -1.8766e-03, -1.9216e-02,\n",
       "           3.5556e-04,  1.9733e-02, -8.4207e-03,  2.7401e-02,  1.4977e-02,\n",
       "          -2.0780e-02,  1.9728e-02,  2.3452e-02, -3.0560e-03,  1.8954e-02,\n",
       "           1.9306e-03, -2.0311e-03,  9.4809e-03, -1.2564e-02,  2.6384e-03,\n",
       "          -2.4826e-02, -2.7265e-02,  2.1122e-02,  2.4275e-03, -1.3022e-02,\n",
       "           2.3353e-02, -1.0990e-02,  7.0669e-03,  4.5120e-03,  4.9922e-03,\n",
       "           2.2958e-02, -2.5240e-02,  9.4150e-03,  2.6170e-02,  3.0169e-03,\n",
       "          -1.1430e-02,  9.8474e-04, -3.5092e-03, -2.4430e-03,  1.9675e-02,\n",
       "           1.6952e-02,  1.9294e-02, -1.7278e-02, -1.8218e-02, -8.2271e-03,\n",
       "           6.5365e-03,  7.4042e-03, -1.6877e-02, -2.7708e-02, -4.1397e-03,\n",
       "          -6.5539e-03, -2.3584e-02,  1.2842e-02,  1.8207e-03, -1.0670e-02,\n",
       "           2.6030e-02,  1.6527e-02, -3.6295e-03, -1.8198e-03, -1.8358e-02,\n",
       "          -6.6821e-03,  2.7893e-02,  8.8896e-03,  1.8456e-02, -1.7720e-02,\n",
       "           2.0459e-02, -2.6718e-02,  2.3176e-02, -7.7618e-03, -5.6240e-03,\n",
       "          -1.1594e-02, -1.0936e-02,  1.8814e-02,  2.3569e-02, -1.8328e-03,\n",
       "          -2.5370e-02,  2.4978e-02, -2.2014e-02, -1.2841e-02,  1.3322e-02,\n",
       "           1.8449e-02,  2.1203e-02, -2.0540e-02, -1.3596e-02, -1.7334e-03,\n",
       "          -6.1550e-03, -1.0693e-02,  2.7325e-02,  2.6433e-03, -3.4705e-03,\n",
       "          -2.1634e-02,  1.7428e-02, -8.9410e-03, -1.6053e-02, -3.4265e-03,\n",
       "           1.1685e-02, -2.8158e-03,  2.3617e-02,  1.1417e-03, -1.0434e-02],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0259, -0.0274, -0.0050,  ...,  0.0020, -0.0360, -0.0349],\n",
       "          [-0.0165, -0.0157,  0.0107,  ...,  0.0074, -0.0026,  0.0091],\n",
       "          [ 0.0152,  0.0391, -0.0177,  ..., -0.0140, -0.0275, -0.0262],\n",
       "          ...,\n",
       "          [-0.0227, -0.0190,  0.0264,  ..., -0.0227, -0.0117, -0.0229],\n",
       "          [ 0.0137,  0.0116, -0.0346,  ...,  0.0040, -0.0251,  0.0145],\n",
       "          [-0.0374,  0.0021,  0.0039,  ..., -0.0150, -0.0054,  0.0283]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.0132,  0.0173,  0.0264,  0.0163, -0.0315, -0.0126,  0.0216, -0.0228],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-6.6011e-03, -9.2802e-03,  2.2120e-02,  ...,  3.9904e-03,\n",
       "            2.1890e-03,  3.2934e-02],\n",
       "          [ 1.6203e-02,  6.9712e-03,  1.5101e-02,  ...,  1.2870e-03,\n",
       "           -2.2574e-02, -6.5349e-03],\n",
       "          [ 1.2296e-02,  1.9652e-06,  2.6697e-03,  ..., -1.3935e-02,\n",
       "            3.1758e-02,  2.7253e-04],\n",
       "          ...,\n",
       "          [ 1.4831e-02,  1.3456e-03,  1.4230e-02,  ..., -2.2994e-02,\n",
       "            1.9393e-02, -2.5357e-03],\n",
       "          [-1.8661e-02,  1.8842e-02,  1.1099e-02,  ..., -9.5682e-03,\n",
       "           -4.4905e-05, -6.0539e-03],\n",
       "          [-2.1159e-02, -5.6798e-03, -2.2693e-02,  ..., -5.2728e-03,\n",
       "            5.1368e-03, -4.1322e-03]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0200,  0.0040, -0.0195,  ...,  0.0010, -0.0194, -0.0250],\n",
       "          [-0.0087, -0.0057,  0.0165,  ..., -0.0241, -0.0035, -0.0074],\n",
       "          [ 0.0168, -0.0234,  0.0191,  ..., -0.0074,  0.0006, -0.0129],\n",
       "          ...,\n",
       "          [ 0.0069, -0.0126,  0.0052,  ..., -0.0187, -0.0338, -0.0200],\n",
       "          [ 0.0250, -0.0086,  0.0338,  ..., -0.0203,  0.0128, -0.0034],\n",
       "          [-0.0122,  0.0059, -0.0031,  ..., -0.0079, -0.0061,  0.0141]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0081,  0.0236,  0.0153,  ..., -0.0010, -0.0058, -0.0035],\n",
       "          [ 0.0098, -0.0034, -0.0041,  ..., -0.0012,  0.0058,  0.0008],\n",
       "          [ 0.0305,  0.0070,  0.0140,  ...,  0.0072, -0.0088, -0.0120],\n",
       "          ...,\n",
       "          [ 0.0171,  0.0312, -0.0072,  ...,  0.0010, -0.0192,  0.0040],\n",
       "          [ 0.0329,  0.0218,  0.0279,  ..., -0.0111,  0.0135,  0.0028],\n",
       "          [ 0.0138, -0.0008, -0.0162,  ..., -0.0215,  0.0064,  0.0058]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0086,  0.0236, -0.0224,  ..., -0.0182, -0.0047,  0.0349],\n",
       "          [ 0.0142, -0.0099, -0.0114,  ...,  0.0056, -0.0132, -0.0022],\n",
       "          [ 0.0224,  0.0210, -0.0059,  ..., -0.0105, -0.0098,  0.0203],\n",
       "          ...,\n",
       "          [ 0.0114,  0.0192,  0.0184,  ..., -0.0026, -0.0017,  0.0210],\n",
       "          [ 0.0106,  0.0009,  0.0277,  ...,  0.0039,  0.0228, -0.0298],\n",
       "          [ 0.0170,  0.0005, -0.0196,  ...,  0.0210, -0.0166, -0.0246]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0013, -0.0207,  0.0229,  ..., -0.0056, -0.0225,  0.0204],\n",
       "          [ 0.0126, -0.0009, -0.0228,  ...,  0.0142, -0.0013,  0.0069],\n",
       "          [ 0.0061,  0.0117,  0.0020,  ...,  0.0083, -0.0122,  0.0261],\n",
       "          ...,\n",
       "          [ 0.0228,  0.0153, -0.0242,  ...,  0.0254, -0.0219, -0.0033],\n",
       "          [-0.0228, -0.0012,  0.0242,  ...,  0.0114, -0.0065,  0.0272],\n",
       "          [ 0.0175,  0.0137, -0.0227,  ..., -0.0114,  0.0204, -0.0072]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 1.3172e-02, -1.6031e-02, -2.1646e-02,  5.6617e-03,  1.3810e-02,\n",
       "           1.6516e-02,  1.7304e-02, -2.3981e-02,  1.1652e-02, -5.1903e-03,\n",
       "          -2.7369e-02,  5.1743e-03, -2.7156e-02,  2.0151e-02,  2.6194e-02,\n",
       "          -1.5427e-02,  3.9881e-03,  3.9722e-04,  1.8335e-02,  2.7631e-02,\n",
       "           2.4868e-03, -1.7822e-02,  1.0211e-03, -1.1691e-02, -2.1930e-02,\n",
       "          -8.8172e-03,  1.7691e-02, -1.0380e-03,  2.5235e-02,  2.7241e-02,\n",
       "           2.3688e-02,  8.3237e-03, -1.8899e-03,  5.4689e-03, -2.0603e-02,\n",
       "          -6.2091e-03, -1.7507e-02,  2.4826e-02,  1.5225e-03, -7.7369e-03,\n",
       "          -1.1827e-02, -2.1480e-02, -2.2134e-02, -2.5322e-02, -2.0047e-02,\n",
       "          -7.5878e-04,  1.3873e-02, -6.4256e-03, -2.0195e-02, -2.5907e-02,\n",
       "          -2.1579e-02, -4.5859e-03,  1.2052e-04, -1.7910e-02, -4.4909e-03,\n",
       "           2.3516e-02, -2.2651e-02, -2.0822e-02,  1.5283e-02, -4.4919e-04,\n",
       "          -1.9053e-02, -2.6374e-02,  2.2055e-02, -5.7059e-03, -2.0750e-02,\n",
       "          -2.6250e-02, -2.4876e-02, -8.9080e-03,  1.2208e-02,  1.8745e-02,\n",
       "          -3.4780e-03,  1.1477e-02, -1.6650e-02, -2.9863e-03,  4.4858e-03,\n",
       "           1.4000e-02, -1.4440e-02, -1.4961e-02,  1.5288e-02,  1.6498e-02,\n",
       "          -2.5124e-02, -1.9128e-02,  1.3052e-02,  1.4349e-02,  8.9146e-03,\n",
       "          -1.1313e-03,  1.1844e-02,  2.4449e-02,  2.5866e-02, -1.8649e-02,\n",
       "          -1.0593e-02,  1.4843e-02,  1.8823e-02,  6.3591e-03, -1.2403e-02,\n",
       "          -2.1982e-02, -1.8347e-02,  4.6742e-03,  2.2036e-02,  1.8164e-02,\n",
       "          -1.8011e-02,  7.1043e-03, -7.8734e-03,  1.9858e-02,  2.0560e-02,\n",
       "          -2.3710e-03,  1.0965e-02,  1.5271e-02,  2.6910e-02, -1.3522e-02,\n",
       "           9.5599e-03, -7.7758e-03, -2.0635e-02,  1.2820e-02,  1.1074e-02,\n",
       "          -4.3722e-03,  1.9824e-02,  1.1767e-02,  1.0343e-02,  1.8427e-02,\n",
       "          -1.4044e-02, -2.3149e-02, -5.6036e-03, -1.6813e-02, -2.0805e-02,\n",
       "           1.2797e-02, -6.4658e-03,  1.7528e-02, -2.0832e-04,  4.3917e-03,\n",
       "           9.0561e-03, -2.1113e-02, -1.7143e-02,  2.4436e-02,  3.6347e-03,\n",
       "           1.7875e-02, -2.3138e-02,  1.4976e-02, -1.4661e-02,  6.3016e-03,\n",
       "           1.3904e-02,  6.8404e-03,  1.7256e-03,  9.6720e-03,  2.1109e-02,\n",
       "           2.2157e-02,  2.2243e-02, -1.2449e-02,  3.7160e-03, -1.1782e-02,\n",
       "          -2.3076e-02, -1.6473e-02,  1.7204e-02, -2.2417e-02, -3.1342e-03,\n",
       "           2.7592e-02, -1.7260e-02, -1.4248e-02, -4.3893e-03, -1.9811e-02,\n",
       "          -8.5020e-03,  1.4508e-02, -1.3922e-02, -6.1457e-03, -5.7441e-03,\n",
       "           2.1715e-02, -1.4307e-02, -7.7543e-03, -1.4864e-02,  7.2836e-03,\n",
       "           1.7242e-02, -2.3129e-02,  3.7304e-03,  1.1419e-02, -2.5781e-03,\n",
       "           9.9059e-04,  5.9661e-03, -2.0639e-02, -8.7113e-03, -7.6264e-03,\n",
       "          -1.8413e-02, -8.2761e-03, -4.5837e-03,  1.8426e-02,  1.3325e-03,\n",
       "           1.6416e-02,  2.6482e-02,  1.5103e-02,  1.6612e-02, -6.8706e-03,\n",
       "          -2.4295e-02, -7.6319e-03,  1.5445e-02,  2.7063e-02,  1.5271e-02,\n",
       "           2.4558e-02, -1.4590e-02, -1.4943e-02, -4.0888e-04, -1.0146e-02,\n",
       "           6.8042e-03, -1.3885e-02, -1.2280e-02, -2.4175e-02, -2.4937e-02,\n",
       "           1.0467e-03,  3.5420e-03, -2.6877e-04, -1.1162e-02,  2.0570e-02,\n",
       "           1.2096e-02,  4.0784e-03, -2.4566e-02, -2.0503e-02,  3.6796e-03,\n",
       "          -1.7570e-02, -2.0197e-03,  1.8421e-02,  7.8572e-03,  1.5962e-02,\n",
       "          -1.8250e-02,  7.9569e-03, -8.9643e-03, -2.4114e-02, -2.0782e-02,\n",
       "           1.2570e-02, -5.9697e-03, -1.2139e-02,  2.0172e-02, -2.7605e-02,\n",
       "           2.5115e-02, -4.0696e-03, -8.5878e-03, -2.1951e-02, -3.3082e-03,\n",
       "           3.1858e-03,  1.0683e-02,  2.7131e-02,  2.3884e-02, -7.9833e-03,\n",
       "          -2.2887e-03, -2.0649e-02, -1.8911e-02,  3.0612e-03,  2.4186e-02,\n",
       "          -4.5434e-03, -1.8167e-02,  9.5576e-03, -2.1343e-02,  7.0386e-03,\n",
       "          -1.2388e-03, -2.6702e-02,  2.1045e-03, -9.7381e-04,  1.7693e-02,\n",
       "           1.3244e-02, -2.0088e-02, -5.8595e-03, -1.9979e-02, -1.3721e-02,\n",
       "           2.0529e-02,  1.1204e-03,  1.2602e-02, -2.7683e-02, -1.4445e-02,\n",
       "          -1.3417e-02, -2.7213e-02,  5.5242e-03,  5.1394e-03, -2.4631e-02,\n",
       "           1.4038e-02, -1.0094e-02,  2.4140e-02, -1.7616e-02, -2.2319e-02,\n",
       "          -2.7407e-03, -6.5545e-03,  3.2792e-03, -1.8127e-02, -2.2580e-02,\n",
       "           5.2965e-04,  5.9651e-03,  3.6637e-03, -5.6038e-03, -2.2780e-03,\n",
       "          -2.9334e-03,  2.2168e-02,  1.3742e-02,  2.4539e-02,  2.7490e-02,\n",
       "          -2.5926e-02,  6.5114e-04, -2.1243e-02,  1.2023e-02,  8.8647e-03,\n",
       "          -5.0938e-03, -1.4649e-02,  9.6077e-03,  2.3269e-02,  1.0871e-02,\n",
       "          -1.0803e-02,  2.4747e-02, -1.6520e-02,  1.2551e-02, -1.3069e-02,\n",
       "          -2.5467e-02, -1.0839e-02,  9.6875e-03, -9.7153e-03, -1.2242e-02,\n",
       "           1.7778e-02, -2.7173e-02,  6.7468e-03,  1.0347e-02, -6.5019e-03,\n",
       "          -7.9012e-03, -1.5025e-02, -1.8612e-02,  7.6913e-05, -2.5572e-02,\n",
       "          -1.6384e-02, -5.9049e-03, -1.2863e-02,  8.5854e-03, -2.3205e-02,\n",
       "          -2.7476e-02, -8.6537e-03, -4.8803e-03, -2.4459e-02,  1.5143e-02,\n",
       "           1.3992e-02,  1.1205e-03, -6.9604e-03,  2.6639e-02,  2.0370e-02,\n",
       "           2.2611e-05,  2.1146e-02,  2.4777e-02, -6.5556e-03,  2.0891e-02,\n",
       "           1.0403e-02, -2.7838e-02,  2.6492e-02, -2.2911e-02, -7.2405e-03,\n",
       "          -2.5704e-03, -9.0684e-03,  3.1765e-03, -2.0703e-02, -6.3928e-03,\n",
       "           1.4391e-02, -1.2544e-02,  1.7731e-02,  1.6717e-02,  1.7143e-02,\n",
       "           6.9772e-03, -2.0507e-02,  2.7197e-02, -4.5257e-03,  4.3483e-03,\n",
       "          -1.6772e-02, -2.6458e-02,  1.8822e-02,  2.9799e-03,  2.2022e-02,\n",
       "          -1.2150e-02, -1.4422e-02, -2.4464e-02,  1.6507e-02,  2.5497e-03,\n",
       "          -1.6631e-02,  1.7667e-02, -1.9790e-02,  4.0009e-04,  1.2975e-02,\n",
       "           1.1001e-04, -2.6711e-02,  9.9078e-03, -2.7366e-02,  2.5849e-03,\n",
       "          -2.4591e-02, -2.4338e-02,  1.8421e-02, -2.4825e-02,  1.9093e-02,\n",
       "          -2.2313e-02,  5.1408e-03, -2.5083e-02, -9.7705e-04, -2.2855e-04,\n",
       "           1.8152e-02, -1.0430e-02, -4.2847e-03, -8.8074e-04, -2.1005e-02,\n",
       "          -1.1029e-02, -6.4063e-03, -5.4359e-03, -3.4309e-03, -8.5549e-04,\n",
       "           1.1051e-02,  1.4779e-02, -2.7120e-02,  6.1884e-04,  1.4092e-02,\n",
       "          -1.3979e-02, -2.7231e-02, -1.0384e-02, -1.6831e-02,  1.3214e-02,\n",
       "          -1.9874e-02, -1.5133e-02,  7.5625e-03, -2.3363e-02, -1.8367e-02,\n",
       "          -6.6482e-03,  4.0903e-03, -2.1996e-02,  1.3960e-02, -6.7504e-03,\n",
       "          -2.5497e-02,  2.6025e-02,  1.1802e-02, -2.2803e-03,  9.6574e-03,\n",
       "           2.0258e-02, -1.8784e-02, -2.1096e-02, -1.7819e-03, -5.1764e-03,\n",
       "          -1.8802e-02, -7.8238e-03,  2.6509e-02, -1.7313e-02, -2.6816e-02,\n",
       "           5.5157e-03,  1.3675e-02, -2.6093e-02, -6.3876e-04,  2.2563e-02,\n",
       "           2.3126e-02,  2.7315e-02,  2.2041e-02,  1.9357e-02, -1.1401e-02,\n",
       "          -2.7504e-02, -2.1129e-02, -1.0358e-02, -3.9201e-03, -2.1081e-02,\n",
       "          -2.1138e-03, -1.5652e-02, -2.7320e-02,  1.9306e-02,  3.3117e-03,\n",
       "          -2.5124e-02,  1.4243e-03, -5.5803e-03, -9.8922e-03,  7.9842e-03,\n",
       "          -4.7928e-03,  1.5338e-02,  1.6060e-02, -2.6551e-02, -1.0492e-02,\n",
       "          -1.1568e-02, -1.8601e-02,  1.0460e-02, -2.5739e-02,  1.3656e-03,\n",
       "          -2.8192e-03, -1.3114e-02, -2.0007e-02,  4.5462e-03,  3.0482e-03,\n",
       "           2.2341e-02, -1.2105e-02, -2.2294e-02, -2.5644e-02,  1.4399e-02,\n",
       "           1.2782e-02,  3.1893e-03, -1.9600e-02,  5.4026e-03, -1.4962e-02,\n",
       "          -1.4876e-02, -1.7964e-02, -7.1182e-03,  2.0489e-02, -3.9923e-04,\n",
       "          -1.8139e-02,  2.9446e-03,  1.1195e-02,  1.7425e-02,  6.1263e-03,\n",
       "           1.5031e-02,  1.2723e-02,  1.4859e-02,  4.0601e-03, -2.4504e-03,\n",
       "           5.8127e-03,  3.2810e-03, -3.1342e-03,  1.1188e-02, -1.9687e-02,\n",
       "           2.7812e-02,  3.9968e-03, -1.9665e-03,  4.5765e-03,  2.7544e-02,\n",
       "          -2.3056e-03, -7.4200e-03,  1.6637e-02, -2.7975e-03,  1.6210e-02,\n",
       "           2.3789e-03, -1.9196e-02,  5.1835e-03, -2.7592e-02, -8.8578e-03,\n",
       "           5.0033e-03, -2.9414e-03,  1.4524e-02, -2.5435e-03,  5.5123e-03,\n",
       "           1.6475e-02, -2.4602e-03, -1.2051e-02, -2.7193e-02, -7.3520e-03,\n",
       "           2.0751e-03,  8.8417e-03, -2.5411e-02,  1.2229e-02, -2.3863e-02,\n",
       "           1.8689e-02, -1.3620e-02, -2.1211e-02, -1.4685e-02,  2.6027e-02,\n",
       "          -9.4894e-03,  1.2304e-02,  1.7880e-02, -2.0472e-02,  1.5462e-02,\n",
       "           1.6506e-02,  1.6464e-02, -8.4625e-03, -1.0216e-02, -1.0062e-02,\n",
       "           1.4845e-02, -4.4445e-03, -2.4541e-02,  1.1394e-02, -6.4779e-03,\n",
       "           3.5474e-03, -1.7113e-02,  1.0006e-02, -1.8091e-02, -4.1763e-03,\n",
       "          -2.5278e-02, -5.2761e-03, -1.0971e-02,  8.4815e-03,  1.2114e-03,\n",
       "          -1.6965e-02,  1.1659e-03, -1.6851e-02, -2.0037e-02,  1.5294e-02,\n",
       "           2.2800e-02, -2.4599e-02, -2.4999e-02,  9.8574e-03, -3.6131e-03,\n",
       "          -2.2610e-02,  9.7187e-03,  2.0498e-02,  9.0436e-03,  1.6402e-02,\n",
       "          -1.5429e-02, -2.3139e-02, -1.8306e-02,  5.8208e-03,  2.1259e-02,\n",
       "           2.3373e-02,  9.0517e-03,  1.5011e-02, -5.1542e-03, -2.3194e-05,\n",
       "          -1.8547e-02,  1.7787e-02,  5.7872e-03, -6.1631e-03,  5.1706e-03,\n",
       "           1.7133e-02, -3.4990e-03, -1.7398e-02, -2.4484e-02, -7.9910e-03,\n",
       "           2.1731e-02, -1.3431e-02,  1.0439e-02,  2.6733e-02, -9.9234e-03,\n",
       "          -9.0147e-03,  2.1453e-02,  1.0262e-03, -1.6355e-02, -1.7144e-02,\n",
       "           1.3428e-02,  3.2970e-04, -1.3826e-03, -8.1610e-03, -1.4942e-02,\n",
       "           2.5965e-02,  7.3132e-03,  5.3673e-03, -1.7848e-02, -1.3139e-02,\n",
       "           2.6999e-02, -1.8219e-02,  3.1108e-03, -7.2262e-03,  1.7327e-02,\n",
       "          -1.4543e-02, -1.9928e-02,  7.8311e-03,  1.3443e-02,  2.3366e-02,\n",
       "           5.0577e-03, -1.0253e-02,  1.7562e-02,  1.4088e-02,  2.1852e-03,\n",
       "          -2.2898e-03, -8.9906e-03, -1.5901e-02,  2.5837e-02, -1.3620e-02],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0194, -0.0273, -0.0128,  ..., -0.0133,  0.0340, -0.0286],\n",
       "          [-0.0090,  0.0116,  0.0080,  ...,  0.0298,  0.0231, -0.0186],\n",
       "          [ 0.0288, -0.0215, -0.0145,  ...,  0.0249, -0.0209,  0.0013],\n",
       "          ...,\n",
       "          [-0.0158, -0.0029,  0.0123,  ..., -0.0378, -0.0314, -0.0004],\n",
       "          [ 0.0297, -0.0206,  0.0077,  ...,  0.0041,  0.0227,  0.0123],\n",
       "          [-0.0373,  0.0007,  0.0177,  ..., -0.0380,  0.0135,  0.0310]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0293, -0.0285,  0.0174,  0.0133,  0.0242, -0.0206,  0.0007,  0.0234],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0042,  0.0113,  0.0014,  ...,  0.0160,  0.0171,  0.0043],\n",
       "          [ 0.0105, -0.0080,  0.0377,  ..., -0.0333,  0.0196, -0.0320],\n",
       "          [ 0.0293, -0.0034,  0.0276,  ...,  0.0134, -0.0107, -0.0057],\n",
       "          ...,\n",
       "          [-0.0087, -0.0209,  0.0134,  ..., -0.0238,  0.0014,  0.0043],\n",
       "          [-0.0119, -0.0312, -0.0031,  ..., -0.0222,  0.0133, -0.0137],\n",
       "          [ 0.0033, -0.0318, -0.0155,  ...,  0.0128,  0.0277,  0.0067]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0178,  0.0161, -0.0005,  ..., -0.0039, -0.0040, -0.0024],\n",
       "          [ 0.0220,  0.0044, -0.0096,  ..., -0.0187,  0.0054, -0.0098],\n",
       "          [-0.0069, -0.0029, -0.0598,  ..., -0.0035, -0.0063,  0.0075],\n",
       "          ...,\n",
       "          [-0.0131, -0.0019,  0.0425,  ...,  0.0147, -0.0151,  0.0060],\n",
       "          [-0.0016, -0.0277, -0.0065,  ...,  0.0017,  0.0010,  0.0131],\n",
       "          [-0.0027,  0.0094,  0.0153,  ...,  0.0054,  0.0030, -0.0203]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0008,  0.0041, -0.0130,  ...,  0.0037,  0.0137,  0.0097],\n",
       "          [-0.0132,  0.0123,  0.0011,  ..., -0.0114,  0.0030, -0.0059],\n",
       "          [-0.0180,  0.0003,  0.0039,  ..., -0.0263,  0.0099, -0.0132],\n",
       "          ...,\n",
       "          [ 0.0043, -0.0038,  0.0315,  ...,  0.0225, -0.0037, -0.0173],\n",
       "          [ 0.0142, -0.0041, -0.0009,  ..., -0.0094,  0.0259,  0.0156],\n",
       "          [ 0.0065, -0.0105,  0.0058,  ..., -0.0184, -0.0238,  0.0095]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0074,  0.0236,  0.0242,  ...,  0.0198, -0.0289,  0.0104],\n",
       "          [-0.0156,  0.0341,  0.0089,  ..., -0.0074,  0.0101, -0.0117],\n",
       "          [-0.0215, -0.0008, -0.0005,  ...,  0.0056,  0.0119, -0.0017],\n",
       "          ...,\n",
       "          [-0.0006,  0.0250,  0.0010,  ...,  0.0114, -0.0026, -0.0008],\n",
       "          [-0.0059,  0.0440,  0.0104,  ...,  0.0143,  0.0030,  0.0038],\n",
       "          [-0.0012, -0.0017,  0.0170,  ...,  0.0066,  0.0139, -0.0092]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0177, -0.0111,  0.0148,  ...,  0.0172,  0.0129, -0.0053],\n",
       "          [ 0.0114, -0.0015, -0.0006,  ...,  0.0005,  0.0111,  0.0119],\n",
       "          [-0.0156, -0.0016,  0.0031,  ..., -0.0096,  0.0161, -0.0099],\n",
       "          ...,\n",
       "          [-0.0242, -0.0201, -0.0209,  ..., -0.0222,  0.0184, -0.0079],\n",
       "          [ 0.0188, -0.0047, -0.0269,  ..., -0.0238, -0.0240, -0.0037],\n",
       "          [ 0.0040,  0.0127, -0.0089,  ..., -0.0151, -0.0198, -0.0207]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.0177,  0.0116,  0.0016,  0.0017, -0.0227, -0.0154, -0.0150, -0.0090,\n",
       "           0.0207, -0.0081, -0.0155,  0.0171,  0.0036,  0.0151, -0.0014, -0.0165,\n",
       "           0.0111, -0.0144,  0.0241,  0.0236, -0.0100,  0.0027, -0.0205,  0.0181,\n",
       "           0.0253,  0.0060, -0.0201,  0.0105, -0.0224,  0.0257, -0.0111,  0.0173,\n",
       "          -0.0046,  0.0113, -0.0153, -0.0139, -0.0025, -0.0227, -0.0124, -0.0222,\n",
       "          -0.0202,  0.0023, -0.0008, -0.0061,  0.0246, -0.0083, -0.0240, -0.0084,\n",
       "          -0.0148, -0.0131,  0.0261, -0.0253, -0.0082, -0.0086,  0.0189, -0.0153,\n",
       "          -0.0136,  0.0205,  0.0132,  0.0248,  0.0236,  0.0202,  0.0116, -0.0156,\n",
       "          -0.0066,  0.0026, -0.0183, -0.0113, -0.0151,  0.0088, -0.0257, -0.0105,\n",
       "          -0.0137, -0.0093, -0.0141, -0.0181,  0.0181,  0.0237, -0.0178, -0.0140,\n",
       "           0.0206,  0.0194, -0.0127,  0.0207,  0.0098, -0.0017,  0.0060,  0.0255,\n",
       "          -0.0150, -0.0108, -0.0078,  0.0139, -0.0073, -0.0212,  0.0149,  0.0043,\n",
       "          -0.0055,  0.0137,  0.0185,  0.0213, -0.0099, -0.0130,  0.0023, -0.0201,\n",
       "           0.0137, -0.0262, -0.0032,  0.0247, -0.0246,  0.0279,  0.0144,  0.0033,\n",
       "          -0.0157, -0.0054,  0.0246,  0.0264,  0.0191,  0.0194,  0.0228,  0.0118,\n",
       "           0.0148,  0.0087,  0.0176,  0.0064, -0.0102, -0.0124,  0.0079,  0.0173,\n",
       "           0.0251,  0.0236, -0.0153,  0.0180,  0.0100, -0.0129, -0.0141, -0.0082,\n",
       "           0.0237,  0.0071, -0.0199, -0.0252,  0.0175, -0.0003,  0.0092, -0.0147,\n",
       "          -0.0276, -0.0126, -0.0254,  0.0065, -0.0040, -0.0036,  0.0006, -0.0161,\n",
       "           0.0204,  0.0080, -0.0061,  0.0236, -0.0163,  0.0123,  0.0114,  0.0234,\n",
       "          -0.0131, -0.0165, -0.0209, -0.0170, -0.0068, -0.0049,  0.0090,  0.0009,\n",
       "           0.0235,  0.0032,  0.0078, -0.0084,  0.0259,  0.0133,  0.0255, -0.0011,\n",
       "          -0.0167, -0.0258, -0.0051, -0.0138, -0.0262,  0.0054,  0.0239, -0.0138,\n",
       "          -0.0047, -0.0114,  0.0023,  0.0081, -0.0018,  0.0267,  0.0131, -0.0067,\n",
       "          -0.0009, -0.0110, -0.0246,  0.0064, -0.0126, -0.0172,  0.0029,  0.0275,\n",
       "           0.0205,  0.0261,  0.0006,  0.0075,  0.0275,  0.0257, -0.0138,  0.0048,\n",
       "          -0.0093,  0.0160, -0.0084, -0.0050, -0.0209, -0.0255, -0.0213, -0.0175,\n",
       "          -0.0066,  0.0210,  0.0250,  0.0236,  0.0266, -0.0185, -0.0100,  0.0186,\n",
       "           0.0244, -0.0279, -0.0161, -0.0003, -0.0053, -0.0102, -0.0029, -0.0156,\n",
       "          -0.0126,  0.0165, -0.0219, -0.0167,  0.0056, -0.0275,  0.0005, -0.0163,\n",
       "          -0.0239, -0.0010,  0.0166,  0.0278, -0.0239,  0.0142,  0.0092, -0.0160,\n",
       "          -0.0039,  0.0212,  0.0161, -0.0160,  0.0128,  0.0210,  0.0072,  0.0264,\n",
       "          -0.0120, -0.0183, -0.0206, -0.0201, -0.0085, -0.0061,  0.0263, -0.0095,\n",
       "          -0.0167, -0.0092,  0.0037, -0.0058, -0.0265,  0.0149, -0.0120,  0.0006,\n",
       "          -0.0126,  0.0063, -0.0179, -0.0098, -0.0025, -0.0090, -0.0029,  0.0149,\n",
       "          -0.0057, -0.0128,  0.0233,  0.0204,  0.0171,  0.0220, -0.0273,  0.0199,\n",
       "          -0.0251,  0.0005, -0.0229, -0.0269,  0.0244, -0.0097, -0.0275,  0.0163,\n",
       "          -0.0180, -0.0199,  0.0018,  0.0070, -0.0152,  0.0054,  0.0244, -0.0107,\n",
       "           0.0223, -0.0085, -0.0177, -0.0182, -0.0256, -0.0165, -0.0166,  0.0248,\n",
       "          -0.0269,  0.0211,  0.0081, -0.0062,  0.0157,  0.0127, -0.0225,  0.0022,\n",
       "          -0.0205, -0.0105,  0.0069,  0.0198, -0.0275, -0.0030,  0.0244, -0.0162,\n",
       "           0.0002,  0.0074,  0.0061, -0.0250, -0.0035, -0.0184, -0.0276,  0.0068,\n",
       "           0.0119,  0.0241, -0.0121, -0.0273, -0.0032, -0.0279, -0.0053, -0.0223,\n",
       "          -0.0131,  0.0196,  0.0194,  0.0278, -0.0212,  0.0189, -0.0237, -0.0160,\n",
       "           0.0116,  0.0045,  0.0153,  0.0239, -0.0053,  0.0078,  0.0163, -0.0091,\n",
       "          -0.0066,  0.0235, -0.0010, -0.0143,  0.0112,  0.0230,  0.0196, -0.0063,\n",
       "          -0.0275,  0.0203, -0.0236, -0.0031, -0.0194, -0.0256,  0.0145,  0.0234,\n",
       "           0.0094,  0.0098, -0.0166, -0.0191,  0.0026,  0.0001,  0.0189, -0.0133,\n",
       "           0.0051, -0.0073, -0.0119, -0.0163,  0.0009, -0.0070, -0.0108, -0.0007,\n",
       "           0.0124,  0.0219, -0.0250, -0.0039,  0.0177, -0.0199, -0.0097,  0.0140,\n",
       "           0.0123,  0.0253, -0.0011, -0.0008,  0.0089,  0.0218,  0.0261, -0.0169,\n",
       "           0.0046,  0.0020,  0.0277,  0.0214,  0.0071, -0.0068,  0.0012,  0.0173,\n",
       "           0.0261, -0.0082,  0.0222, -0.0266,  0.0032,  0.0213, -0.0172,  0.0200,\n",
       "           0.0058,  0.0106, -0.0142,  0.0113,  0.0121, -0.0119,  0.0050, -0.0190,\n",
       "          -0.0098,  0.0132,  0.0127,  0.0054, -0.0185,  0.0092, -0.0105, -0.0142,\n",
       "          -0.0041, -0.0206,  0.0244, -0.0034,  0.0027,  0.0165,  0.0037, -0.0147,\n",
       "           0.0238,  0.0191,  0.0107, -0.0181, -0.0144, -0.0229, -0.0045, -0.0114,\n",
       "           0.0167,  0.0162, -0.0094,  0.0246, -0.0027, -0.0214,  0.0106,  0.0156,\n",
       "           0.0025,  0.0057,  0.0245, -0.0255, -0.0215, -0.0212, -0.0138,  0.0031,\n",
       "           0.0086,  0.0076, -0.0013,  0.0131,  0.0014,  0.0023,  0.0021,  0.0256,\n",
       "           0.0160, -0.0117,  0.0201,  0.0188, -0.0224,  0.0104,  0.0059, -0.0274,\n",
       "          -0.0186, -0.0230,  0.0151, -0.0205, -0.0084,  0.0192,  0.0041,  0.0120,\n",
       "           0.0246,  0.0109,  0.0109,  0.0118,  0.0245,  0.0076,  0.0274, -0.0051,\n",
       "           0.0135,  0.0195,  0.0078,  0.0169, -0.0276,  0.0015, -0.0201, -0.0173,\n",
       "           0.0084,  0.0113,  0.0060, -0.0208,  0.0204,  0.0017,  0.0108,  0.0113,\n",
       "           0.0089,  0.0146,  0.0162, -0.0265, -0.0206,  0.0239, -0.0130,  0.0113,\n",
       "          -0.0183, -0.0170,  0.0266,  0.0279, -0.0021, -0.0277, -0.0269,  0.0230,\n",
       "          -0.0118,  0.0203, -0.0261,  0.0273, -0.0262, -0.0022,  0.0242,  0.0267,\n",
       "          -0.0249,  0.0256,  0.0011,  0.0034, -0.0010,  0.0071, -0.0234, -0.0134,\n",
       "          -0.0051,  0.0218, -0.0265, -0.0060, -0.0219,  0.0217,  0.0138,  0.0071,\n",
       "          -0.0039, -0.0275, -0.0087, -0.0010,  0.0213, -0.0034, -0.0272,  0.0218,\n",
       "           0.0238, -0.0239, -0.0142,  0.0076, -0.0155,  0.0121,  0.0140,  0.0014,\n",
       "          -0.0245, -0.0171, -0.0277,  0.0238, -0.0279, -0.0069,  0.0125, -0.0059,\n",
       "          -0.0074,  0.0129,  0.0003,  0.0277, -0.0152,  0.0204,  0.0008, -0.0100,\n",
       "           0.0217, -0.0135, -0.0018, -0.0233,  0.0251,  0.0240, -0.0126,  0.0080,\n",
       "           0.0105,  0.0059, -0.0234, -0.0248,  0.0131, -0.0146, -0.0090,  0.0261,\n",
       "           0.0104,  0.0253, -0.0162,  0.0093, -0.0088, -0.0226, -0.0257,  0.0002,\n",
       "          -0.0074, -0.0151,  0.0199,  0.0231, -0.0237,  0.0004, -0.0100,  0.0038,\n",
       "          -0.0019,  0.0028,  0.0114, -0.0215, -0.0162, -0.0021,  0.0039, -0.0001,\n",
       "           0.0187, -0.0006, -0.0265, -0.0260, -0.0025, -0.0034, -0.0120,  0.0276],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0380, -0.0221, -0.0209,  ...,  0.0225, -0.0179,  0.0147],\n",
       "          [-0.0159, -0.0096,  0.0078,  ...,  0.0318, -0.0265,  0.0107],\n",
       "          [ 0.0346,  0.0030, -0.0101,  ...,  0.0169, -0.0223, -0.0329],\n",
       "          ...,\n",
       "          [-0.0034,  0.0298,  0.0244,  ..., -0.0300, -0.0121,  0.0056],\n",
       "          [-0.0392,  0.0051, -0.0002,  ..., -0.0149, -0.0195, -0.0261],\n",
       "          [-0.0375, -0.0120, -0.0104,  ..., -0.0148,  0.0369,  0.0076]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.0295,  0.0289, -0.0147, -0.0383,  0.0302, -0.0298, -0.0333, -0.0307],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0184, -0.0183,  0.0105,  ..., -0.0147,  0.0239, -0.0079],\n",
       "          [ 0.0148,  0.0039, -0.0201,  ...,  0.0061,  0.0141,  0.0061],\n",
       "          [-0.0360,  0.0184,  0.0118,  ...,  0.0018, -0.0070,  0.0006],\n",
       "          ...,\n",
       "          [ 0.0204,  0.0128,  0.0163,  ..., -0.0067, -0.0050, -0.0085],\n",
       "          [-0.0283, -0.0119, -0.0073,  ...,  0.0012,  0.0192,  0.0082],\n",
       "          [ 0.0249, -0.0212,  0.0203,  ..., -0.0007,  0.0006, -0.0090]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0024,  0.0004, -0.0059,  ..., -0.0168,  0.0085, -0.0054],\n",
       "          [-0.0198, -0.0114, -0.0015,  ..., -0.0091,  0.0229,  0.0044],\n",
       "          [ 0.0078,  0.0202, -0.0140,  ...,  0.0021,  0.0072,  0.0044],\n",
       "          ...,\n",
       "          [-0.0192,  0.0419,  0.0039,  ..., -0.0010,  0.0355, -0.0215],\n",
       "          [ 0.0046,  0.0043,  0.0304,  ..., -0.0106,  0.0103, -0.0308],\n",
       "          [-0.0029,  0.0050,  0.0167,  ..., -0.0139, -0.0055,  0.0006]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0050, -0.0094, -0.0102,  ...,  0.0296,  0.0096, -0.0085],\n",
       "          [-0.0056,  0.0116,  0.0377,  ..., -0.0161, -0.0207,  0.0155],\n",
       "          [-0.0328, -0.0081, -0.0074,  ..., -0.0186,  0.0025,  0.0216],\n",
       "          ...,\n",
       "          [-0.0109, -0.0036,  0.0235,  ...,  0.0201, -0.0116,  0.0032],\n",
       "          [ 0.0074,  0.0059, -0.0129,  ...,  0.0168,  0.0163, -0.0127],\n",
       "          [ 0.0210,  0.0043, -0.0042,  ...,  0.0020, -0.0074,  0.0170]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0158,  0.0156,  0.0043,  ...,  0.0192,  0.0178, -0.0211],\n",
       "          [-0.0009, -0.0171, -0.0147,  ..., -0.0169,  0.0003, -0.0318],\n",
       "          [ 0.0095, -0.0055,  0.0112,  ...,  0.0054,  0.0167,  0.0164],\n",
       "          ...,\n",
       "          [-0.0114, -0.0086,  0.0359,  ...,  0.0150,  0.0156,  0.0094],\n",
       "          [-0.0232,  0.0053,  0.0054,  ...,  0.0132,  0.0061,  0.0016],\n",
       "          [ 0.0165, -0.0164, -0.0056,  ..., -0.0018,  0.0126, -0.0194]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-2.0213e-02, -2.3354e-02, -1.4873e-02,  ..., -2.3250e-02,\n",
       "           -4.6927e-03, -2.0701e-03],\n",
       "          [ 2.6400e-02, -4.9875e-03,  1.7606e-02,  ...,  1.1795e-02,\n",
       "           -2.1861e-02,  1.0977e-02],\n",
       "          [-6.1939e-03, -8.2666e-03,  7.3969e-03,  ..., -2.6686e-03,\n",
       "            7.2749e-03,  2.9746e-03],\n",
       "          ...,\n",
       "          [ 7.2171e-06,  1.1072e-02, -1.0721e-02,  ...,  1.3872e-02,\n",
       "            2.2561e-02, -5.6691e-03],\n",
       "          [ 5.3536e-04,  3.8843e-03, -2.0455e-03,  ..., -2.6439e-03,\n",
       "           -1.8358e-02,  8.0183e-03],\n",
       "          [-9.7014e-03,  5.2253e-03, -1.9027e-03,  ...,  2.7773e-02,\n",
       "            2.6968e-02, -4.1104e-03]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-2.3318e-02, -1.4010e-02, -2.6463e-02, -1.6641e-02, -3.7947e-03,\n",
       "          -2.4169e-02,  1.1552e-03,  2.4345e-02, -2.5979e-02,  4.4343e-03,\n",
       "           5.1517e-03,  7.7257e-03, -1.5425e-02,  2.5289e-02,  6.1012e-03,\n",
       "          -9.6370e-03, -1.5236e-03, -6.8091e-03, -1.1986e-02, -9.6062e-03,\n",
       "           1.9498e-02, -1.8035e-02, -3.8526e-03, -1.9290e-02, -6.8697e-03,\n",
       "          -1.0055e-02,  1.4006e-02, -1.3105e-02, -1.0971e-02, -2.7524e-02,\n",
       "          -1.4837e-02,  2.0763e-02,  2.1090e-02,  2.7554e-02, -4.7044e-03,\n",
       "          -1.0314e-02,  1.3574e-02, -8.4368e-03,  7.4607e-03,  6.8096e-03,\n",
       "          -2.0428e-02, -2.5202e-02,  8.4494e-03,  2.1885e-02,  1.0456e-02,\n",
       "           1.5954e-02,  2.4992e-02,  6.4173e-04,  1.8154e-02, -9.8904e-03,\n",
       "          -1.2888e-02,  3.2246e-03,  1.9159e-02, -1.4398e-02, -2.2686e-02,\n",
       "          -1.0183e-02, -2.1016e-02,  9.5533e-03,  1.2975e-02, -3.4262e-03,\n",
       "           2.2749e-02, -1.6035e-02, -2.7345e-02,  1.7403e-02, -3.1700e-03,\n",
       "          -1.6574e-02, -6.8453e-03, -1.2155e-02, -5.1060e-03,  6.7870e-03,\n",
       "          -1.5304e-02, -1.8503e-02,  9.5906e-03, -7.9594e-03, -1.6268e-02,\n",
       "           6.2043e-03,  1.8758e-02,  2.1461e-03,  2.7795e-02,  1.1009e-02,\n",
       "          -9.6239e-03, -1.2365e-03, -4.4350e-03,  5.8703e-03, -1.7563e-02,\n",
       "           2.4861e-02, -1.7072e-02,  1.4743e-02, -1.6600e-02,  5.2072e-03,\n",
       "           1.5408e-02,  2.1190e-02, -1.1589e-02, -9.1072e-03, -2.4928e-02,\n",
       "           1.0960e-02, -1.3824e-02, -2.5891e-03,  2.3634e-02,  1.7389e-02,\n",
       "           2.2501e-02,  1.2118e-02, -1.4443e-02,  4.7848e-03, -2.4666e-02,\n",
       "          -1.0184e-02,  2.0934e-02, -2.1796e-03, -5.0179e-03, -3.5273e-03,\n",
       "          -9.0642e-03,  1.0537e-02,  1.9493e-02,  1.2607e-02,  1.9074e-02,\n",
       "           2.7739e-03, -2.1425e-02, -1.0533e-02, -1.9055e-02, -9.7396e-03,\n",
       "           2.5336e-02,  2.4767e-02, -1.1899e-02, -2.4516e-02, -1.9739e-02,\n",
       "           2.4037e-02,  1.9042e-02, -2.7160e-02, -1.4823e-03, -1.7837e-02,\n",
       "          -1.4151e-03,  1.2546e-02,  6.0393e-03, -2.0433e-02,  1.1117e-02,\n",
       "           1.3915e-02, -1.9891e-02, -1.9644e-02, -6.4319e-03, -7.2706e-03,\n",
       "          -9.2593e-03,  2.0989e-02,  7.7585e-04, -4.9116e-03,  3.3344e-03,\n",
       "           1.5626e-02,  3.4371e-03, -1.1044e-02,  7.5415e-03, -1.2196e-02,\n",
       "          -2.0122e-02, -1.7289e-02, -1.6602e-02, -1.3511e-03, -1.2422e-02,\n",
       "          -7.6550e-03,  2.7473e-02,  2.3210e-02, -1.3072e-03, -9.3305e-03,\n",
       "          -1.7395e-02,  1.3707e-02,  8.6897e-04,  3.9704e-03, -1.4075e-02,\n",
       "          -7.3544e-03, -2.1765e-03,  2.7106e-02, -7.8876e-03,  1.0220e-02,\n",
       "           1.9974e-02, -1.3599e-02, -2.4800e-02,  2.6869e-02, -2.1008e-02,\n",
       "           9.5590e-03,  1.0923e-02,  5.7662e-03,  2.0765e-02, -1.8171e-02,\n",
       "           8.0529e-03,  8.8470e-03,  2.6278e-02, -1.5884e-02,  2.1367e-02,\n",
       "           2.2366e-02, -2.5802e-02,  9.9996e-03,  1.0785e-02, -8.4745e-03,\n",
       "           2.2262e-02, -1.3594e-02,  1.2601e-02,  7.4258e-03,  1.0305e-02,\n",
       "           2.4304e-02, -1.2295e-02, -1.2394e-02, -1.8016e-02, -2.5461e-02,\n",
       "           1.0524e-02, -2.5574e-02,  2.0397e-02, -1.9259e-02, -9.9346e-03,\n",
       "           2.3774e-02, -2.0611e-02, -1.3336e-02, -2.2710e-02,  1.5477e-02,\n",
       "          -2.4778e-02, -9.9847e-03, -2.0915e-02,  7.6992e-03,  1.6676e-02,\n",
       "           1.8513e-02, -2.2191e-02, -2.2222e-02, -1.5080e-02, -1.4005e-02,\n",
       "           3.9767e-03, -9.9446e-03, -1.7164e-02, -2.6556e-02,  8.5245e-03,\n",
       "          -2.9532e-03, -5.7774e-03, -5.9957e-03, -2.2528e-02, -1.5592e-02,\n",
       "          -2.2149e-03, -1.1560e-02,  5.4209e-03, -7.4830e-03,  1.5282e-02,\n",
       "           1.6957e-02,  2.0648e-02,  2.7931e-02, -5.7067e-03, -2.1508e-02,\n",
       "          -1.9446e-02,  1.5908e-02,  2.1398e-03, -1.1899e-02,  3.8690e-03,\n",
       "           2.4793e-02,  2.7456e-02, -5.3834e-04, -9.4208e-03, -1.6817e-02,\n",
       "           6.1512e-03, -3.8171e-03,  2.0921e-02,  1.2851e-02, -2.6206e-02,\n",
       "          -2.6678e-02,  1.6906e-02, -2.9379e-03, -2.2430e-02,  3.0317e-03,\n",
       "          -6.5701e-03,  2.2503e-02,  1.9358e-02,  2.3228e-02, -1.2494e-02,\n",
       "          -2.4192e-02, -7.5798e-03, -9.8046e-03,  1.6073e-02, -7.3060e-03,\n",
       "          -2.5130e-02, -6.2805e-03, -2.3645e-02, -1.2663e-02,  1.2044e-02,\n",
       "          -2.4342e-02, -6.9917e-03,  1.7307e-02,  1.8874e-02, -1.3747e-02,\n",
       "          -2.0476e-02, -2.5303e-02, -1.8620e-04,  2.6268e-02, -1.4597e-02,\n",
       "           3.9852e-03,  2.3330e-03,  2.0207e-02, -9.6027e-04, -2.1923e-02,\n",
       "          -2.1129e-02,  7.1962e-03,  2.8999e-03, -4.1237e-03,  1.3777e-02,\n",
       "           1.6814e-02, -3.9519e-03, -1.7755e-03,  1.1844e-03,  2.2065e-02,\n",
       "           1.8590e-02, -1.2271e-02, -6.9075e-03, -1.6189e-02,  1.8095e-02,\n",
       "           1.7475e-02, -1.5123e-02, -7.4063e-03,  1.2689e-02,  2.7336e-02,\n",
       "           9.2977e-03, -2.4857e-02,  1.8418e-03,  1.2628e-02, -8.5261e-03,\n",
       "          -5.5889e-03,  2.2937e-02, -1.5140e-02, -2.1571e-02, -2.3805e-02,\n",
       "          -5.4927e-03, -2.0505e-02, -1.9113e-02,  6.7466e-03,  4.3279e-03,\n",
       "           8.0638e-03,  2.5751e-02, -2.5023e-02,  1.8458e-02, -8.1180e-03,\n",
       "          -1.0831e-02,  2.2806e-02, -2.4243e-02,  2.0550e-02,  2.0974e-02,\n",
       "          -9.8637e-03,  5.6771e-03,  5.3754e-03, -9.2578e-03, -1.7277e-02,\n",
       "           2.0666e-02, -1.7188e-02, -2.4051e-03,  1.9863e-02, -1.2977e-02,\n",
       "           1.8785e-02,  2.7613e-02, -2.0686e-02,  1.2952e-02, -1.5555e-02,\n",
       "          -1.5361e-02, -1.3842e-02,  7.2685e-03, -1.2831e-02, -7.6235e-04,\n",
       "          -3.8274e-03,  1.0928e-02,  2.1058e-02, -2.1141e-02,  2.7663e-02,\n",
       "          -2.5998e-02,  2.4622e-03, -1.8287e-02, -1.2226e-03,  4.7876e-03,\n",
       "           1.2420e-02,  1.5223e-02, -2.4754e-02,  6.9011e-03,  7.0261e-03,\n",
       "          -2.4649e-02,  8.6370e-03, -1.3061e-02, -1.2721e-02, -1.6917e-02,\n",
       "          -1.6950e-02, -9.2306e-03, -1.0233e-02, -2.6193e-02,  1.3835e-02,\n",
       "          -9.1841e-03,  1.6511e-02, -1.7168e-02, -8.7047e-03, -2.3440e-02,\n",
       "           2.7821e-02,  4.8694e-03,  3.4153e-03, -1.0989e-02, -2.6717e-02,\n",
       "           2.7480e-02, -1.7901e-02, -8.6874e-03,  2.1218e-03,  7.8229e-03,\n",
       "           7.2625e-03, -4.0457e-03,  2.5648e-02, -6.2460e-03,  1.2400e-02,\n",
       "          -1.7886e-03,  1.0893e-02,  1.0492e-02,  1.1929e-02,  1.5019e-02,\n",
       "          -1.8772e-02, -2.5525e-02,  1.3974e-02,  1.1321e-02,  1.7100e-03,\n",
       "          -1.7724e-02,  2.4712e-02, -4.2404e-03,  1.1632e-02, -2.6542e-02,\n",
       "           2.0762e-02, -2.2127e-02, -9.7285e-03,  4.5655e-03, -5.4085e-03,\n",
       "           6.4450e-04, -3.6197e-03,  2.0193e-02,  1.5985e-03, -1.7593e-02,\n",
       "          -4.4974e-03,  7.1713e-03, -5.3278e-03, -4.7201e-03,  1.7429e-02,\n",
       "          -2.0456e-02, -2.6780e-02,  2.3619e-02,  2.3959e-02,  5.3297e-03,\n",
       "          -1.8527e-02,  6.4485e-03, -5.2384e-03, -1.9074e-02, -1.3472e-03,\n",
       "          -4.9581e-03, -1.5127e-02, -2.7553e-02, -2.4708e-02, -1.4378e-02,\n",
       "          -1.4563e-02, -2.2410e-02, -5.3319e-03, -1.6089e-02,  2.0015e-02,\n",
       "           4.7851e-04, -2.4902e-02, -6.8376e-04, -3.1328e-03, -2.7918e-02,\n",
       "           2.1170e-02, -6.1051e-03,  3.7424e-03, -7.9942e-03, -5.2915e-03,\n",
       "          -3.2408e-03,  2.3677e-02, -2.7827e-02, -2.6894e-02,  1.5287e-02,\n",
       "           7.1666e-03,  2.1362e-02, -6.7597e-03,  4.3567e-03,  2.1233e-02,\n",
       "          -1.4039e-02,  9.1374e-03,  1.7465e-02,  1.0430e-02,  1.4541e-02,\n",
       "          -1.3474e-02,  5.0284e-03, -2.4577e-02,  1.5194e-02, -1.9490e-02,\n",
       "          -9.6257e-04,  1.4294e-02, -4.3916e-03,  1.8622e-02,  2.3230e-02,\n",
       "          -8.4483e-03,  3.2557e-03, -5.3087e-03, -2.5233e-02,  1.6970e-02,\n",
       "           1.4576e-02, -2.2817e-02, -2.3779e-02,  6.2491e-03, -2.7342e-02,\n",
       "           1.4524e-02, -2.7403e-02,  9.8832e-03,  5.8282e-03,  1.0384e-02,\n",
       "           2.3490e-02,  1.1601e-02,  3.0169e-03, -1.2610e-02,  4.4937e-03,\n",
       "           2.2457e-02,  2.5862e-02, -1.7420e-02, -2.7433e-02, -2.0362e-03,\n",
       "          -2.3578e-02,  3.4436e-03,  5.4491e-03,  1.8568e-03, -2.1497e-02,\n",
       "           1.6982e-02,  4.3215e-03, -8.8976e-03,  1.9076e-02,  1.4484e-02,\n",
       "           1.6526e-02, -1.2912e-02,  1.4185e-02, -9.9388e-03, -2.6723e-02,\n",
       "          -5.7357e-03, -5.5539e-04,  1.4631e-02, -8.1193e-03,  1.6790e-02,\n",
       "           7.1388e-03,  1.8617e-03, -1.2335e-02, -2.6268e-02,  4.3541e-03,\n",
       "           2.3303e-02,  6.8100e-03,  2.3381e-02, -5.4576e-03,  1.9451e-02,\n",
       "          -1.4971e-03,  2.0351e-02, -2.7365e-02,  2.1202e-02,  2.3602e-02,\n",
       "           9.2226e-03,  2.4581e-02, -1.6963e-02, -6.9481e-04, -2.3623e-02,\n",
       "          -1.2369e-02,  1.8312e-02, -5.3720e-03, -5.2188e-03, -5.8792e-03,\n",
       "           2.6354e-02,  1.4746e-02, -1.0367e-02,  3.6518e-03, -5.6907e-03,\n",
       "          -2.5062e-02, -2.0913e-02,  2.2203e-02, -2.1288e-03,  2.7809e-02,\n",
       "          -6.8047e-03,  2.7263e-02,  1.3831e-03,  1.5084e-02,  5.2152e-04,\n",
       "           2.6733e-02,  6.2977e-03, -4.5888e-05,  2.1813e-02,  2.5368e-02,\n",
       "          -3.7453e-03,  3.2280e-03,  2.4869e-03, -2.7394e-02, -2.3044e-02,\n",
       "          -2.8972e-03, -1.5766e-02, -2.7251e-02,  1.5383e-02, -4.6406e-03,\n",
       "          -1.7416e-02, -1.1011e-02,  2.4902e-02,  7.7475e-03,  6.2007e-03,\n",
       "           6.4468e-03,  3.0175e-03, -2.5748e-03,  4.4665e-03, -5.4113e-03,\n",
       "          -1.2370e-02,  1.1623e-02,  2.9295e-03,  1.5011e-02,  1.9077e-02,\n",
       "          -1.7698e-02, -1.2423e-02,  4.3756e-03, -3.8694e-03,  2.1050e-02,\n",
       "          -2.3351e-02,  2.7376e-02, -1.8071e-03,  5.0759e-03, -2.3186e-02,\n",
       "           4.0065e-03,  2.8716e-03, -1.4878e-02, -2.0905e-02, -1.9845e-02,\n",
       "          -2.4682e-02,  1.1803e-02,  7.9068e-03,  1.3297e-02, -1.0659e-02,\n",
       "          -1.7602e-02,  2.1899e-02, -1.9808e-02,  1.1874e-03, -1.2030e-02,\n",
       "           3.5083e-03,  1.2180e-02,  7.2962e-03,  1.3292e-02,  1.7162e-02,\n",
       "           1.3844e-02, -9.2348e-03, -4.1824e-03, -1.5826e-02,  8.1069e-04,\n",
       "           1.8134e-02,  7.2284e-03,  7.6028e-03, -1.7782e-02, -1.4674e-02],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0035,  0.0358,  0.0325,  ...,  0.0088,  0.0026,  0.0392],\n",
       "          [ 0.0320,  0.0030, -0.0392,  ...,  0.0084,  0.0290,  0.0002],\n",
       "          [-0.0065,  0.0141, -0.0153,  ...,  0.0138,  0.0337, -0.0370],\n",
       "          ...,\n",
       "          [-0.0365,  0.0170, -0.0069,  ...,  0.0142, -0.0356,  0.0143],\n",
       "          [ 0.0377, -0.0302,  0.0052,  ...,  0.0083, -0.0169,  0.0009],\n",
       "          [ 0.0266,  0.0294,  0.0310,  ..., -0.0164,  0.0074, -0.0254]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0190,  0.0251,  0.0104, -0.0009, -0.0123,  0.0286,  0.0226,  0.0150],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 2.3498e-03, -1.0009e-02,  1.3316e-02,  ...,  3.7400e-03,\n",
       "           -2.5089e-02, -1.2695e-02],\n",
       "          [-1.7059e-03, -2.4479e-03,  5.1511e-03,  ..., -9.0617e-03,\n",
       "           -1.0694e-02, -1.2218e-03],\n",
       "          [ 6.4020e-03, -1.5768e-02,  2.1688e-02,  ..., -3.0113e-05,\n",
       "           -1.2728e-02, -3.0010e-02],\n",
       "          ...,\n",
       "          [-2.3128e-02,  4.6758e-03,  4.1045e-03,  ...,  7.6716e-03,\n",
       "           -1.0512e-02,  1.4218e-02],\n",
       "          [-1.5254e-02, -1.2303e-02,  1.5667e-02,  ..., -2.6145e-03,\n",
       "            5.5155e-03,  2.2108e-03],\n",
       "          [ 1.9072e-02, -1.7774e-03, -2.7757e-03,  ...,  2.3520e-02,\n",
       "           -1.7017e-02,  1.0498e-02]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0060, -0.0312, -0.0048,  ...,  0.0112,  0.0155,  0.0039],\n",
       "          [-0.0036, -0.0018, -0.0135,  ..., -0.0032, -0.0104, -0.0035],\n",
       "          [ 0.0086, -0.0071,  0.0061,  ..., -0.0036, -0.0203, -0.0082],\n",
       "          ...,\n",
       "          [-0.0132,  0.0047, -0.0106,  ..., -0.0064, -0.0151,  0.0070],\n",
       "          [-0.0286, -0.0308,  0.0134,  ..., -0.0078,  0.0126,  0.0057],\n",
       "          [-0.0049, -0.0164, -0.0076,  ..., -0.0032,  0.0079,  0.0111]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0111, -0.0183, -0.0238,  ...,  0.0050, -0.0121,  0.0004],\n",
       "          [-0.0090,  0.0003, -0.0161,  ..., -0.0131, -0.0105, -0.0074],\n",
       "          [-0.0195,  0.0112, -0.0173,  ...,  0.0026, -0.0213, -0.0125],\n",
       "          ...,\n",
       "          [ 0.0057, -0.0186, -0.0019,  ...,  0.0199, -0.0100, -0.0066],\n",
       "          [ 0.0007, -0.0290, -0.0012,  ..., -0.0199,  0.0182,  0.0185],\n",
       "          [ 0.0066,  0.0089, -0.0136,  ..., -0.0408,  0.0163, -0.0028]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0243, -0.0075,  0.0057,  ..., -0.0224,  0.0209,  0.0010],\n",
       "          [ 0.0069,  0.0045, -0.0250,  ..., -0.0179,  0.0292, -0.0201],\n",
       "          [ 0.0056,  0.0225,  0.0010,  ...,  0.0014,  0.0059,  0.0088],\n",
       "          ...,\n",
       "          [-0.0021, -0.0281,  0.0015,  ...,  0.0031, -0.0123, -0.0234],\n",
       "          [ 0.0121, -0.0330,  0.0185,  ..., -0.0080, -0.0218, -0.0198],\n",
       "          [ 0.0088,  0.0027,  0.0127,  ..., -0.0051, -0.0156,  0.0292]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0129, -0.0086,  0.0159,  ...,  0.0054,  0.0268,  0.0125],\n",
       "          [-0.0013, -0.0175,  0.0141,  ..., -0.0120, -0.0002, -0.0162],\n",
       "          [ 0.0049,  0.0235,  0.0073,  ..., -0.0084,  0.0128,  0.0110],\n",
       "          ...,\n",
       "          [-0.0012,  0.0009, -0.0017,  ...,  0.0225,  0.0126, -0.0136],\n",
       "          [-0.0102,  0.0021, -0.0174,  ...,  0.0268,  0.0179, -0.0198],\n",
       "          [ 0.0193, -0.0189,  0.0220,  ..., -0.0144,  0.0197, -0.0160]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-2.5950e-02,  2.5110e-05,  1.9307e-02, -1.1922e-04,  1.5594e-03,\n",
       "          -8.9677e-03,  2.1594e-02, -6.8792e-03,  6.8947e-03,  1.9309e-02,\n",
       "          -6.8182e-03, -1.9738e-02,  1.0746e-03, -4.0479e-03, -1.4530e-02,\n",
       "           7.3483e-03, -1.2836e-02, -2.2082e-03,  2.3512e-02,  4.8224e-03,\n",
       "           6.9964e-03,  1.7914e-02,  2.5280e-02, -2.0393e-02,  1.7867e-02,\n",
       "          -2.6667e-02, -1.3793e-02, -1.9502e-02,  7.2507e-03, -7.5992e-03,\n",
       "          -6.6321e-03, -8.3588e-03, -1.3456e-02,  1.0837e-02, -1.5402e-02,\n",
       "           2.7627e-02,  1.9974e-02,  1.3242e-02, -1.6011e-02, -2.8881e-04,\n",
       "           1.1398e-03, -1.2311e-02, -1.9832e-02, -1.2379e-02, -2.2331e-02,\n",
       "           2.7162e-02, -1.5462e-02,  4.8303e-03, -1.3207e-02, -9.5848e-03,\n",
       "           2.8562e-03,  2.6008e-02,  1.3298e-02, -8.0736e-03, -1.1418e-02,\n",
       "          -2.3282e-03,  1.4435e-02,  5.8830e-03, -5.3245e-03, -1.6071e-02,\n",
       "           2.7863e-02,  1.0410e-02, -1.6096e-02, -2.7006e-02,  2.0244e-02,\n",
       "           1.7802e-02,  2.0254e-03,  2.0644e-02, -1.0868e-02,  1.7953e-02,\n",
       "          -1.0234e-02,  1.0251e-02,  2.7321e-02, -4.6098e-03,  2.6910e-02,\n",
       "          -2.2341e-03,  1.0570e-02, -1.7114e-02,  5.9087e-03,  5.6411e-03,\n",
       "          -1.3089e-02, -1.0190e-02,  7.1486e-03,  2.6266e-02,  1.9265e-02,\n",
       "          -2.2150e-03,  3.4521e-03, -1.9665e-02,  2.7232e-02, -2.1176e-02,\n",
       "          -1.2418e-02, -4.0760e-03,  3.8976e-03,  2.0877e-02, -2.0179e-02,\n",
       "           2.5396e-02,  2.0895e-02,  7.1342e-04,  1.7216e-02, -8.2913e-03,\n",
       "          -2.9597e-03, -1.7960e-02, -1.6799e-02,  2.1001e-02, -1.7499e-02,\n",
       "           1.0233e-02, -6.3520e-03,  2.5446e-02,  9.3170e-03,  2.4553e-02,\n",
       "           2.6516e-02,  2.0332e-02,  2.2157e-02, -1.1912e-02, -7.2612e-03,\n",
       "          -2.3461e-02, -1.4462e-02,  1.7993e-02,  2.4089e-02, -3.6002e-03,\n",
       "          -2.4006e-02,  8.0166e-03,  1.4775e-02, -4.9594e-03,  2.2195e-03,\n",
       "           2.5876e-02, -1.9574e-02, -2.3170e-02, -1.0565e-02, -8.6813e-04,\n",
       "          -2.1565e-02, -1.9362e-03,  2.7552e-02, -5.0115e-03, -2.2145e-02,\n",
       "           5.6001e-04, -1.4746e-02,  4.9917e-03,  1.2697e-02, -1.0538e-02,\n",
       "           2.5746e-02, -4.8849e-03,  2.5837e-02,  2.0893e-02,  2.0605e-02,\n",
       "          -4.0612e-03, -5.0483e-03,  2.7937e-02,  7.6196e-03, -6.0952e-03,\n",
       "           1.7781e-02,  1.3407e-02, -1.4402e-02, -8.4594e-03, -1.1464e-02,\n",
       "          -1.6043e-02,  2.6732e-02,  1.6095e-02, -1.0491e-02, -3.0854e-04,\n",
       "           1.6152e-02, -1.6757e-02, -5.2218e-03,  1.0992e-02,  2.6338e-02,\n",
       "           2.3271e-02,  2.2317e-02,  2.0672e-02, -2.0545e-02,  8.2110e-03,\n",
       "           9.2085e-04, -2.2916e-02, -4.0375e-04, -1.9048e-02, -2.5106e-02,\n",
       "           2.6828e-02,  5.9063e-03, -1.7093e-02, -3.5715e-03,  1.7309e-02,\n",
       "          -2.3920e-02,  1.7977e-02, -2.5805e-02, -1.3431e-02, -2.3701e-02,\n",
       "           1.4228e-02,  2.6081e-02, -2.6080e-02, -9.3860e-03,  1.1593e-02,\n",
       "          -2.1164e-02, -1.9114e-02,  2.1883e-02, -6.2843e-03,  1.7873e-02,\n",
       "          -8.4063e-03,  2.0839e-02,  1.0120e-02, -4.8598e-03,  2.5601e-02,\n",
       "           1.5843e-02, -2.6867e-02,  2.6024e-02,  2.3291e-02,  1.8715e-02,\n",
       "           1.9353e-02, -1.8464e-02, -4.5556e-03, -1.3990e-02,  1.4202e-02,\n",
       "          -2.4734e-02,  1.9690e-02, -4.4784e-03,  2.5540e-03,  7.4759e-03,\n",
       "           1.8906e-02,  2.0324e-02,  2.6251e-02,  1.0297e-02,  1.1239e-02,\n",
       "          -2.4150e-02,  3.5769e-03,  1.5714e-02, -8.3076e-03, -6.2413e-03,\n",
       "           1.4120e-02, -6.5418e-03,  1.5234e-02,  1.9546e-03, -3.5559e-03,\n",
       "          -5.3005e-03,  1.1720e-02,  2.0269e-02, -4.2559e-04,  2.1756e-02,\n",
       "           1.7495e-02, -6.4110e-03,  1.7918e-02,  2.1347e-02,  1.4215e-02,\n",
       "           2.1479e-03, -8.7260e-03, -5.4393e-03,  1.0964e-02, -2.3468e-02,\n",
       "          -2.7729e-02, -1.4981e-02,  1.9423e-02,  1.0785e-02, -2.4308e-02,\n",
       "           9.0268e-03, -2.5899e-02, -2.6027e-03, -2.6744e-02,  1.5304e-02,\n",
       "           5.9473e-04, -1.1914e-02,  1.3748e-02, -2.7377e-02, -1.1944e-02,\n",
       "           2.0918e-02,  2.1662e-02, -9.9513e-03, -7.0697e-03,  6.2723e-03,\n",
       "          -2.5045e-02,  1.1945e-02,  1.2072e-02, -5.6939e-04,  7.5040e-03,\n",
       "          -2.0890e-02, -7.7159e-03, -2.2615e-02, -1.5974e-02, -5.5805e-03,\n",
       "          -1.3215e-02,  2.4805e-02, -2.2057e-02, -2.1828e-02, -9.6140e-03,\n",
       "           1.5348e-02, -2.0074e-02, -2.7929e-03, -1.2612e-03,  2.3047e-02,\n",
       "          -6.2729e-03,  1.5458e-02, -1.7708e-02,  1.0895e-02,  1.1169e-02,\n",
       "           9.1527e-05,  2.2508e-02, -2.6136e-02,  1.9256e-02,  1.1126e-02,\n",
       "          -2.0120e-02,  1.8420e-03, -1.7713e-02, -1.8249e-03, -1.6650e-03,\n",
       "           5.2363e-03,  5.3316e-03, -2.7938e-02, -1.6667e-02,  1.6575e-02,\n",
       "          -2.3843e-02, -2.5660e-02,  1.5893e-02,  9.0077e-03, -3.8026e-04,\n",
       "           7.9011e-03, -8.5721e-03,  1.6367e-02,  1.8928e-02,  8.1258e-03,\n",
       "           1.0445e-02, -3.6076e-03,  2.2833e-02, -1.5850e-02,  1.0811e-02,\n",
       "           7.9535e-03,  4.4269e-03, -1.4184e-02, -2.1616e-02,  2.5710e-02,\n",
       "          -1.6610e-02, -2.2600e-03,  2.4922e-02, -2.6390e-03,  2.1627e-02,\n",
       "           1.2520e-02,  1.0369e-02, -2.5704e-02, -4.2765e-03, -2.7659e-02,\n",
       "          -2.5950e-02,  1.8738e-02,  3.9550e-03, -1.6746e-02,  2.4601e-02,\n",
       "          -1.1422e-02, -2.5802e-02, -1.9494e-02,  2.5514e-03,  7.9117e-03,\n",
       "           8.1172e-04,  1.4714e-02,  1.0754e-02, -1.2301e-02, -7.8839e-03,\n",
       "          -2.2015e-02,  1.9313e-02,  5.0109e-03, -3.4762e-03, -1.1573e-03,\n",
       "          -1.1126e-02, -2.7896e-03, -1.0381e-03,  1.1819e-02, -2.3454e-02,\n",
       "          -9.8632e-03, -8.1252e-03, -1.5982e-02,  5.2738e-03,  9.0562e-03,\n",
       "           7.6791e-03,  2.0291e-03,  1.9024e-02, -2.0399e-02,  2.3131e-02,\n",
       "          -2.5322e-03, -2.3993e-02, -4.3011e-03, -1.1601e-02, -1.8202e-02,\n",
       "           1.6637e-02,  1.0970e-02, -2.6225e-02,  1.7221e-02,  1.2136e-02,\n",
       "           2.1428e-02,  7.5777e-03, -1.2295e-02,  1.1808e-02,  2.2319e-02,\n",
       "          -1.2564e-02, -1.5627e-02, -4.2787e-03, -2.1750e-02,  1.2047e-02,\n",
       "          -1.7078e-02, -7.4436e-03, -3.0652e-03, -6.2063e-03, -9.7159e-03,\n",
       "          -4.1433e-03, -1.2050e-03, -1.1134e-02,  2.3529e-02,  1.0927e-02,\n",
       "           1.9854e-02,  6.1200e-03, -2.8142e-03,  1.7477e-02, -1.5883e-02,\n",
       "           1.4166e-02,  1.9252e-02,  2.7768e-02, -1.0278e-02,  7.9963e-04,\n",
       "           2.1605e-02, -8.5001e-03, -1.6246e-02, -1.4508e-02,  1.6135e-02,\n",
       "           2.2113e-02, -6.9458e-04, -4.6686e-03,  1.4921e-02,  8.8646e-04,\n",
       "           1.7749e-02,  1.4155e-03,  2.1998e-02,  9.3203e-04, -2.0314e-02,\n",
       "          -9.9312e-03,  1.9457e-03, -1.5764e-02, -7.6284e-03,  1.9321e-02,\n",
       "          -1.1392e-02, -1.2417e-02, -2.2393e-02, -1.6783e-02, -1.0171e-02,\n",
       "          -7.9592e-04, -2.1166e-02, -1.0749e-02, -9.6248e-03, -1.8702e-02,\n",
       "           2.2940e-02,  2.0490e-02,  1.8443e-02, -2.3612e-02,  1.7524e-02,\n",
       "           2.2766e-02, -9.3784e-03, -8.5940e-03,  8.5909e-03, -7.1651e-03,\n",
       "           1.9211e-02,  2.5660e-02,  1.4939e-02,  3.6141e-03, -2.4449e-02,\n",
       "           1.4429e-02,  2.2401e-02,  2.5673e-02, -1.9311e-02, -2.2753e-02,\n",
       "          -7.5836e-04, -3.9169e-03,  1.5865e-02,  1.9157e-02, -2.7932e-02,\n",
       "          -8.7288e-03,  2.2047e-02,  2.3866e-02, -1.0042e-02, -1.0890e-02,\n",
       "          -3.0808e-03, -1.0801e-02, -1.8000e-02,  1.5241e-02, -1.8464e-02,\n",
       "          -6.5783e-04, -8.7072e-03, -1.7484e-02,  6.3482e-03, -5.5641e-03,\n",
       "           1.0211e-02,  1.6874e-02, -1.6727e-02,  9.5787e-03,  3.7391e-04,\n",
       "          -1.3528e-02, -2.7968e-03,  9.7967e-03, -2.7979e-03,  4.2582e-03,\n",
       "          -2.3104e-02, -1.2945e-02, -1.9915e-02, -2.4887e-02,  2.5126e-02,\n",
       "          -3.7855e-03,  2.4279e-02,  4.0765e-03, -1.3101e-02, -1.9800e-02,\n",
       "          -3.3218e-03,  1.8998e-02, -2.5662e-02, -2.7786e-02, -1.0329e-02,\n",
       "           8.3288e-03,  2.2274e-02, -4.8748e-03, -7.6352e-03,  3.4081e-03,\n",
       "          -1.4085e-02,  2.4705e-02, -3.7996e-03,  5.9088e-03, -2.3658e-02,\n",
       "           1.7799e-02,  2.0073e-02, -1.2242e-02, -1.0363e-02, -1.8250e-03,\n",
       "           2.4348e-02,  9.2423e-03,  1.9241e-02, -3.7877e-03,  8.6940e-03,\n",
       "           9.1145e-03,  5.6668e-04, -2.2920e-04,  9.5267e-03, -2.2108e-02,\n",
       "           1.6872e-02,  2.5069e-02, -1.9130e-02, -3.5270e-04,  1.4823e-02,\n",
       "          -9.5231e-03, -1.7351e-02, -5.9567e-03, -1.0089e-02, -9.1709e-03,\n",
       "          -1.8768e-02, -1.5503e-02,  2.4356e-02,  2.5513e-02, -1.4999e-02,\n",
       "           2.6437e-02,  6.1692e-03,  1.2139e-02, -5.0565e-03, -1.4042e-03,\n",
       "          -2.7515e-02, -9.4530e-03,  2.7573e-04,  1.5621e-02,  1.8665e-02,\n",
       "          -1.3795e-02, -8.1944e-03, -2.1582e-02,  9.6527e-03, -7.1259e-03,\n",
       "           1.6958e-02,  1.8709e-02, -1.5777e-02,  8.0285e-03, -2.1912e-02,\n",
       "          -1.5530e-02, -1.3546e-02,  1.6735e-02,  2.0072e-02, -1.0964e-03,\n",
       "          -1.4316e-02,  1.4147e-03, -5.9042e-03,  7.2771e-03, -3.5425e-03,\n",
       "          -1.2734e-02,  7.9602e-03, -1.2906e-03, -1.7490e-02, -2.6218e-02,\n",
       "          -1.6135e-02,  1.8936e-02, -8.6893e-03, -1.1743e-02, -2.4551e-02,\n",
       "          -1.2237e-02, -1.5884e-02,  1.8049e-03, -1.2956e-02, -1.2186e-02,\n",
       "          -2.0043e-02, -1.8543e-02,  8.9019e-03,  2.5703e-02,  1.8318e-02,\n",
       "          -2.5810e-02, -1.6198e-02, -1.3017e-02,  6.1279e-03, -3.7967e-03,\n",
       "          -1.9506e-02, -1.2903e-02,  1.6602e-02,  2.2663e-02,  1.1993e-02,\n",
       "          -9.4777e-03,  3.5120e-04,  2.4071e-02,  9.7692e-03,  4.4843e-03,\n",
       "          -9.0575e-03,  9.5312e-03,  3.0413e-03,  1.1821e-02,  9.8876e-03,\n",
       "           1.9436e-04, -1.3549e-02,  2.6242e-02,  9.5477e-03, -2.2022e-02,\n",
       "           9.5979e-03, -1.1591e-02, -3.6297e-03, -9.0530e-03,  1.0181e-02,\n",
       "           1.6914e-02, -6.9998e-03,  1.2167e-02, -7.1426e-03,  1.8401e-02,\n",
       "           1.4780e-02, -4.3873e-03,  2.6801e-02, -6.0229e-03,  1.9315e-02,\n",
       "          -2.4243e-02, -1.8495e-02,  2.1929e-02, -1.5153e-03,  1.3396e-02],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0379, -0.0043,  0.0007,  ...,  0.0328, -0.0134,  0.0223],\n",
       "          [-0.0089,  0.0088, -0.0248,  ...,  0.0061, -0.0125, -0.0298],\n",
       "          [ 0.0287, -0.0391, -0.0254,  ...,  0.0147,  0.0365, -0.0153],\n",
       "          ...,\n",
       "          [ 0.0116, -0.0030,  0.0059,  ...,  0.0209,  0.0312, -0.0291],\n",
       "          [-0.0232,  0.0050, -0.0183,  ..., -0.0115, -0.0393, -0.0175],\n",
       "          [ 0.0030,  0.0012,  0.0034,  ..., -0.0248,  0.0195, -0.0057]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.0020,  0.0137,  0.0340, -0.0197,  0.0050,  0.0093,  0.0262, -0.0146],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0153, -0.0057,  0.0415,  ..., -0.0020, -0.0021,  0.0035],\n",
       "          [ 0.0065,  0.0170,  0.0197,  ..., -0.0114, -0.0229, -0.0182],\n",
       "          [ 0.0097, -0.0257, -0.0238,  ...,  0.0227,  0.0028,  0.0187],\n",
       "          ...,\n",
       "          [ 0.0365,  0.0255,  0.0090,  ...,  0.0174,  0.0292, -0.0358],\n",
       "          [ 0.0157,  0.0098,  0.0002,  ...,  0.0248, -0.0123,  0.0141],\n",
       "          [-0.0119, -0.0063, -0.0026,  ...,  0.0059, -0.0082, -0.0025]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0061,  0.0170,  0.0130,  ..., -0.0010,  0.0235,  0.0020],\n",
       "          [ 0.0210,  0.0107,  0.0053,  ...,  0.0009,  0.0169, -0.0051],\n",
       "          [ 0.0070,  0.0092,  0.0102,  ..., -0.0031, -0.0092,  0.0309],\n",
       "          ...,\n",
       "          [-0.0400, -0.0104, -0.0211,  ...,  0.0293, -0.0087,  0.0045],\n",
       "          [-0.0084, -0.0187, -0.0171,  ...,  0.0106,  0.0105,  0.0057],\n",
       "          [-0.0062, -0.0090,  0.0181,  ..., -0.0287,  0.0335, -0.0037]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0122, -0.0138,  0.0171,  ...,  0.0197,  0.0251,  0.0157],\n",
       "          [ 0.0120, -0.0180,  0.0127,  ...,  0.0118, -0.0367,  0.0114],\n",
       "          [ 0.0241,  0.0140, -0.0075,  ...,  0.0062, -0.0115, -0.0024],\n",
       "          ...,\n",
       "          [ 0.0131, -0.0106, -0.0153,  ..., -0.0286,  0.0116,  0.0070],\n",
       "          [ 0.0142, -0.0050, -0.0232,  ...,  0.0074, -0.0017, -0.0176],\n",
       "          [-0.0157, -0.0194, -0.0015,  ...,  0.0001,  0.0076, -0.0205]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0222,  0.0166, -0.0130,  ...,  0.0114,  0.0109,  0.0023],\n",
       "          [-0.0187,  0.0192, -0.0221,  ...,  0.0084,  0.0019, -0.0120],\n",
       "          [ 0.0048,  0.0030, -0.0250,  ...,  0.0175, -0.0271, -0.0150],\n",
       "          ...,\n",
       "          [ 0.0052, -0.0363,  0.0080,  ...,  0.0113, -0.0052,  0.0281],\n",
       "          [ 0.0140, -0.0109,  0.0063,  ..., -0.0082, -0.0014, -0.0216],\n",
       "          [ 0.0013, -0.0356, -0.0154,  ..., -0.0255,  0.0069,  0.0141]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 1.7504e-02,  1.0775e-02, -1.3897e-03,  ...,  1.6571e-03,\n",
       "            1.7299e-02, -6.5660e-03],\n",
       "          [-1.5892e-02,  2.4934e-02, -1.9091e-02,  ...,  5.2803e-03,\n",
       "           -1.7846e-02, -4.1569e-03],\n",
       "          [-2.4135e-02,  6.4840e-03, -5.4741e-05,  ..., -1.3162e-02,\n",
       "            8.4583e-03, -1.5918e-02],\n",
       "          ...,\n",
       "          [ 5.7180e-03, -2.7324e-02, -6.2032e-03,  ..., -1.9663e-04,\n",
       "            1.5126e-02, -3.5663e-03],\n",
       "          [-1.1754e-02, -1.3436e-03, -2.3581e-02,  ..., -4.4503e-03,\n",
       "            6.0380e-03,  2.1002e-02],\n",
       "          [ 1.5665e-03,  1.4462e-02,  4.2816e-03,  ...,  2.5750e-02,\n",
       "           -1.7478e-02,  7.6168e-03]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 2.5628e-02,  9.3918e-04,  1.5043e-02,  2.1796e-02,  1.1839e-02,\n",
       "           1.5588e-02, -2.5936e-02,  7.2651e-03, -1.4057e-02, -1.6188e-03,\n",
       "           8.8378e-04,  1.9374e-03,  9.4828e-03, -1.6144e-02,  1.4523e-02,\n",
       "          -3.1183e-04, -2.6936e-02,  6.6309e-03,  5.4008e-03,  1.8677e-02,\n",
       "           2.3446e-03,  8.4333e-03,  8.0441e-03, -2.5791e-02, -1.5789e-02,\n",
       "          -1.9942e-03, -2.4148e-03,  1.8414e-02, -2.0457e-02,  2.2685e-02,\n",
       "           8.5465e-03, -3.5566e-03,  1.0805e-02,  1.7088e-02, -3.5588e-03,\n",
       "           5.5824e-03, -1.1518e-02, -3.4395e-03,  1.4232e-02,  8.8702e-03,\n",
       "           8.6503e-03,  1.8159e-02,  2.7281e-02, -6.2645e-03, -2.5352e-02,\n",
       "           1.1443e-02,  1.6523e-02,  7.1155e-03, -8.3343e-03, -2.2436e-02,\n",
       "          -2.3613e-02, -2.4812e-02, -2.6268e-02,  2.4051e-02,  1.0059e-02,\n",
       "           2.0086e-02, -2.2657e-02, -2.1372e-02,  2.7271e-03,  8.7401e-03,\n",
       "           1.4161e-02, -2.1225e-02,  2.4118e-02,  4.6921e-03,  1.3748e-02,\n",
       "           1.1899e-02,  5.9045e-04,  2.6272e-02, -2.6434e-02,  1.1923e-02,\n",
       "           1.9933e-02, -5.5154e-04,  2.3921e-02,  1.3233e-02, -9.9178e-03,\n",
       "           1.3690e-02,  2.8083e-03, -1.4781e-02,  2.2213e-02, -2.2742e-02,\n",
       "           7.2874e-03, -3.4556e-04, -6.4919e-03, -1.7556e-02,  2.7719e-02,\n",
       "          -2.4248e-02, -1.6735e-02,  6.9623e-03, -2.2260e-02, -1.2278e-02,\n",
       "          -1.6158e-02, -1.9286e-02, -1.8293e-02,  1.6458e-02,  2.3569e-02,\n",
       "          -1.7149e-02,  1.1895e-02, -1.9922e-02, -1.9918e-03,  1.0640e-02,\n",
       "          -2.6702e-02,  1.9363e-02, -2.6053e-02, -2.6507e-02, -6.7070e-03,\n",
       "          -5.1118e-03, -2.2496e-02, -5.6811e-03, -2.7763e-02, -2.0911e-02,\n",
       "           7.7449e-03,  1.4451e-02,  4.9158e-04, -2.2280e-02,  2.2648e-02,\n",
       "          -2.6396e-02, -8.8760e-03,  2.5426e-03,  2.4397e-02, -1.0365e-02,\n",
       "           2.0324e-02,  8.6878e-04,  4.9276e-03, -2.4947e-02, -7.9455e-03,\n",
       "           2.6963e-02, -1.4594e-02,  2.0525e-02,  2.1331e-02,  2.7855e-02,\n",
       "           2.7217e-02,  9.4039e-03,  7.5089e-03, -2.2244e-02,  4.2647e-03,\n",
       "          -1.7139e-02,  2.7798e-02, -1.8618e-02,  2.4453e-02, -2.6713e-02,\n",
       "          -1.5511e-02,  1.2817e-02, -2.0500e-02, -2.2474e-02,  1.5940e-02,\n",
       "           1.9824e-02,  4.8700e-03,  8.8085e-03, -2.5125e-02, -1.5398e-02,\n",
       "          -1.9396e-02, -8.9109e-03,  2.1729e-02, -1.3798e-02,  1.2726e-02,\n",
       "          -2.6581e-02, -2.6665e-03, -2.4152e-02, -1.7218e-02,  2.3110e-02,\n",
       "          -2.4958e-02, -2.7502e-02,  1.8564e-02,  2.0664e-02, -5.1710e-03,\n",
       "           1.4806e-02, -1.3070e-02, -1.5994e-03,  5.6304e-03,  1.3966e-02,\n",
       "          -1.4850e-02, -6.0678e-03, -1.7271e-02, -3.9859e-03,  1.7612e-02,\n",
       "          -1.1177e-03, -2.0042e-02, -2.2459e-02, -2.7143e-02,  2.1800e-03,\n",
       "          -1.2258e-02, -2.1557e-02,  1.4848e-02,  3.8714e-03, -1.6905e-02,\n",
       "           2.5350e-02,  1.2733e-02, -2.4523e-02, -4.8663e-03, -1.5608e-02,\n",
       "          -2.4646e-02, -1.5294e-02,  7.0779e-03, -6.0060e-03,  1.0240e-02,\n",
       "          -1.4729e-02, -1.5799e-02,  1.9858e-02,  1.4584e-02,  2.7915e-02,\n",
       "           9.0336e-03, -2.3722e-02,  2.4387e-02,  1.0751e-02,  2.2015e-02,\n",
       "           1.7405e-02, -3.1133e-03,  2.8307e-03,  1.4932e-02,  4.3354e-03,\n",
       "          -2.5047e-02,  2.1960e-02, -2.0917e-02,  2.5560e-02,  2.5081e-02,\n",
       "           1.8931e-03, -2.2260e-02,  8.8317e-04, -1.5387e-02, -9.5779e-03,\n",
       "          -1.0424e-02,  1.4856e-02,  1.6579e-02, -1.0910e-02,  7.5630e-03,\n",
       "          -2.3664e-02,  2.7889e-02, -1.8899e-02, -2.2499e-02, -2.4422e-02,\n",
       "           3.8676e-03,  1.7480e-02, -2.2818e-02, -1.6649e-02,  1.3186e-02,\n",
       "          -1.5897e-02,  1.6226e-02,  1.6779e-02,  2.3754e-02,  6.5440e-03,\n",
       "           6.3901e-03,  1.2829e-03,  2.4280e-02, -1.2254e-02, -2.6490e-02,\n",
       "           1.7032e-02, -2.5964e-03,  2.5913e-02, -4.7570e-03,  1.5644e-02,\n",
       "          -1.2315e-02,  4.8463e-03,  1.4275e-02, -1.2473e-02,  1.1404e-02,\n",
       "           2.3410e-02,  2.4037e-03, -7.9051e-03,  1.1806e-03, -2.1635e-02,\n",
       "           2.3811e-02,  2.6245e-02, -4.7834e-03, -9.1058e-03, -2.6988e-02,\n",
       "          -2.0411e-02,  2.5648e-02, -1.2126e-02,  2.7523e-02, -7.3285e-03,\n",
       "          -5.5540e-03,  1.4095e-02, -1.4629e-02,  1.2609e-02, -3.4445e-04,\n",
       "          -2.6090e-02,  2.6891e-02,  9.9126e-03, -3.3130e-03,  2.2821e-02,\n",
       "           2.4729e-02, -2.0762e-02,  1.7607e-02, -1.0277e-02,  1.1867e-02,\n",
       "           1.2563e-02, -1.9241e-04, -1.7887e-02, -2.6879e-02, -2.4114e-02,\n",
       "           8.3933e-03, -1.1276e-02,  2.2038e-03,  2.4564e-02, -2.6344e-02,\n",
       "           1.1416e-02, -2.5168e-02,  1.7828e-03,  1.0375e-02, -5.1372e-03,\n",
       "          -1.3281e-02,  1.6501e-02,  1.3897e-02, -1.0887e-02,  2.7359e-02,\n",
       "          -1.0821e-02, -2.0648e-02,  1.8735e-02, -1.6428e-02, -2.0333e-02,\n",
       "           1.4577e-02, -1.6363e-02,  1.3983e-02, -1.8804e-02,  9.8282e-03,\n",
       "           5.6342e-03, -2.3450e-03,  2.4800e-02,  1.5273e-02, -2.4687e-02,\n",
       "          -1.2738e-02, -1.4424e-02,  1.2031e-02, -1.9807e-02, -2.3006e-02,\n",
       "          -1.3699e-02,  2.5281e-02, -1.5446e-02,  2.4106e-02,  2.4918e-02,\n",
       "          -2.0427e-02,  1.4078e-02,  1.5424e-02, -1.5174e-02,  5.6602e-03,\n",
       "          -1.9155e-02,  4.7707e-03, -2.7697e-02, -1.3702e-02,  1.4560e-02,\n",
       "           8.4676e-03,  2.6717e-02, -3.3599e-03, -1.2488e-02, -2.4546e-02,\n",
       "           9.8260e-03,  1.6542e-02,  1.7169e-02,  1.8620e-02, -1.9056e-02,\n",
       "           9.1938e-03,  1.8873e-02, -2.5222e-02, -6.1013e-03,  2.6612e-02,\n",
       "           8.7147e-03,  1.6617e-02,  1.3744e-03,  9.6980e-03, -6.8693e-03,\n",
       "           1.1864e-02, -1.6347e-03,  5.7781e-03,  1.1832e-02, -2.5677e-02,\n",
       "          -2.0616e-02,  6.5527e-03,  6.5712e-03,  2.7342e-02,  5.3730e-03,\n",
       "           2.0874e-02,  3.5772e-03,  9.1819e-03,  4.8870e-03,  1.8081e-02,\n",
       "           1.0015e-02, -2.6438e-02,  2.0994e-02, -2.1207e-02, -1.5578e-02,\n",
       "          -4.4359e-03, -1.6270e-02,  1.0100e-02, -3.6725e-03, -2.6896e-02,\n",
       "           4.1843e-03, -1.2925e-02,  1.6987e-02,  2.0325e-02,  1.1076e-02,\n",
       "           1.1535e-02,  1.6957e-02,  1.9192e-02, -2.5053e-02, -2.2727e-02,\n",
       "          -1.0899e-02, -4.3640e-03,  1.4441e-02, -1.2579e-02, -1.3492e-02,\n",
       "           1.6689e-02, -1.3298e-02, -5.5853e-03,  1.7393e-02, -8.2866e-03,\n",
       "           6.1504e-03, -2.0890e-02, -1.8016e-02, -6.3370e-03,  1.4729e-02,\n",
       "           6.4140e-03,  7.3250e-03,  1.8701e-02, -1.8645e-02,  2.7430e-02,\n",
       "          -4.3403e-03, -1.5019e-02,  2.1343e-02,  1.6123e-02, -8.4248e-03,\n",
       "           1.0398e-02,  1.0170e-04, -2.6812e-02, -2.3199e-02, -2.3182e-02,\n",
       "           1.9732e-02, -2.2957e-03,  1.9130e-02,  1.0705e-03, -9.5119e-03,\n",
       "          -1.7744e-02, -2.2953e-02, -1.1613e-02, -1.7585e-03, -2.5399e-02,\n",
       "          -9.0465e-03,  1.6310e-02,  5.9706e-03,  2.4447e-02,  1.3584e-02,\n",
       "           1.0259e-03, -1.0173e-02, -1.6595e-03,  1.7235e-03,  2.1205e-02,\n",
       "           1.9354e-02, -2.0266e-02,  7.8045e-03, -1.8082e-02, -6.9157e-03,\n",
       "          -1.0168e-02, -2.1276e-02,  1.3596e-02,  2.3294e-02, -1.3027e-02,\n",
       "          -2.4921e-02,  2.6878e-02, -2.0694e-02, -2.6700e-02,  1.5829e-02,\n",
       "          -2.5754e-02, -1.1316e-03,  2.2754e-02,  2.2391e-02, -8.9732e-03,\n",
       "          -1.9639e-02,  1.4350e-02, -5.1345e-04,  4.4691e-03,  8.8222e-04,\n",
       "          -1.4322e-02,  2.4438e-02,  1.7538e-02, -9.3282e-03,  2.7762e-02,\n",
       "           6.8850e-03,  2.3722e-02, -2.3872e-02,  1.8906e-02,  2.6972e-03,\n",
       "          -6.4240e-03,  2.0479e-02,  1.0784e-02, -1.1307e-02,  8.0536e-03,\n",
       "          -5.7943e-05,  2.6681e-02, -1.9772e-02,  2.4210e-02, -2.5486e-02,\n",
       "           1.7926e-02, -1.3674e-02,  6.4956e-03,  5.8312e-03, -9.6925e-03,\n",
       "          -6.4898e-03,  3.3732e-03, -6.2007e-03,  1.8836e-02, -4.4728e-03,\n",
       "          -1.7592e-02, -2.0902e-02,  2.6822e-02,  1.5994e-02,  1.2915e-02,\n",
       "           7.8195e-03, -2.7381e-02, -2.2291e-02, -1.8633e-02,  2.1526e-02,\n",
       "          -6.9176e-03,  1.0665e-02, -1.7100e-03, -7.0033e-03,  6.3150e-03,\n",
       "          -9.7994e-03,  2.0118e-02,  1.5054e-02,  2.5598e-02, -2.2325e-02,\n",
       "           1.2374e-02, -2.4703e-02,  2.7107e-02, -1.4716e-02, -5.2560e-03,\n",
       "          -5.3285e-03,  1.8904e-03, -2.7403e-02, -1.1139e-02, -2.1917e-04,\n",
       "           2.7440e-02, -6.0825e-03, -1.8210e-02,  4.2583e-03,  1.5436e-02,\n",
       "           1.1939e-02,  4.9986e-03, -2.1870e-02, -1.2101e-02,  7.0452e-03,\n",
       "          -8.7627e-03, -8.7694e-03,  2.4482e-03, -2.1135e-03,  1.2225e-03,\n",
       "           5.9186e-03,  9.0815e-03, -4.6799e-03,  5.0165e-03,  2.3717e-02,\n",
       "           1.2581e-02, -1.1119e-02, -1.6572e-02, -4.4713e-03, -5.0320e-03,\n",
       "          -2.4551e-02,  8.2597e-03, -1.0133e-02,  2.4685e-02,  2.1701e-02,\n",
       "           1.6477e-02, -8.4841e-03,  1.1089e-02,  2.4895e-02,  2.3112e-02,\n",
       "          -1.8283e-02,  1.0021e-02,  1.7497e-02, -2.5886e-02, -1.9243e-02,\n",
       "          -1.4560e-02, -1.6172e-02, -2.1245e-02, -2.6931e-03,  2.0713e-02,\n",
       "           1.9226e-02, -1.1546e-02, -2.1471e-02,  2.6249e-03,  1.1589e-03,\n",
       "          -5.0225e-03,  2.6345e-02,  1.7190e-02,  1.1507e-02, -1.8787e-02,\n",
       "          -1.3318e-02, -5.7036e-03, -2.7109e-02,  2.1756e-02,  1.8655e-02,\n",
       "           5.2996e-03, -5.2268e-03,  1.0445e-02,  1.0143e-02, -2.6873e-03,\n",
       "           1.6120e-02, -1.2205e-03, -1.1522e-02, -1.8544e-02,  3.5021e-03,\n",
       "           1.6535e-02, -2.0326e-02, -2.1616e-02,  2.0932e-02,  1.6534e-02,\n",
       "           9.6462e-04,  4.3268e-03, -2.2521e-02,  6.1632e-03, -2.7109e-03,\n",
       "          -1.4105e-02, -2.3036e-02,  1.9619e-02,  2.4700e-02, -3.8636e-03,\n",
       "           8.1846e-03,  1.7325e-02, -1.7565e-02, -3.3964e-03, -2.2309e-02,\n",
       "          -1.0977e-02, -4.7551e-05, -4.5603e-03, -8.4236e-03, -1.0472e-02,\n",
       "           8.9857e-03,  1.1951e-02, -2.0109e-02, -1.6793e-03,  1.3998e-02,\n",
       "           1.5581e-02, -4.7050e-03,  2.9530e-03, -1.7641e-02,  2.1096e-02,\n",
       "           7.7021e-03, -1.1757e-02, -2.2860e-02, -5.8340e-03, -4.1545e-03],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0173, -0.0062, -0.0055,  ..., -0.0352, -0.0191,  0.0040],\n",
       "          [ 0.0077,  0.0196,  0.0333,  ..., -0.0209,  0.0083, -0.0261],\n",
       "          [ 0.0078,  0.0218,  0.0076,  ...,  0.0330, -0.0284,  0.0105],\n",
       "          ...,\n",
       "          [ 0.0120,  0.0293, -0.0190,  ...,  0.0362,  0.0350, -0.0057],\n",
       "          [ 0.0274,  0.0039, -0.0338,  ..., -0.0074, -0.0265, -0.0187],\n",
       "          [-0.0124,  0.0303,  0.0136,  ..., -0.0099, -0.0132,  0.0283]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.0020,  0.0200,  0.0297,  0.0015,  0.0186,  0.0150, -0.0192, -0.0045],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0114,  0.0316, -0.0152,  ..., -0.0010, -0.0122, -0.0070],\n",
       "          [ 0.0188, -0.0122, -0.0056,  ...,  0.0059,  0.0086,  0.0243],\n",
       "          [ 0.0070,  0.0123,  0.0159,  ..., -0.0200,  0.0037, -0.0076],\n",
       "          ...,\n",
       "          [ 0.0131, -0.0002,  0.0024,  ..., -0.0049,  0.0386,  0.0145],\n",
       "          [-0.0070, -0.0220, -0.0059,  ...,  0.0254,  0.0080,  0.0165],\n",
       "          [-0.0333,  0.0056, -0.0240,  ..., -0.0170, -0.0413,  0.0449]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0062,  0.0048,  0.0037,  ..., -0.0041, -0.0102, -0.0230],\n",
       "          [-0.0048, -0.0142, -0.0066,  ..., -0.0135, -0.0323, -0.0105],\n",
       "          [-0.0005,  0.0036, -0.0095,  ..., -0.0009,  0.0029,  0.0129],\n",
       "          ...,\n",
       "          [ 0.0196,  0.0199,  0.0036,  ...,  0.0157, -0.0033,  0.0126],\n",
       "          [ 0.0135, -0.0006,  0.0096,  ...,  0.0038, -0.0108,  0.0100],\n",
       "          [-0.0114, -0.0071,  0.0214,  ...,  0.0221,  0.0057,  0.0077]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 2.6481e-02, -2.0724e-02,  2.6143e-03,  ..., -5.7266e-03,\n",
       "            1.0851e-03, -2.5562e-02],\n",
       "          [ 1.3139e-02,  3.1025e-02, -1.6721e-02,  ..., -1.3271e-02,\n",
       "           -3.3017e-02, -1.1237e-02],\n",
       "          [ 6.4195e-03,  1.6776e-02,  6.9758e-04,  ..., -2.7071e-02,\n",
       "           -1.3596e-02, -4.3131e-03],\n",
       "          ...,\n",
       "          [ 1.3464e-03, -1.2758e-02, -7.3853e-03,  ..., -2.6107e-03,\n",
       "           -1.9506e-02, -7.6253e-03],\n",
       "          [ 2.1792e-02,  2.4489e-02, -2.7980e-02,  ..., -8.2444e-03,\n",
       "            1.0127e-03, -1.8248e-02],\n",
       "          [-1.0397e-03,  4.0402e-03,  1.2694e-05,  ..., -4.6420e-03,\n",
       "            1.3372e-02,  4.5002e-02]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0086, -0.0158,  0.0028,  ...,  0.0096,  0.0047,  0.0010],\n",
       "          [-0.0008,  0.0126,  0.0134,  ..., -0.0082,  0.0010, -0.0057],\n",
       "          [ 0.0009, -0.0022, -0.0011,  ..., -0.0012, -0.0098,  0.0392],\n",
       "          ...,\n",
       "          [ 0.0122, -0.0166, -0.0048,  ...,  0.0042, -0.0011,  0.0050],\n",
       "          [ 0.0385,  0.0041,  0.0143,  ..., -0.0026,  0.0071,  0.0060],\n",
       "          [ 0.0205, -0.0119,  0.0055,  ...,  0.0325, -0.0007,  0.0172]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0220, -0.0255,  0.0077,  ..., -0.0226,  0.0127, -0.0140],\n",
       "          [ 0.0151, -0.0098, -0.0081,  ...,  0.0078, -0.0018,  0.0264],\n",
       "          [-0.0207,  0.0211,  0.0241,  ..., -0.0120, -0.0069,  0.0196],\n",
       "          ...,\n",
       "          [-0.0250, -0.0043,  0.0222,  ...,  0.0238,  0.0233, -0.0191],\n",
       "          [ 0.0041,  0.0009, -0.0262,  ...,  0.0255,  0.0015,  0.0022],\n",
       "          [-0.0211, -0.0136, -0.0060,  ...,  0.0052,  0.0122, -0.0110]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 1.6108e-02,  2.6910e-02,  1.0496e-02,  1.9242e-02,  1.7567e-02,\n",
       "          -1.9467e-02, -1.9975e-02, -2.5707e-02,  2.1916e-02, -1.4649e-02,\n",
       "          -1.2233e-02,  2.6572e-02, -8.0825e-03,  1.6633e-02, -1.8024e-02,\n",
       "           8.7731e-03, -1.6954e-02, -3.9941e-03,  6.0628e-03, -2.0377e-02,\n",
       "           9.5420e-03,  1.1489e-02, -1.3165e-02, -2.2306e-02,  2.4951e-02,\n",
       "           1.7589e-02,  4.4021e-03, -1.5911e-02, -9.2448e-03, -7.6275e-03,\n",
       "          -3.4763e-03, -1.3895e-02, -9.7365e-03,  2.2221e-02, -1.8040e-02,\n",
       "          -2.0355e-02, -1.4567e-02, -9.5270e-03,  3.5066e-03, -8.4815e-03,\n",
       "          -5.6438e-03,  1.6957e-02, -2.5295e-02, -1.8144e-02, -1.7120e-02,\n",
       "          -1.5100e-02, -2.7627e-02, -3.9768e-03, -7.1619e-03, -2.7581e-02,\n",
       "          -1.3630e-02, -1.0199e-02, -1.2879e-02,  1.1655e-02,  2.5426e-02,\n",
       "           2.3216e-02, -1.3578e-02, -1.0016e-03, -5.7260e-03, -1.5069e-02,\n",
       "           1.6078e-02,  2.4130e-03, -2.6002e-02,  1.7775e-02, -3.7375e-03,\n",
       "           8.7779e-03,  1.9148e-02,  2.7363e-02,  6.1527e-03,  2.0712e-02,\n",
       "           2.4733e-02, -2.2557e-02, -4.9760e-03, -6.2083e-03,  1.1401e-02,\n",
       "          -2.3005e-02,  9.1726e-03, -1.5647e-02, -1.9695e-02,  3.8238e-03,\n",
       "           6.2404e-03,  2.5592e-02, -3.7940e-03,  1.5744e-02, -2.3226e-02,\n",
       "          -2.1467e-02, -5.6021e-03,  1.3269e-02,  5.7461e-03, -1.3441e-02,\n",
       "          -2.2260e-03,  1.5863e-02, -2.4162e-02, -6.0724e-04, -2.5382e-02,\n",
       "           1.2159e-04, -4.9427e-03,  2.4020e-02, -1.4634e-02,  1.9828e-02,\n",
       "          -8.9949e-03, -1.9632e-02,  2.4732e-02,  2.3995e-02, -2.6772e-02,\n",
       "          -1.1270e-02,  1.8823e-02, -2.3356e-02, -2.4497e-02,  1.8142e-02,\n",
       "           5.6538e-03,  1.6211e-02, -2.0466e-02,  2.0786e-02,  2.1462e-02,\n",
       "          -2.5340e-02,  1.4086e-03, -2.5518e-02,  8.7422e-03,  1.6440e-02,\n",
       "           1.3562e-02,  1.3388e-02, -2.1117e-02,  9.6240e-03,  1.7422e-02,\n",
       "           1.9199e-02,  1.6749e-03,  2.7838e-02, -1.4829e-02,  9.7322e-03,\n",
       "          -1.6886e-02,  2.1639e-02,  8.1311e-03,  2.1136e-02,  7.5247e-03,\n",
       "           1.8004e-02,  6.0240e-03, -1.5034e-02, -2.6544e-02, -1.1117e-02,\n",
       "          -8.4767e-03,  2.6323e-02, -1.5597e-02, -2.2703e-02, -2.5193e-02,\n",
       "           9.2586e-03,  1.3311e-02, -2.3921e-02,  2.3240e-02,  2.7836e-02,\n",
       "          -2.0417e-02,  2.5095e-02,  1.9127e-02,  2.1299e-02,  8.0907e-03,\n",
       "           2.1092e-02,  2.9075e-04, -1.7988e-03, -1.3215e-03, -1.8863e-02,\n",
       "           3.2176e-03,  4.2336e-03,  1.6778e-02,  1.3426e-02,  1.5262e-02,\n",
       "           2.1129e-02,  7.5668e-03,  8.1986e-03,  2.4179e-02,  1.8475e-02,\n",
       "          -1.8827e-02, -2.1130e-02, -2.0367e-02,  1.2983e-02,  6.2229e-03,\n",
       "           1.7775e-02,  1.0454e-02,  1.3108e-02,  1.6285e-02,  1.8031e-02,\n",
       "           2.1586e-02, -2.6373e-03, -2.7451e-03,  8.9103e-03, -1.4457e-02,\n",
       "          -1.4135e-02,  1.8046e-02, -1.9436e-02, -2.1003e-03,  9.1725e-03,\n",
       "           2.7858e-02, -2.5879e-02,  6.4448e-03,  2.6214e-02,  6.2287e-03,\n",
       "           1.1282e-02, -9.3283e-03,  1.7098e-02, -2.7902e-02,  1.6088e-02,\n",
       "          -1.4961e-02, -3.7645e-03, -1.0745e-02, -2.5831e-02,  4.7630e-03,\n",
       "           1.0258e-02, -1.7507e-02, -2.3211e-02, -1.2527e-02, -2.7740e-02,\n",
       "           4.4304e-03, -1.6517e-02,  3.2932e-03, -1.5697e-02,  2.1360e-02,\n",
       "          -1.0312e-02,  1.6438e-03,  1.8236e-02, -7.7353e-03,  2.0486e-02,\n",
       "          -2.1633e-02, -2.4960e-02, -2.1665e-02, -5.0290e-03, -2.0909e-02,\n",
       "          -2.6186e-02,  2.5796e-02,  8.9348e-03, -4.0458e-04, -1.5735e-02,\n",
       "          -1.3954e-02,  3.9690e-04, -2.2644e-02, -9.8912e-03,  1.7588e-02,\n",
       "           1.2050e-02,  2.1111e-02, -8.8010e-03, -1.8327e-02, -2.4031e-02,\n",
       "          -4.2289e-03,  3.9057e-03,  2.4297e-03, -1.2378e-02,  1.5352e-02,\n",
       "          -2.3463e-02, -6.5479e-03, -1.5860e-02, -8.3996e-03,  1.3978e-02,\n",
       "          -2.1189e-02,  1.9425e-02, -1.7805e-02,  2.6099e-02, -8.4526e-03,\n",
       "          -2.4936e-02, -1.8411e-02,  2.5621e-02,  2.5455e-03,  1.4275e-02,\n",
       "           1.8131e-02, -2.5305e-02, -2.5740e-02,  1.8863e-03, -1.2819e-02,\n",
       "           1.1770e-02, -3.1375e-04,  1.0694e-02, -2.3762e-02,  2.4954e-03,\n",
       "          -5.7940e-03, -2.5867e-02, -8.3776e-03, -2.5619e-02,  9.8201e-03,\n",
       "          -2.1129e-02,  5.3980e-03, -1.7370e-02,  2.1744e-02, -8.5460e-03,\n",
       "           1.1534e-02,  6.5011e-03, -1.6414e-02,  2.1606e-03, -2.1004e-02,\n",
       "          -2.7409e-02,  1.9709e-02,  5.0407e-03, -2.7468e-03, -3.3801e-03,\n",
       "           1.1567e-02, -1.4622e-02,  1.2765e-02, -1.2777e-02, -2.2846e-02,\n",
       "           1.1715e-03,  7.4341e-04,  2.0141e-02,  1.7229e-02, -4.9385e-03,\n",
       "           2.0340e-02,  8.1871e-03,  3.9152e-03,  1.5755e-02, -7.3406e-03,\n",
       "           2.2503e-02,  1.7884e-02, -8.0661e-03, -1.6003e-02,  1.1492e-02,\n",
       "          -1.5094e-02,  1.5192e-03, -1.5555e-02,  4.9543e-03, -1.7416e-02,\n",
       "          -2.3861e-02, -1.6007e-02, -9.1952e-03,  1.5816e-02, -4.3531e-03,\n",
       "           2.4407e-02,  1.6818e-02, -1.0274e-02,  1.8639e-02, -2.4698e-02,\n",
       "          -1.8586e-03, -2.1764e-02,  1.7666e-02, -1.7402e-02,  6.1675e-03,\n",
       "           2.1010e-02,  8.2521e-03, -1.9209e-03,  2.5009e-03, -7.7118e-03,\n",
       "          -2.7164e-02,  1.3466e-02,  9.5119e-03, -4.6353e-03,  1.2017e-02,\n",
       "          -1.8150e-02, -2.0123e-02, -1.5827e-02,  1.3902e-02, -2.6490e-02,\n",
       "           1.3609e-02, -1.4209e-02, -3.5219e-03, -4.9419e-03,  1.2755e-03,\n",
       "           1.8589e-02, -1.1701e-02, -7.5854e-04, -8.0607e-03, -1.9571e-02,\n",
       "           2.7519e-03,  2.4353e-02,  1.4001e-02,  1.8147e-02,  2.3707e-02,\n",
       "           4.2145e-03,  3.8295e-03, -2.1878e-02,  1.8229e-02,  8.2854e-04,\n",
       "           1.9561e-02, -2.2055e-02, -8.3342e-03, -2.2505e-02, -5.2268e-03,\n",
       "          -5.3373e-03, -8.7231e-03,  2.6178e-02, -1.9767e-02,  1.4062e-02,\n",
       "           2.5905e-03, -9.3984e-03, -3.1160e-03,  2.0154e-02, -2.1967e-02,\n",
       "           1.9916e-03, -4.2334e-03,  2.5418e-02, -2.7361e-02,  2.1507e-02,\n",
       "          -2.3761e-02, -6.1963e-03,  7.9839e-03,  2.2262e-02,  2.2129e-02,\n",
       "           2.0235e-02,  2.5594e-02,  2.2871e-02, -3.1500e-03,  7.5546e-03,\n",
       "          -1.8149e-02, -1.4700e-02, -8.3528e-03, -2.7262e-02, -2.2065e-02,\n",
       "           5.6915e-03,  2.5416e-02, -3.1434e-03,  1.3793e-02,  7.0686e-04,\n",
       "          -2.5166e-02,  9.3560e-03, -2.5461e-02,  2.5749e-02, -2.6607e-02,\n",
       "           4.6946e-03, -8.1591e-05,  1.1650e-02, -7.6399e-03,  2.3283e-02,\n",
       "          -2.2030e-02, -2.0807e-02, -1.7301e-02, -2.5764e-02, -1.1781e-02,\n",
       "           1.2158e-02, -1.0733e-02, -2.9037e-03,  3.2746e-03,  1.2679e-02,\n",
       "           9.5789e-03, -1.2230e-02,  1.9570e-02,  1.5886e-03, -6.9373e-03,\n",
       "          -9.3291e-03,  1.2852e-02, -2.8943e-03, -2.1758e-03, -1.3474e-02,\n",
       "           2.2341e-02, -2.1992e-02,  2.7482e-02, -2.3894e-02, -1.8447e-02,\n",
       "          -1.2284e-02, -1.3874e-02,  8.4756e-03, -2.1403e-03, -1.1132e-02,\n",
       "          -2.5698e-02, -9.2414e-03, -2.5476e-02, -2.4002e-02,  2.6906e-02,\n",
       "          -2.5364e-02, -4.3716e-04,  1.3151e-02, -1.8819e-02,  1.3052e-02,\n",
       "           2.3185e-02,  5.7755e-03, -2.7809e-02,  1.5167e-02,  7.1172e-03,\n",
       "           3.7736e-03, -2.6545e-02,  2.3964e-02,  1.6427e-02, -2.2228e-02,\n",
       "           7.7831e-03,  6.1023e-03, -3.4432e-03, -5.2448e-03, -1.6673e-02,\n",
       "           1.8387e-02, -8.7605e-03,  6.7997e-03,  2.6990e-02, -1.4294e-02,\n",
       "          -1.3423e-02, -1.3197e-02,  8.1788e-03,  2.7666e-02, -3.8253e-03,\n",
       "          -7.3652e-03, -1.4559e-02, -3.7668e-03, -7.8919e-03, -1.8350e-02,\n",
       "          -1.1329e-02,  2.4905e-02,  2.7779e-02, -2.3150e-02,  1.1986e-02,\n",
       "          -1.7791e-02,  5.8357e-03, -5.1770e-03, -9.8559e-04, -6.9077e-03,\n",
       "          -2.5447e-02,  2.1475e-02, -2.3089e-02, -2.5437e-02,  2.6904e-02,\n",
       "           1.8503e-03,  9.5390e-03, -5.9577e-03,  1.8542e-02, -1.0195e-02,\n",
       "          -1.5459e-02,  2.3994e-02,  1.1151e-03, -1.2729e-02, -1.0676e-02,\n",
       "           2.3923e-02,  1.3220e-02, -2.6508e-02, -5.9287e-03, -1.1001e-02,\n",
       "          -2.5742e-02, -1.9540e-02, -9.2314e-03, -9.9362e-03, -2.4305e-03,\n",
       "          -2.6999e-02,  2.6575e-02,  8.7805e-03, -1.0107e-02, -2.4038e-02,\n",
       "           1.3553e-02, -2.7912e-02,  2.0756e-03, -1.9189e-02,  1.3534e-02,\n",
       "          -2.6129e-02,  8.8608e-03, -1.0117e-02, -1.9970e-02,  2.1193e-02,\n",
       "           1.5868e-02,  1.7230e-02, -1.4415e-02, -2.5583e-02, -1.2007e-02,\n",
       "           1.8283e-02,  9.3313e-03,  1.5901e-02, -2.3370e-02, -2.2095e-02,\n",
       "           2.7467e-02, -7.0383e-03,  8.2495e-03,  2.5204e-02, -2.4841e-02,\n",
       "          -2.5917e-02,  2.4453e-02, -1.4418e-02,  2.1531e-03, -1.9545e-02,\n",
       "          -7.0081e-03,  6.0796e-03, -5.2912e-03,  2.5822e-02, -2.4604e-02,\n",
       "           9.1429e-03,  1.4182e-02,  1.7299e-02,  2.3509e-02,  1.1961e-03,\n",
       "          -6.7686e-03, -1.8984e-02,  1.2573e-02, -1.4383e-02,  1.5755e-02,\n",
       "          -1.8733e-02, -2.1261e-02,  3.9728e-03,  2.6150e-02, -1.7130e-02,\n",
       "           1.6233e-02,  1.9421e-02,  7.4106e-03,  9.0301e-03,  5.3834e-03,\n",
       "          -4.5639e-03,  2.1898e-02,  2.4063e-03, -7.5206e-03, -5.7136e-03,\n",
       "          -1.9303e-02,  1.6234e-02,  2.4125e-02,  2.2855e-02, -6.6304e-03,\n",
       "           2.7394e-02,  9.0735e-03, -1.8526e-02, -3.7880e-03, -2.5189e-02,\n",
       "           8.9197e-03,  2.0225e-03,  2.4213e-02,  1.3694e-02,  1.9736e-03,\n",
       "           2.5753e-02,  1.3867e-03, -7.9876e-03, -1.4508e-02,  3.7679e-03,\n",
       "           2.2948e-02,  2.5003e-02,  1.8322e-02,  8.2956e-04,  2.3245e-02,\n",
       "          -1.8178e-02,  1.9095e-02, -1.3333e-02,  7.9457e-03,  2.7350e-02,\n",
       "          -1.3942e-02, -1.6020e-02,  1.2461e-02,  7.1027e-03, -5.3323e-03,\n",
       "           1.7173e-02, -1.8365e-02,  1.4260e-02, -2.8763e-03,  2.4699e-02,\n",
       "           1.5003e-03,  1.2086e-02,  2.4944e-02,  1.2572e-02,  2.5801e-02,\n",
       "          -3.6357e-03,  1.3196e-02,  2.7544e-02, -5.8887e-03,  2.4983e-02,\n",
       "          -2.2193e-02,  4.4124e-03, -1.9383e-02,  5.4183e-03, -6.5122e-03],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0072,  0.0338,  0.0311,  ..., -0.0384,  0.0060,  0.0011],\n",
       "          [ 0.0391,  0.0376,  0.0340,  ...,  0.0119, -0.0206,  0.0002],\n",
       "          [ 0.0056, -0.0092, -0.0262,  ...,  0.0288, -0.0367, -0.0013],\n",
       "          ...,\n",
       "          [-0.0143, -0.0243,  0.0093,  ..., -0.0106, -0.0102,  0.0124],\n",
       "          [ 0.0183, -0.0238, -0.0099,  ...,  0.0377,  0.0083,  0.0133],\n",
       "          [-0.0364, -0.0188,  0.0371,  ..., -0.0227, -0.0137, -0.0284]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0228,  0.0174,  0.0155, -0.0225,  0.0112,  0.0081, -0.0311,  0.0081],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0156,  0.0156, -0.0063,  ...,  0.0044, -0.0140, -0.0147],\n",
       "          [ 0.0121,  0.0088,  0.0027,  ..., -0.0080,  0.0052,  0.0199],\n",
       "          [ 0.0064,  0.0178, -0.0140,  ...,  0.0190,  0.0128, -0.0077],\n",
       "          ...,\n",
       "          [-0.0052,  0.0067, -0.0110,  ..., -0.0048, -0.0182, -0.0206],\n",
       "          [-0.0225, -0.0190, -0.0087,  ...,  0.0015,  0.0218,  0.0377],\n",
       "          [-0.0007,  0.0123, -0.0104,  ..., -0.0047,  0.0185, -0.0239]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0128, -0.0350,  0.0281,  ..., -0.0089, -0.0224,  0.0056],\n",
       "          [ 0.0170, -0.0153,  0.0354,  ..., -0.0063, -0.0017, -0.0125],\n",
       "          [-0.0040,  0.0207,  0.0024,  ...,  0.0084,  0.0166, -0.0010],\n",
       "          ...,\n",
       "          [ 0.0140, -0.0295, -0.0025,  ...,  0.0066, -0.0195, -0.0072],\n",
       "          [-0.0150,  0.0090,  0.0070,  ..., -0.0262, -0.0443,  0.0173],\n",
       "          [ 0.0159, -0.0201, -0.0059,  ..., -0.0195,  0.0431,  0.0099]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0141, -0.0110,  0.0155,  ...,  0.0072,  0.0175, -0.0073],\n",
       "          [ 0.0280,  0.0124, -0.0143,  ..., -0.0018, -0.0143,  0.0240],\n",
       "          [ 0.0076, -0.0141, -0.0182,  ..., -0.0124,  0.0147, -0.0311],\n",
       "          ...,\n",
       "          [-0.0201, -0.0122, -0.0074,  ..., -0.0100, -0.0051, -0.0183],\n",
       "          [ 0.0096,  0.0095, -0.0307,  ...,  0.0173,  0.0051,  0.0069],\n",
       "          [ 0.0278, -0.0110,  0.0003,  ...,  0.0169, -0.0160,  0.0101]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0045, -0.0154, -0.0205,  ..., -0.0246,  0.0123,  0.0278],\n",
       "          [-0.0011, -0.0140, -0.0128,  ...,  0.0076,  0.0047,  0.0254],\n",
       "          [-0.0002,  0.0400, -0.0158,  ...,  0.0025,  0.0166,  0.0040],\n",
       "          ...,\n",
       "          [-0.0104,  0.0100, -0.0145,  ...,  0.0022, -0.0307,  0.0146],\n",
       "          [ 0.0280, -0.0226,  0.0212,  ..., -0.0001,  0.0224,  0.0181],\n",
       "          [-0.0165, -0.0281,  0.0237,  ...,  0.0144, -0.0013, -0.0249]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-1.6132e-02, -4.4629e-05,  2.7558e-02,  ...,  9.9704e-03,\n",
       "            2.4939e-02, -1.4856e-02],\n",
       "          [-6.2681e-03, -2.5858e-02,  9.5215e-03,  ..., -2.1118e-03,\n",
       "            2.7435e-02, -2.6766e-02],\n",
       "          [ 2.0347e-02,  1.8473e-02,  1.3629e-02,  ...,  1.0044e-02,\n",
       "            2.1465e-02,  6.6976e-03],\n",
       "          ...,\n",
       "          [ 2.2360e-02,  2.3272e-02, -2.1178e-02,  ..., -1.0226e-02,\n",
       "           -2.2729e-02,  1.2983e-02],\n",
       "          [ 2.4341e-02,  2.6811e-02,  2.0205e-02,  ...,  1.9030e-02,\n",
       "            1.0806e-02, -6.8283e-03],\n",
       "          [-1.2143e-02,  1.5472e-02,  5.5436e-03,  ..., -5.1340e-03,\n",
       "           -1.9340e-02,  1.7241e-02]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-2.0416e-02, -4.5686e-03,  6.4218e-03, -3.6588e-03, -4.0311e-03,\n",
       "          -1.5787e-02,  2.2906e-02, -2.4556e-02,  2.4673e-02, -9.2997e-03,\n",
       "           2.0879e-02, -1.4190e-02,  2.4645e-02,  1.0561e-02,  8.1307e-03,\n",
       "          -7.3012e-03, -2.5343e-02, -9.6071e-03,  1.6562e-03,  3.8005e-03,\n",
       "          -2.3546e-02,  2.6653e-02, -1.3424e-02,  1.8466e-02,  1.9949e-02,\n",
       "           2.7539e-02, -1.5719e-02,  1.9695e-02, -1.1734e-02, -2.5380e-02,\n",
       "           1.0220e-02, -2.2387e-02,  1.8379e-02,  9.9329e-04,  2.9900e-04,\n",
       "           1.1153e-02,  7.7054e-03,  2.1688e-02, -2.0019e-02,  4.9127e-03,\n",
       "           4.4630e-03, -1.1493e-02, -1.3605e-03,  4.2810e-03,  9.5582e-03,\n",
       "          -1.3677e-02, -7.4062e-04,  1.0016e-02,  1.7114e-02,  1.1256e-03,\n",
       "           2.0589e-03,  1.7176e-03, -2.4990e-03,  1.6115e-03, -7.9721e-03,\n",
       "          -3.7609e-04,  2.0579e-02, -2.4925e-02,  1.7769e-02,  1.9886e-02,\n",
       "           1.9505e-02, -2.4155e-02, -2.4695e-02,  2.0694e-03, -2.7593e-02,\n",
       "           3.6886e-03,  2.3072e-02,  1.9209e-02,  1.0452e-02, -2.4766e-02,\n",
       "           2.3688e-02, -2.9401e-03,  1.9822e-02, -1.3718e-02, -1.6243e-02,\n",
       "           1.5339e-02, -2.7782e-02,  1.5457e-02,  4.0361e-03, -2.3135e-02,\n",
       "           4.0882e-03, -2.5489e-02,  2.4467e-02,  1.6732e-02, -5.3177e-03,\n",
       "           1.4173e-02, -2.2527e-02, -1.8619e-02, -2.1881e-02,  2.0708e-02,\n",
       "          -2.0176e-02, -4.0366e-03,  1.0122e-02,  1.2002e-02, -1.1212e-02,\n",
       "           2.0216e-02,  2.0887e-02,  4.7580e-03, -1.2467e-02,  2.7014e-02,\n",
       "          -1.6194e-02, -1.3341e-03,  2.7760e-02,  2.6832e-02, -2.3048e-02,\n",
       "          -1.9574e-02,  1.6438e-02,  4.0499e-03, -1.5318e-02, -1.0815e-02,\n",
       "          -7.3606e-03, -1.2315e-02, -1.0517e-02, -1.9714e-02, -2.5413e-02,\n",
       "          -2.0660e-02, -3.9822e-03,  7.8381e-03, -1.8839e-02, -2.3356e-02,\n",
       "           6.2118e-03,  2.6007e-02, -2.0769e-02, -1.9041e-03, -1.9605e-02,\n",
       "           1.3449e-02, -1.5187e-02,  2.6681e-02,  1.8612e-02, -1.7194e-02,\n",
       "           8.2575e-03, -3.7442e-03,  2.3885e-02,  6.1208e-03, -4.2206e-03,\n",
       "           2.0000e-02,  4.5201e-03, -2.4032e-02, -1.6103e-02, -6.3608e-03,\n",
       "          -6.9217e-03, -2.5447e-02, -1.9613e-02,  1.9804e-02, -1.8258e-02,\n",
       "           2.6784e-03, -2.6639e-02, -2.0891e-02, -2.0841e-02, -1.2883e-02,\n",
       "          -2.6022e-02, -4.3878e-03,  1.6932e-02, -1.1501e-02,  1.6845e-02,\n",
       "           2.3699e-02,  3.7466e-03,  7.1150e-03, -4.3244e-03,  3.2638e-03,\n",
       "          -5.2324e-03,  2.7600e-02, -4.8037e-03, -6.8987e-03,  2.9173e-03,\n",
       "           1.0598e-02,  2.7889e-02, -1.5886e-02, -2.3886e-02, -6.1364e-03,\n",
       "           5.3373e-04,  3.5842e-03,  1.8766e-02,  2.4906e-02, -1.0289e-02,\n",
       "          -2.7935e-02,  2.3651e-02, -2.1816e-02,  1.7605e-02,  2.3963e-02,\n",
       "          -1.3617e-02,  1.2585e-02, -1.9512e-02, -1.9672e-03, -1.9378e-02,\n",
       "           1.8003e-02, -1.6974e-03, -2.4352e-02,  5.3002e-03,  1.3710e-02,\n",
       "          -4.3674e-04,  2.6205e-02,  1.1123e-02,  1.4999e-02,  9.1712e-03,\n",
       "          -9.6540e-03,  1.2672e-03,  1.9705e-02,  9.5794e-03,  2.7382e-02,\n",
       "           7.9113e-03,  6.4503e-03,  6.3643e-03,  2.7581e-02,  1.4971e-02,\n",
       "           2.6706e-02,  2.5152e-02,  1.3640e-02,  1.4166e-02, -1.6311e-02,\n",
       "          -2.4477e-02, -1.9864e-02, -2.5108e-02, -2.7164e-02,  2.4375e-02,\n",
       "           2.8531e-03,  1.0907e-02, -1.9307e-02, -2.5044e-02,  1.5269e-02,\n",
       "           3.5361e-03, -1.8822e-02,  2.4761e-02,  2.1859e-02,  2.2090e-02,\n",
       "          -9.6187e-03,  9.6256e-03, -2.4884e-02,  1.0689e-02, -1.8660e-02,\n",
       "          -1.3056e-02, -2.6933e-02,  2.7521e-02,  1.4730e-02, -1.0562e-02,\n",
       "           8.5917e-03,  1.7988e-03,  9.8082e-03,  2.2353e-02,  4.4224e-03,\n",
       "          -2.7403e-02, -3.3552e-03,  4.1971e-03,  1.4953e-02, -1.7694e-02,\n",
       "          -2.7281e-02,  1.9797e-02,  1.0933e-02, -1.9690e-02, -5.9421e-03,\n",
       "           2.3641e-02, -1.3460e-02,  1.7829e-02, -1.7353e-02,  1.8741e-02,\n",
       "          -2.3931e-02, -6.2607e-03, -2.5884e-02, -4.7331e-03,  1.6714e-02,\n",
       "           6.1937e-03,  1.5015e-02, -1.6790e-02,  5.7441e-03, -3.2832e-03,\n",
       "           1.6824e-02,  1.3715e-02,  4.7460e-03, -1.3134e-02,  2.5540e-02,\n",
       "          -1.3315e-02, -5.4201e-03, -2.5918e-02,  9.9906e-03,  2.3722e-02,\n",
       "          -4.3261e-03,  1.6036e-02,  4.2027e-04, -1.9677e-02,  1.6621e-03,\n",
       "          -1.6898e-03,  2.1439e-02,  1.6984e-02, -1.8689e-02,  2.1790e-02,\n",
       "           8.9010e-03,  4.4867e-03,  1.9238e-02,  1.6297e-02,  2.3438e-02,\n",
       "          -1.1383e-02, -1.2199e-02,  2.1169e-02, -1.7884e-02, -1.8392e-02,\n",
       "          -2.0696e-02,  2.2754e-02, -1.3824e-02,  1.2845e-02, -2.2589e-02,\n",
       "           1.9678e-02, -8.6833e-03, -7.0150e-03, -2.3863e-02,  1.6198e-02,\n",
       "          -1.1497e-02, -7.7109e-03,  1.2777e-03, -1.7027e-02,  8.3617e-03,\n",
       "           1.7939e-02, -7.2608e-03,  2.3709e-02,  1.8106e-02,  1.8863e-03,\n",
       "          -8.8891e-03, -1.9088e-02, -2.1964e-02, -2.2179e-02, -1.7197e-02,\n",
       "           1.9255e-02, -1.2958e-02,  1.3909e-02, -9.3655e-03, -1.4200e-03,\n",
       "          -2.0854e-02,  3.1784e-03,  2.1784e-02,  1.9047e-02,  1.6636e-02,\n",
       "           2.8888e-03,  3.4222e-04,  4.3499e-03, -2.3318e-02, -1.0533e-02,\n",
       "           2.2142e-02, -2.4839e-02, -1.1959e-02, -2.3948e-02, -2.0064e-02,\n",
       "           2.3337e-02, -3.2596e-03, -2.2403e-03, -2.8376e-03, -2.6816e-02,\n",
       "           2.1691e-02, -1.0785e-02,  2.2821e-02,  2.1294e-02,  6.0570e-03,\n",
       "          -2.6617e-02,  9.2553e-04, -1.6417e-02, -6.4634e-03, -4.8709e-03,\n",
       "           1.1035e-02,  2.5104e-02,  7.4696e-03, -1.0168e-02,  6.1575e-03,\n",
       "           1.8335e-02, -2.4577e-02, -2.4859e-02,  2.6322e-02,  1.8127e-02,\n",
       "          -2.7792e-02, -1.8782e-02, -8.9076e-03, -2.3580e-03,  2.6595e-02,\n",
       "          -2.6798e-02, -1.1372e-02,  1.7744e-03,  2.7245e-02, -3.1873e-04,\n",
       "           1.3348e-02, -1.0367e-02, -2.9347e-04, -7.6425e-03, -1.9086e-02,\n",
       "           2.5765e-02,  6.8938e-03, -9.2087e-03, -3.6930e-03,  2.3190e-02,\n",
       "          -8.7884e-03,  2.4848e-02,  2.1717e-02,  1.0941e-02,  1.2192e-02,\n",
       "          -2.0788e-02,  2.6508e-02, -2.0512e-02,  9.6948e-03, -1.6087e-02,\n",
       "          -8.3697e-03, -2.7472e-02,  4.6773e-03, -2.6765e-02, -1.3590e-02,\n",
       "           2.2820e-02, -9.8160e-03,  5.0796e-04,  1.1929e-02, -1.5555e-02,\n",
       "          -1.7886e-02,  1.4431e-02,  3.7974e-03,  2.2273e-02, -8.7266e-03,\n",
       "          -7.4212e-03,  1.2672e-02, -2.4469e-02, -1.8578e-02,  8.0301e-06,\n",
       "           1.8916e-02,  1.3126e-02,  1.7804e-02, -6.5175e-03, -8.2834e-03,\n",
       "          -1.6831e-02, -8.0545e-03, -1.5469e-02, -2.8600e-03, -2.3699e-02,\n",
       "           2.1142e-02, -6.0577e-03, -2.5892e-02,  1.6028e-02,  3.2238e-03,\n",
       "           1.7601e-02, -1.1944e-03, -1.1430e-02,  1.6833e-02, -2.7896e-02,\n",
       "           2.1089e-04,  2.2755e-02,  2.3136e-02,  2.0773e-02, -2.0630e-02,\n",
       "           2.0142e-02, -4.2345e-03, -1.5602e-02, -1.0716e-02,  1.9578e-02,\n",
       "           1.8749e-02, -2.0889e-02, -1.0335e-02,  1.6042e-02, -1.2987e-02,\n",
       "           6.1415e-03, -9.4976e-03, -1.9233e-02, -3.8145e-04, -1.1492e-02,\n",
       "          -1.9362e-02,  2.3928e-02, -1.3638e-02,  2.5729e-02, -3.4262e-04,\n",
       "           1.1262e-02, -1.9216e-02,  1.8294e-02,  2.3054e-03,  1.6371e-02,\n",
       "          -2.2654e-02,  1.3957e-03,  1.2686e-02,  2.4267e-02, -2.5109e-02,\n",
       "          -4.7451e-03,  9.9268e-03, -9.2659e-03, -1.0914e-02,  1.4281e-02,\n",
       "           2.7330e-02,  6.4419e-03,  2.4584e-02, -2.2009e-02, -2.3348e-02,\n",
       "           6.1631e-03,  1.3281e-02,  1.5006e-02,  2.1124e-02,  2.3329e-02,\n",
       "          -1.0758e-02,  2.1145e-02, -1.3797e-02, -1.2761e-02,  9.5636e-03,\n",
       "           1.1836e-02,  1.2249e-02, -1.6587e-02, -9.5707e-03, -4.1110e-04,\n",
       "          -2.6606e-02,  1.2896e-02,  1.8195e-02,  9.4204e-03,  2.3470e-02,\n",
       "          -7.0377e-03, -6.1660e-03,  8.7776e-03, -2.6338e-02,  1.8050e-02,\n",
       "          -1.2424e-02, -2.0567e-02, -1.5613e-02,  2.3519e-03,  1.5475e-02,\n",
       "           1.8618e-02, -2.7651e-02,  2.5371e-02,  1.2910e-02, -3.8866e-03,\n",
       "          -5.3775e-03, -4.4649e-03,  1.1010e-02, -1.4220e-02,  1.3942e-02,\n",
       "           2.3426e-02,  2.3327e-02, -2.1587e-02, -2.6954e-02, -2.1103e-02,\n",
       "           3.2744e-03,  1.1298e-02, -2.6266e-02,  1.2618e-02, -9.8124e-04,\n",
       "          -2.5602e-02,  1.2094e-03,  7.2272e-04, -2.5191e-03,  1.9449e-03,\n",
       "           5.9002e-03,  8.5696e-03, -1.2601e-03,  2.1044e-02,  9.2996e-04,\n",
       "          -3.1435e-03,  1.3891e-02,  4.9438e-03, -2.3091e-02,  2.3288e-02,\n",
       "          -7.6588e-03, -1.5898e-02, -1.3960e-02,  5.3787e-03, -1.3570e-02,\n",
       "           2.1764e-02, -9.9226e-03,  1.3488e-02, -2.5172e-02, -3.6480e-03,\n",
       "          -1.9688e-02,  1.3807e-02,  2.2055e-02, -1.3203e-02,  1.5283e-02,\n",
       "          -1.4631e-02, -1.2496e-02,  1.6718e-02,  1.6774e-02, -1.9335e-02,\n",
       "           4.6935e-03, -9.6710e-03,  3.1738e-04, -1.7178e-02, -2.3660e-02,\n",
       "           1.6531e-02, -1.5465e-02, -2.3106e-02, -1.9932e-02,  1.7056e-02,\n",
       "          -1.9310e-03,  5.3749e-03, -1.5591e-02, -1.2850e-02,  4.1551e-03,\n",
       "          -7.0562e-03,  2.4447e-02, -2.2029e-02,  9.3927e-03, -1.1188e-02,\n",
       "          -5.4069e-03, -1.4011e-03,  6.0512e-04,  6.5310e-03,  2.1612e-03,\n",
       "           8.1011e-03,  1.2948e-02,  1.7439e-02, -8.7253e-03,  1.5624e-02,\n",
       "          -1.7066e-02,  5.2450e-03,  8.7279e-03, -2.6322e-02,  8.7179e-03,\n",
       "           1.6796e-02,  2.7944e-02, -2.5697e-02,  1.1418e-02, -2.3461e-02,\n",
       "          -2.4844e-02,  6.4187e-03,  4.8063e-03, -1.0964e-02,  2.0551e-02,\n",
       "           5.6845e-03, -9.0586e-03,  1.6061e-02,  2.0599e-02, -2.8776e-03,\n",
       "          -5.1304e-03, -2.0472e-02,  5.4580e-03, -1.9824e-02, -7.2707e-03,\n",
       "          -5.7619e-03, -1.9162e-02, -8.6853e-03,  2.4618e-02, -2.4506e-02,\n",
       "          -1.9922e-02,  1.9456e-02, -1.0853e-02, -3.1915e-03, -1.4154e-02,\n",
       "          -1.1002e-03,  2.4014e-02, -2.3744e-03, -2.6429e-02, -9.7691e-03,\n",
       "          -2.7715e-02,  1.8801e-04,  7.3674e-03, -2.5038e-02,  6.2313e-03],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0210, -0.0186,  0.0007,  ..., -0.0251,  0.0245, -0.0273],\n",
       "          [ 0.0058, -0.0363,  0.0047,  ..., -0.0004,  0.0127, -0.0234],\n",
       "          [-0.0180,  0.0269, -0.0361,  ...,  0.0159,  0.0115,  0.0354],\n",
       "          ...,\n",
       "          [ 0.0292, -0.0190, -0.0390,  ..., -0.0270, -0.0347, -0.0192],\n",
       "          [-0.0147,  0.0218,  0.0136,  ...,  0.0085, -0.0296, -0.0312],\n",
       "          [-0.0167, -0.0243,  0.0173,  ..., -0.0269,  0.0272,  0.0234]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0391,  0.0131,  0.0365,  0.0129,  0.0324,  0.0059, -0.0186, -0.0096],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-2.1411e-02,  1.8572e-02, -7.1713e-04,  ..., -2.5031e-03,\n",
       "           -1.0897e-02, -7.8325e-03],\n",
       "          [ 1.8554e-03, -1.6286e-02,  1.4769e-02,  ..., -2.3362e-03,\n",
       "            2.0914e-02,  1.2555e-02],\n",
       "          [-3.1094e-02,  1.2151e-02,  6.6760e-03,  ...,  1.0422e-02,\n",
       "            2.3372e-02,  7.2748e-03],\n",
       "          ...,\n",
       "          [ 5.8888e-03,  1.0547e-02, -1.1437e-02,  ...,  2.0689e-02,\n",
       "            4.5371e-03,  1.4652e-02],\n",
       "          [-9.3604e-03, -1.0182e-03, -1.9049e-02,  ...,  4.8442e-03,\n",
       "            1.0815e-02,  2.0581e-02],\n",
       "          [ 2.7150e-02,  3.5820e-02, -9.6363e-03,  ...,  1.4816e-02,\n",
       "           -2.6900e-02, -7.0942e-05]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0005, -0.0119,  0.0170,  ...,  0.0005,  0.0018,  0.0323],\n",
       "          [-0.0127, -0.0064,  0.0017,  ..., -0.0138, -0.0298, -0.0064],\n",
       "          [-0.0072, -0.0071, -0.0052,  ..., -0.0066,  0.0189, -0.0124],\n",
       "          ...,\n",
       "          [-0.0097, -0.0045,  0.0006,  ..., -0.0066,  0.0178,  0.0168],\n",
       "          [ 0.0403, -0.0359,  0.0129,  ...,  0.0093,  0.0042,  0.0379],\n",
       "          [ 0.0068,  0.0090, -0.0218,  ...,  0.0193,  0.0165, -0.0400]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0130,  0.0156, -0.0292,  ...,  0.0015,  0.0236,  0.0125],\n",
       "          [-0.0220,  0.0106, -0.0033,  ...,  0.0004, -0.0122, -0.0033],\n",
       "          [-0.0017, -0.0151,  0.0032,  ...,  0.0027,  0.0189, -0.0369],\n",
       "          ...,\n",
       "          [ 0.0043, -0.0107,  0.0082,  ..., -0.0008,  0.0035,  0.0129],\n",
       "          [ 0.0123, -0.0118,  0.0073,  ..., -0.0041, -0.0165,  0.0200],\n",
       "          [ 0.0335,  0.0004,  0.0100,  ..., -0.0061, -0.0124,  0.0295]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0319,  0.0328, -0.0181,  ..., -0.0128,  0.0045, -0.0066],\n",
       "          [-0.0175, -0.0071,  0.0014,  ..., -0.0071,  0.0167,  0.0142],\n",
       "          [-0.0050, -0.0160,  0.0286,  ..., -0.0009,  0.0003, -0.0074],\n",
       "          ...,\n",
       "          [-0.0055,  0.0390,  0.0033,  ..., -0.0054, -0.0287,  0.0235],\n",
       "          [-0.0006,  0.0349,  0.0079,  ...,  0.0050, -0.0115, -0.0377],\n",
       "          [ 0.0179, -0.0087,  0.0077,  ..., -0.0334, -0.0013,  0.0071]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True)])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replace_self_attention_with_cross_frame_attention(\n",
    "                unet=pipeline.unet,\n",
    "                n_input_images=runfig.n_input_images,\n",
    "                to_k_other_frames=runfig.cross_frame_attention.to_k_other_frames,\n",
    "                with_self_attention=runfig.cross_frame_attention.with_self_attention,\n",
    "                random_others=runfig.cross_frame_attention.random_others,\n",
    "                use_lora_in_cfa=\"cfa\" in runfig.model.pose_cond_mode or \"sa\" in runfig.model.pose_cond_mode,\n",
    "                use_temb_in_lora=runfig.cross_frame_attention.use_temb_cond,\n",
    "                temb_out_size=8,\n",
    "                pose_cond_dim=runfig.model.pose_cond_dim,\n",
    "                rank=runfig.model.pose_cond_lora_rank,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('zero-conv', 'no_residual_connection')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runfig.cross_frame_attention.last_layer_mode,finetune_config.training.changed_cfa_last_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runfig.cross_frame_attention.with_self_attention,runfig.cross_frame_attention.random_others,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_cfa_config(\n",
    "   \n",
    "    pipeline: CustomInstructPix2pixDiffusionPipeline,\n",
    "):\n",
    "    if runfig.cross_frame_attention.mode == \"add_in_existing_block\":\n",
    "        update_cross_frame_attention_config(\n",
    "            pipeline.unet,\n",
    "            runfig.n_input_images,\n",
    "            runfig.cross_frame_attention.to_k_other_frames,\n",
    "            runfig.cross_frame_attention.with_self_attention,\n",
    "            runfig.cross_frame_attention.random_others,\n",
    "            change_self_attention_layers=False,  # should have custom cfa layers\n",
    "        )\n",
    "    elif runfig.cross_frame_attention.mode == \"pretrained\":\n",
    "        update_cross_frame_attention_config(\n",
    "            pipeline.unet,\n",
    "            3,\n",
    "            2,\n",
    "            runfig.cross_frame_attention.with_self_attention,\n",
    "            runfig.cross_frame_attention.random_others,\n",
    "            change_self_attention_layers=True,  # should have cfa is sa layers\n",
    "        )\n",
    "    else:\n",
    "        raise NotImplementedError(\n",
    "            f\"did not implement different n_input_images for cfa.mode={runfig.cross_frame_attention.mode}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change last-layer-mode to no_residual_connection\n"
     ]
    }
   ],
   "source": [
    "if finetune_config.training.changed_cfa_last_layer != runfig.cross_frame_attention.last_layer_mode:\n",
    "        print(\"Change last-layer-mode to\", finetune_config.training.changed_cfa_last_layer)\n",
    "        update_last_layer_mode(\n",
    "            pipeline.unet,\n",
    "            finetune_config.training.changed_cfa_last_layer,\n",
    "        )\n",
    "update_vol_rend_inject_noise_sigma(\n",
    "        pipeline.unet, 0.0\n",
    "    )\n",
    "    # disable n_novel_images\n",
    "update_n_novel_images(\n",
    "        pipeline.unet, 0\n",
    "\n",
    "    )\n",
    "update_cfa_config(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded LoRA weights into model\n"
     ]
    }
   ],
   "source": [
    "if runfig.model.pose_cond_mode != \"none\":\n",
    "        # Set correct lora layers\n",
    "        unet_lora_attn_procs, unet_lora_parameters = add_pose_cond_to_attention_layers(\n",
    "            pipeline.unet,\n",
    "            rank=runfig.model.pose_cond_lora_rank,\n",
    "            pose_cond_dim=runfig.model.pose_cond_dim,\n",
    "            only_cross_attention=\"sa\" not in runfig.model.pose_cond_mode,\n",
    "        )\n",
    "\n",
    "        if unet_lora_parameters is not None:\n",
    "            in_dir = os.path.join(runfig.pretrained_model_name_or_path, \"unet\")\n",
    "            try:\n",
    "                lora_state_dict, network_alpha = LoraLoaderMixin.lora_state_dict(in_dir, weight_name=\"pytorch_lora_weights.safetensors\")\n",
    "            except:\n",
    "                lora_state_dict, network_alpha = LoraLoaderMixin.lora_state_dict(in_dir, weight_name=\"pytorch_lora_weights.bin\")\n",
    "            lora_state_dict = {k.replace(\"unet.\", \"\"): v for k, v in lora_state_dict.items()}\n",
    "            pipeline.unet.load_state_dict(lora_state_dict, strict=False)\n",
    "            print(\"Loaded LoRA weights into model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = pipeline.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sa-ca'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runfig.model.pose_cond_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "@torch.no_grad()\n",
    "def process_batch(\n",
    "    \n",
    "   \n",
    "    pipeline,\n",
    "   \n",
    "    batch,\n",
    "    guidance_scale=16,\n",
    "    image_guidance_scale: float = 1.0,\n",
    "    \n",
    "):\n",
    "    \n",
    "    model_config=runfig.model\n",
    "    cfa_config=runfig.cross_frame_attention\n",
    "    io_config=runfig\n",
    "    orig_hw=(512, 640)\n",
    "    num_inference_steps=50\n",
    "    n_repeat_generation=1\n",
    "    generator = torch.Generator(\"cuda\").manual_seed(42)\n",
    "\n",
    "    # combine\n",
    "    \n",
    "    batch[\"images\"] = batch[\"images\"].to(\"cuda\").unsqueeze(0)\n",
    "    batch[\"target_imgs\"] = batch[\"target_imgs\"].to(\"cuda\").unsqueeze(0) \n",
    "    batch[\"pose\"] = batch[\"pose\"].to(\"cuda\").unsqueeze(0)\n",
    "    batch[\"K\"] = batch[\"K\"].to(\"cuda\").unsqueeze(0)\n",
    "    batch[\"intensity_stats\"] = batch[\"intensity_stats\"].to(\"cuda\").unsqueeze(0)\n",
    "    batch[\"bbox\"] = batch[\"bbox\"].to(\"cuda\").unsqueeze(0)\n",
    "\n",
    "    # check if need to change n_input_images\n",
    "    if runfig.n_input_images != batch[\"pose\"].shape[1]:\n",
    "        runfig.n_input_images = batch[\"pose\"].shape[1]\n",
    "        runfig.cross_frame_attention.to_k_other_frames = batch[\"pose\"].shape[1] - 1\n",
    "        runfig.model.n_input_images = batch[\"pose\"].shape[1]\n",
    "        update_cfa_config(runfig, pipeline)\n",
    "\n",
    "    # alwasy set to 0\n",
    "    batch[\"intensity_stats\"] *= 0\n",
    "\n",
    "    # create images\n",
    "    batch_size = len(batch[\"prompt\"])\n",
    "\n",
    "    batch[\"images\"] = 2*batch[\"images\"]-1\n",
    "    batch[\"target_imgs\"] = 2*batch[\"target_imgs\"]-1\n",
    "    # parse batch\n",
    "    # collapse K dimension into batch dimension (no concatenation happening)\n",
    "    batch[\"prompt\"] = [cap for cap in batch[\"prompt\"]]\n",
    "    prompt = collapse_prompt_to_batch_dim(batch[\"prompt\"],3)\n",
    "   \n",
    "    \n",
    "    _, pose = collapse_tensor_to_batch_dim(batch[\"pose\"])\n",
    "    _, K = collapse_tensor_to_batch_dim(batch[\"K\"])\n",
    "    _, intensity_stats = collapse_tensor_to_batch_dim(batch[\"intensity_stats\"])\n",
    "    bbox = batch[\"bbox\"]\n",
    "\n",
    "    _, known_images = collapse_tensor_to_batch_dim(batch[\"images\"])\n",
    "    known_images = known_images.to(pipeline.device)\n",
    "    known_images = known_images.squeeze(1)\n",
    "    print(known_images.shape)\n",
    "\n",
    "    K = K.squeeze(1)[..., :3, :3]\n",
    "    pose = pose.squeeze(1)\n",
    "    intensity_stats = intensity_stats.squeeze(1)\n",
    "\n",
    "    # build cross_attention_kwargs\n",
    "    cross_attention_kwargs = build_cross_attention_kwargs(\n",
    "        model_config=runfig.model,\n",
    "        cfa_config=runfig.cross_frame_attention,\n",
    "        pose=pose,\n",
    "        K=K,\n",
    "        intensity_stats=intensity_stats,\n",
    "        bbox=bbox,\n",
    "        orig_hw=orig_hw,\n",
    "    )\n",
    "    if \"pose_cond\" in cross_attention_kwargs:\n",
    "            cross_attention_kwargs[\"pose_cond\"] = torch.cat([cross_attention_kwargs[\"pose_cond\"]] * 3)\n",
    "    if \"unproj_reproj_kwargs\" in cross_attention_kwargs:\n",
    "        proj_kwargs = cross_attention_kwargs[\"unproj_reproj_kwargs\"]\n",
    "        proj_kwargs[\"pose\"] = torch.cat([proj_kwargs[\"pose\"]] * 3)\n",
    "        proj_kwargs[\"K\"] = torch.cat([proj_kwargs[\"K\"]] * 3)\n",
    "        proj_kwargs[\"bbox\"] = torch.cat([proj_kwargs[\"bbox\"]] * 3)\n",
    "\n",
    "    outputs = []\n",
    "    all_psnrs = []\n",
    "    all_lpipses = []\n",
    "    all_ssims = []\n",
    "    for _ in range(n_repeat_generation):\n",
    "        output = pipeline(\n",
    "            prompt=prompt,\n",
    "            height=orig_hw[0],\n",
    "            width=orig_hw[1],\n",
    "            known_images=known_images,\n",
    "            output_type=\"pt\",  # return tensor normalized to [0, 1]\n",
    "            generator=generator,\n",
    "            cross_attention_kwargs=cross_attention_kwargs,\n",
    "            guidance_scale=guidance_scale,\n",
    "            image_guidance_scale=image_guidance_scale,\n",
    "            decode_all_timesteps=True,\n",
    "            num_inference_steps=num_inference_steps,\n",
    "            n_images_per_batch=model_config.n_input_images,\n",
    "        )\n",
    "\n",
    "        # re-create K dimension from batch dimension\n",
    "        output.images = output.images.unsqueeze(1)\n",
    "        expand_output_to_k(output, batch_size, model_config.n_input_images)\n",
    "\n",
    "        outputs.append(output)\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    return outputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs = process_batch(pipeline,val_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import save_image\n",
    "import matplotlib.pyplot as plt\n",
    "# batch = val_data[0]\n",
    "# save_image(outputs[0].images[0], \"output.png\")\n",
    "# save_image(batch[\"images\"], \"input.png\")\n",
    "# save_image(batch[\"target_imgs\"], \"target.png\")\n",
    "\n",
    "# plt.imshow(plt.imread(\"output.png\"))\n",
    "# plt.show()\n",
    "# plt.imshow(plt.imread(\"input.png\"))\n",
    "# plt.show()\n",
    "# plt.imshow(plt.imread(\"target.png\"))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scan</th>\n",
       "      <th>ref_view</th>\n",
       "      <th>light_idx</th>\n",
       "      <th>src_views</th>\n",
       "      <th>target_light</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>scan3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[10, 1, 9, 12, 11, 13, 2, 8, 14, 27]</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>scan3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[9, 10, 2, 0, 8, 13, 14, 12, 7, 15]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>scan3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[8, 1, 7, 9, 3, 15, 14, 16, 6, 10]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>scan3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>[7, 6, 2, 4, 8, 5, 17, 16, 1, 15]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>scan3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>[5, 6, 3, 7, 18, 2, 17, 8, 16, 1]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    scan  ref_view  light_idx                             src_views  \\\n",
       "0  scan3         0          0  [10, 1, 9, 12, 11, 13, 2, 8, 14, 27]   \n",
       "1  scan3         1          0   [9, 10, 2, 0, 8, 13, 14, 12, 7, 15]   \n",
       "2  scan3         2          0    [8, 1, 7, 9, 3, 15, 14, 16, 6, 10]   \n",
       "3  scan3         3          0     [7, 6, 2, 4, 8, 5, 17, 16, 1, 15]   \n",
       "4  scan3         4          0     [5, 6, 3, 7, 18, 2, 17, 8, 16, 1]   \n",
       "\n",
       "   target_light  \n",
       "0             6  \n",
       "1             0  \n",
       "2             5  \n",
       "3             2  \n",
       "4             1  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import DataFrame\n",
    "df = DataFrame(val_data.metas,columns=[\"scan\",\"ref_view\",\"light_idx\",\"src_views\",\"target_light\"])    \n",
    "df.head()                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['scan3', 'scan5', 'scan17', 'scan21', 'scan28', 'scan35', 'scan37',\n",
       "       'scan38', 'scan40', 'scan43', 'scan56', 'scan59', 'scan66',\n",
       "       'scan67', 'scan82', 'scan86', 'scan106', 'scan117'], dtype=object)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"scan\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "import sys\n",
    "sys.path.append('/root/autodl-tmp/project/dp_simple/')\n",
    "#import ViT\n",
    "from torchvision import transforms as T\n",
    "from CasMVSNet_pl.models.mvsnet import CascadeMVSNet\n",
    "from CasMVSNet_pl.utils import load_ckpt\n",
    "from CasMVSNet_pl.datasets.dtu import DTUDataset  \n",
    "from CasMVSNet_pl.utils import *\n",
    "from CasMVSNet_pl.datasets.dtu import DTUDataset \n",
    "from CasMVSNet_pl.metrics import *  \n",
    "from inplace_abn import ABN\n",
    "\n",
    "import pytorch_ssim\n",
    "import pytorch_lightning as pl\n",
    "import pytorch_ssim\n",
    "import pytorch_lightning as pl\n",
    "import sys\n",
    "sys.path.append('/root/autodl-tmp/D3Dnet/code')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import functools\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from collections import namedtuple\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "from einops import rearrange\n",
    "from torchvision import models\n",
    "import sys\n",
    "\n",
    "from CasMVSNet_pl.datasets.utils import save_pfm, read_pfm\n",
    "import cv2\n",
    "import torch\n",
    "import os, shutil\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "# for depth prediction\n",
    "from CasMVSNet_pl.models.mvsnet import CascadeMVSNet\n",
    "from CasMVSNet_pl.utils import load_ckpt\n",
    "from inplace_abn import ABN\n",
    "\n",
    "# for point cloud fusion\n",
    "from numba import jit\n",
    "from plyfile import PlyData, PlyElement\n",
    "\n",
    "torch.backends.cudnn.benchmark = True # this increases inference speed a little"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True # this increases inference speed a little\n",
    "\n",
    "def get_opts():\n",
    "    parser = ArgumentParser()\n",
    "    parser.add_argument('--root_dir', type=str,\n",
    "                        default='/root/autodl-tmp/mvs_training/dtu',\n",
    "                        help='root directory of dtu dataset')\n",
    "    parser.add_argument('--dataset_name', type=str, default='dtu',\n",
    "                        choices=['dtu', 'tanks', 'blendedmvs'],\n",
    "                        help='which dataset to train/val')\n",
    "    parser.add_argument('--split', type=str, default='train',\n",
    "                        help='which split to evaluate')\n",
    "    parser.add_argument('--scan', type=str, default='scan7',\n",
    "                        help='specify scan to evaluate (must be in the split)')\n",
    "    parser.add_argument('--cpu', default=False, action='store_true',\n",
    "                        help='''use cpu to do depth inference.\n",
    "                                WARNING: It is going to be EXTREMELY SLOW!\n",
    "                                about 37s/view, so in total 30min/scan. \n",
    "                             ''')\n",
    "    # for depth prediction\n",
    "    parser.add_argument('--n_views', type=int, default=3,\n",
    "                        help='number of views (including ref) to be used in testing')\n",
    "    parser.add_argument('--depth_interval', type=float, default=2.65,\n",
    "                        help='depth interval unit in mm')\n",
    "    parser.add_argument('--n_depths', nargs='+', type=int, default=[8,32,48],\n",
    "                        help='number of depths in each level')\n",
    "    parser.add_argument('--interval_ratios', nargs='+', type=float, default=[1.0,2.0,4.0],\n",
    "                        help='depth interval ratio to multiply with --depth_interval in each level')\n",
    "    parser.add_argument('--num_groups', type=int, default=1, choices=[1, 2, 4, 8],\n",
    "                        help='number of groups in groupwise correlation, must be a divisor of 8')\n",
    "    parser.add_argument('--img_wh', nargs=\"+\", type=int, default=[640,512],\n",
    "                        help='resolution (img_w, img_h) of the image, must be multiples of 32')\n",
    "    parser.add_argument('--ckpt_path', type=str, default='/root/autodl-tmp/project/dp_simple/CasMVSNet_pl/ckpts/_ckpt_epoch_10.ckpt',\n",
    "                        help='pretrained checkpoint path to load')\n",
    "    parser.add_argument('--save_visual', default=False, action='store_true',\n",
    "                        help='save depth and proba visualization or not')\n",
    "\n",
    "    # for point cloud fusion\n",
    "    parser.add_argument('--conf', type=float, default=0.999,\n",
    "                        help='min confidence for pixel to be valid')\n",
    "    parser.add_argument('--min_geo_consistent', type=int, default=5,\n",
    "                        help='min number of consistent views for pixel to be valid')\n",
    "    parser.add_argument('--max_ref_views', type=int, default=400,\n",
    "                        help='max number of ref views (to limit RAM usage)')\n",
    "    parser.add_argument('--skip', type=int, default=1,\n",
    "                        help='''how many points to skip when creating the point cloud.\n",
    "                                Larger = fewer points and smaller file size.\n",
    "                                Ref: skip=10 creates ~= 3M points = 50MB file\n",
    "                                     skip=1 creates ~= 30M points = 500MB file\n",
    "                             ''')\n",
    "    args, _ = parser.parse_known_args()\n",
    "    return args\n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_batch(batch):\n",
    "    imgs = batch['images']\n",
    "    proj_mats = batch['proj_mats']\n",
    "    init_depth_min = batch['init_depth_min'].item()\n",
    "    depth_interval = batch['depth_interval'].item()\n",
    "    scan, vid = batch['scan_vid']\n",
    "    return imgs, proj_mats, init_depth_min, depth_interval, \\\n",
    "           scan, vid\n",
    "\n",
    "\n",
    "# define read_image and read_proj_mat for each dataset\n",
    "\n",
    "def read_image(dataset_name, root_dir, scan, vid):\n",
    "    if dataset_name == 'dtu':\n",
    "        return cv2.imread(os.path.join(root_dir,\n",
    "                    f'Rectified/{scan}_train/rect_{vid+1:03d}_3_r5000.png'))\n",
    "    if dataset_name == 'tanks':\n",
    "        return cv2.imread(os.path.join(root_dir, scan,\n",
    "                    f'images/{vid:08d}.jpg'))\n",
    "    if dataset_name == 'blendedmvs':\n",
    "        return cv2.imread(os.path.join(root_dir, scan,\n",
    "                    f'blended_images/{vid:08d}.jpg'))\n",
    "\n",
    "\n",
    "def read_refined_image(dataset_name, scan, vid):\n",
    "    return cv2.imread(f'results/{dataset_name}/image_refined/{scan}/{vid:08d}.png')\n",
    "\n",
    "\n",
    "def save_refined_image(image_refined, dataset_name, scan, vid):\n",
    "    cv2.imwrite(f'results/{dataset_name}/image_refined/{scan}/{vid:08d}.png',\n",
    "                image_refined)\n",
    "\n",
    "\n",
    "def read_proj_mat(dataset_name, dataset, scan, vid):\n",
    "    if dataset_name == 'dtu':\n",
    "        return dataset.proj_mats[vid][0][0].numpy()\n",
    "    if dataset_name in ['tanks', 'blendedmvs']:\n",
    "        return dataset.proj_mats[scan][vid][0][0].numpy()\n",
    "\n",
    "\n",
    "@jit(nopython=True, fastmath=True)\n",
    "def xy_ref2src(xy_ref, depth_ref, P_world2ref,\n",
    "               depth_src, P_world2src, img_wh):\n",
    "    # create ref grid and project to ref 3d coordinate using depth_ref\n",
    "    xyz_ref = np.vstack((xy_ref, np.ones_like(xy_ref[:1]))) * depth_ref\n",
    "    xyz_ref_h = np.vstack((xyz_ref, np.ones_like(xy_ref[:1])))\n",
    "\n",
    "    P = (P_world2src @ np.ascontiguousarray(np.linalg.inv(P_world2ref)))[:3]\n",
    "    # project to src 3d coordinate using P_world2ref and P_world2src\n",
    "    xyz_src_h = P @ xyz_ref_h.reshape(4,-1)\n",
    "    xy_src = xyz_src_h[:2]/xyz_src_h[2:3]\n",
    "    xy_src = xy_src.reshape(2, img_wh[1], img_wh[0])\n",
    "\n",
    "    return xy_src\n",
    "\n",
    "\n",
    "@jit(nopython=True, fastmath=True)\n",
    "def xy_src2ref(xy_ref, xy_src, depth_ref, P_world2ref,\n",
    "               depth_src2ref, P_world2src, img_wh):\n",
    "    # project xy_src back to ref view using the sampled depth\n",
    "    xyz_src = np.vstack((xy_src, np.ones_like(xy_src[:1]))) * depth_src2ref\n",
    "    xyz_src_h = np.vstack((xyz_src, np.ones_like(xy_src[:1])))\n",
    "    P = (P_world2ref @ np.ascontiguousarray(np.linalg.inv(P_world2src)))[:3]\n",
    "    xyz_ref_h = P @ xyz_src_h.reshape(4,-1)\n",
    "    depth_ref_reproj = xyz_ref_h[2].reshape(img_wh[1], img_wh[0])\n",
    "    xy_ref_reproj = xyz_ref_h[:2]/xyz_ref_h[2:3]\n",
    "    xy_ref_reproj = xy_ref_reproj.reshape(2, img_wh[1], img_wh[0])\n",
    "\n",
    "    # check |p_reproj-p_1| < 1\n",
    "    pixel_diff = xy_ref_reproj - xy_ref\n",
    "    mask_pixel_reproj = (pixel_diff[0]**2+pixel_diff[1]**2)<1\n",
    "\n",
    "    # check |d_reproj-d_1| / d_1 < 0.01\n",
    "    mask_depth_reproj = np.abs((depth_ref_reproj-depth_ref)/depth_ref)<0.01\n",
    "\n",
    "    mask_geo = mask_pixel_reproj & mask_depth_reproj\n",
    "\n",
    "    return depth_ref_reproj, mask_geo\n",
    "\n",
    "\n",
    "def check_geo_consistency(depth_ref, P_world2ref,\n",
    "                          depth_src, P_world2src,\n",
    "                          image_ref, image_src,\n",
    "                          img_wh):\n",
    "    \"\"\"\n",
    "    Check the geometric consistency between ref and src views.\n",
    "    \"\"\"\n",
    "    xy_ref = np.mgrid[:img_wh[1],:img_wh[0]][::-1].astype(np.float32)\n",
    "    xy_src = xy_ref2src(xy_ref, depth_ref, P_world2ref,\n",
    "                        depth_src, P_world2src, img_wh)\n",
    "\n",
    "    # Sample the depth of xy_src using bilinear interpolation\n",
    "    depth_src2ref = cv2.remap(depth_src,\n",
    "                              xy_src[0].astype(np.float32),\n",
    "                              xy_src[1].astype(np.float32),\n",
    "                              interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    image_src2ref = cv2.remap(image_src,\n",
    "                              xy_src[0].astype(np.float32),\n",
    "                              xy_src[1].astype(np.float32),\n",
    "                              interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    depth_ref_reproj, mask_geo = \\\n",
    "        xy_src2ref(xy_ref, xy_src, depth_ref, P_world2ref, \n",
    "                   depth_src2ref, P_world2src, img_wh)\n",
    "\n",
    "    depth_ref_reproj[~mask_geo] = 0\n",
    "    image_src2ref[~mask_geo] = 0\n",
    "    \n",
    "    return depth_ref_reproj, mask_geo, image_src2ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abs_error(depth_pred, depth_gt, mask):\n",
    "    depth_pred, depth_gt = depth_pred[mask], depth_gt[mask]\n",
    "    return np.abs(depth_pred - depth_gt)\n",
    "\n",
    "def acc_threshold(depth_pred, depth_gt, mask, threshold):\n",
    "    \"\"\"\n",
    "    computes the percentage of pixels whose depth error is less than @threshold\n",
    "    \"\"\"\n",
    "    errors = abs_error(depth_pred, depth_gt, mask)\n",
    "    acc_mask = errors < threshold\n",
    "    return acc_mask.mean()\n",
    "\n",
    "def return_log(result1,result2,gt_depth,mask):\n",
    "    depth_pred = result1[\"depth_0\"][0].cpu().numpy()\n",
    "    ori_pred = result2[\"depth_0\"][0].cpu().numpy()\n",
    "\n",
    "    print(depth_pred.shape, ori_pred.shape, gt_depth.shape, mask.shape)\n",
    "    \n",
    "\n",
    "    abs_error1 = abs_error(depth_pred, gt_depth, mask).mean()\n",
    "    abs_error2 = abs_error(ori_pred, gt_depth, mask).mean()\n",
    "    print(f\"depth modified is {abs_error1},original error is {abs_error2} \")\n",
    "    abs_diff = abs_error1 - abs_error2\n",
    "    abs_ratio = abs_error1 / abs_error2\n",
    "\n",
    "    acc1mm1 = acc_threshold(depth_pred, gt_depth, mask, 1)\n",
    "    acc1mm2 = acc_threshold(ori_pred, gt_depth, mask, 1)\n",
    "    acc_diff = acc1mm1 - acc1mm2\n",
    "    acc_ratio = acc1mm1 / (acc1mm2+1e-7)\n",
    "\n",
    "    acc2mm1 = acc_threshold(depth_pred, gt_depth, mask, 2)\n",
    "    acc2mm2 = acc_threshold(ori_pred, gt_depth, mask, 2)\n",
    "    acc_diff2 = acc2mm1 - acc2mm2\n",
    "    acc_ratio2 = acc2mm1 / (acc2mm2+1e-7)\n",
    "\n",
    "    acc3mm1 = acc_threshold(depth_pred, gt_depth, mask, 3)\n",
    "    acc3mm2 = acc_threshold(ori_pred, gt_depth, mask, 3)\n",
    "    acc_diff3 = acc3mm1 - acc3mm2\n",
    "    acc_ratio3 = acc3mm1 / (acc3mm2+1e-7)\n",
    "\n",
    "    acc4mm1 = acc_threshold(depth_pred, gt_depth, mask, 4)\n",
    "    acc4mm2 = acc_threshold(ori_pred, gt_depth, mask, 4)\n",
    "    acc_diff4 = acc4mm1 - acc4mm2\n",
    "    acc_ratio4 = acc4mm1 / (acc4mm2+1e-7)\n",
    "\n",
    "    return {\"abs_diff\":abs_diff,\"abs_ratio\":abs_ratio,\"acc_diff1\":acc_diff,\"acc_ratio1\":acc_ratio,\n",
    "            \"acc_diff2\":acc_diff2,\"acc_ratio2\":acc_ratio2,\"acc_diff3\":acc_diff3,\"acc_ratio3\":acc_ratio3,\n",
    "            \"acc_diff4\":acc_diff4,\"acc_ratio4\":acc_ratio4}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = get_opts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CascadeMVSNet(\n",
       "  (feature): FeatureNet(\n",
       "    (conv0): Sequential(\n",
       "      (0): ConvBnReLU(\n",
       "        (conv): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): ABN(8, eps=1e-05, momentum=0.1, affine=True, activation=leaky_relu[0.01])\n",
       "      )\n",
       "      (1): ConvBnReLU(\n",
       "        (conv): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): ABN(8, eps=1e-05, momentum=0.1, affine=True, activation=leaky_relu[0.01])\n",
       "      )\n",
       "    )\n",
       "    (conv1): Sequential(\n",
       "      (0): ConvBnReLU(\n",
       "        (conv): Conv2d(8, 16, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
       "        (bn): ABN(16, eps=1e-05, momentum=0.1, affine=True, activation=leaky_relu[0.01])\n",
       "      )\n",
       "      (1): ConvBnReLU(\n",
       "        (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): ABN(16, eps=1e-05, momentum=0.1, affine=True, activation=leaky_relu[0.01])\n",
       "      )\n",
       "      (2): ConvBnReLU(\n",
       "        (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): ABN(16, eps=1e-05, momentum=0.1, affine=True, activation=leaky_relu[0.01])\n",
       "      )\n",
       "    )\n",
       "    (conv2): Sequential(\n",
       "      (0): ConvBnReLU(\n",
       "        (conv): Conv2d(16, 32, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
       "        (bn): ABN(32, eps=1e-05, momentum=0.1, affine=True, activation=leaky_relu[0.01])\n",
       "      )\n",
       "      (1): ConvBnReLU(\n",
       "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): ABN(32, eps=1e-05, momentum=0.1, affine=True, activation=leaky_relu[0.01])\n",
       "      )\n",
       "      (2): ConvBnReLU(\n",
       "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): ABN(32, eps=1e-05, momentum=0.1, affine=True, activation=leaky_relu[0.01])\n",
       "      )\n",
       "    )\n",
       "    (toplayer): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (lat1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (lat0): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (smooth1): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (smooth0): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (cost_reg_0): CostRegNet(\n",
       "    (conv0): ConvBnReLU3D(\n",
       "      (conv): Conv3d(8, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn): ABN(8, eps=1e-05, momentum=0.1, affine=True, activation=leaky_relu[0.01])\n",
       "    )\n",
       "    (conv1): ConvBnReLU3D(\n",
       "      (conv): Conv3d(8, 16, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "      (bn): ABN(16, eps=1e-05, momentum=0.1, affine=True, activation=leaky_relu[0.01])\n",
       "    )\n",
       "    (conv2): ConvBnReLU3D(\n",
       "      (conv): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn): ABN(16, eps=1e-05, momentum=0.1, affine=True, activation=leaky_relu[0.01])\n",
       "    )\n",
       "    (conv3): ConvBnReLU3D(\n",
       "      (conv): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "      (bn): ABN(32, eps=1e-05, momentum=0.1, affine=True, activation=leaky_relu[0.01])\n",
       "    )\n",
       "    (conv4): ConvBnReLU3D(\n",
       "      (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn): ABN(32, eps=1e-05, momentum=0.1, affine=True, activation=leaky_relu[0.01])\n",
       "    )\n",
       "    (conv5): ConvBnReLU3D(\n",
       "      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "      (bn): ABN(64, eps=1e-05, momentum=0.1, affine=True, activation=leaky_relu[0.01])\n",
       "    )\n",
       "    (conv6): ConvBnReLU3D(\n",
       "      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn): ABN(64, eps=1e-05, momentum=0.1, affine=True, activation=leaky_relu[0.01])\n",
       "    )\n",
       "    (conv7): Sequential(\n",
       "      (0): ConvTranspose3d(64, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1), bias=False)\n",
       "      (1): ABN(32, eps=1e-05, momentum=0.1, affine=True, activation=leaky_relu[0.01])\n",
       "    )\n",
       "    (conv9): Sequential(\n",
       "      (0): ConvTranspose3d(32, 16, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1), bias=False)\n",
       "      (1): ABN(16, eps=1e-05, momentum=0.1, affine=True, activation=leaky_relu[0.01])\n",
       "    )\n",
       "    (conv11): Sequential(\n",
       "      (0): ConvTranspose3d(16, 8, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1), bias=False)\n",
       "      (1): ABN(8, eps=1e-05, momentum=0.1, affine=True, activation=leaky_relu[0.01])\n",
       "    )\n",
       "    (prob): Conv3d(8, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  )\n",
       "  (cost_reg_1): CostRegNet(\n",
       "    (conv0): ConvBnReLU3D(\n",
       "      (conv): Conv3d(16, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn): ABN(8, eps=1e-05, momentum=0.1, affine=True, activation=leaky_relu[0.01])\n",
       "    )\n",
       "    (conv1): ConvBnReLU3D(\n",
       "      (conv): Conv3d(8, 16, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "      (bn): ABN(16, eps=1e-05, momentum=0.1, affine=True, activation=leaky_relu[0.01])\n",
       "    )\n",
       "    (conv2): ConvBnReLU3D(\n",
       "      (conv): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn): ABN(16, eps=1e-05, momentum=0.1, affine=True, activation=leaky_relu[0.01])\n",
       "    )\n",
       "    (conv3): ConvBnReLU3D(\n",
       "      (conv): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "      (bn): ABN(32, eps=1e-05, momentum=0.1, affine=True, activation=leaky_relu[0.01])\n",
       "    )\n",
       "    (conv4): ConvBnReLU3D(\n",
       "      (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn): ABN(32, eps=1e-05, momentum=0.1, affine=True, activation=leaky_relu[0.01])\n",
       "    )\n",
       "    (conv5): ConvBnReLU3D(\n",
       "      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "      (bn): ABN(64, eps=1e-05, momentum=0.1, affine=True, activation=leaky_relu[0.01])\n",
       "    )\n",
       "    (conv6): ConvBnReLU3D(\n",
       "      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn): ABN(64, eps=1e-05, momentum=0.1, affine=True, activation=leaky_relu[0.01])\n",
       "    )\n",
       "    (conv7): Sequential(\n",
       "      (0): ConvTranspose3d(64, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1), bias=False)\n",
       "      (1): ABN(32, eps=1e-05, momentum=0.1, affine=True, activation=leaky_relu[0.01])\n",
       "    )\n",
       "    (conv9): Sequential(\n",
       "      (0): ConvTranspose3d(32, 16, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1), bias=False)\n",
       "      (1): ABN(16, eps=1e-05, momentum=0.1, affine=True, activation=leaky_relu[0.01])\n",
       "    )\n",
       "    (conv11): Sequential(\n",
       "      (0): ConvTranspose3d(16, 8, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1), bias=False)\n",
       "      (1): ABN(8, eps=1e-05, momentum=0.1, affine=True, activation=leaky_relu[0.01])\n",
       "    )\n",
       "    (prob): Conv3d(8, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  )\n",
       "  (cost_reg_2): CostRegNet(\n",
       "    (conv0): ConvBnReLU3D(\n",
       "      (conv): Conv3d(32, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn): ABN(8, eps=1e-05, momentum=0.1, affine=True, activation=leaky_relu[0.01])\n",
       "    )\n",
       "    (conv1): ConvBnReLU3D(\n",
       "      (conv): Conv3d(8, 16, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "      (bn): ABN(16, eps=1e-05, momentum=0.1, affine=True, activation=leaky_relu[0.01])\n",
       "    )\n",
       "    (conv2): ConvBnReLU3D(\n",
       "      (conv): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn): ABN(16, eps=1e-05, momentum=0.1, affine=True, activation=leaky_relu[0.01])\n",
       "    )\n",
       "    (conv3): ConvBnReLU3D(\n",
       "      (conv): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "      (bn): ABN(32, eps=1e-05, momentum=0.1, affine=True, activation=leaky_relu[0.01])\n",
       "    )\n",
       "    (conv4): ConvBnReLU3D(\n",
       "      (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn): ABN(32, eps=1e-05, momentum=0.1, affine=True, activation=leaky_relu[0.01])\n",
       "    )\n",
       "    (conv5): ConvBnReLU3D(\n",
       "      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "      (bn): ABN(64, eps=1e-05, momentum=0.1, affine=True, activation=leaky_relu[0.01])\n",
       "    )\n",
       "    (conv6): ConvBnReLU3D(\n",
       "      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn): ABN(64, eps=1e-05, momentum=0.1, affine=True, activation=leaky_relu[0.01])\n",
       "    )\n",
       "    (conv7): Sequential(\n",
       "      (0): ConvTranspose3d(64, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1), bias=False)\n",
       "      (1): ABN(32, eps=1e-05, momentum=0.1, affine=True, activation=leaky_relu[0.01])\n",
       "    )\n",
       "    (conv9): Sequential(\n",
       "      (0): ConvTranspose3d(32, 16, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1), bias=False)\n",
       "      (1): ABN(16, eps=1e-05, momentum=0.1, affine=True, activation=leaky_relu[0.01])\n",
       "    )\n",
       "    (conv11): Sequential(\n",
       "      (0): ConvTranspose3d(16, 8, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1), bias=False)\n",
       "      (1): ABN(8, eps=1e-05, momentum=0.1, affine=True, activation=leaky_relu[0.01])\n",
       "    )\n",
       "    (prob): Conv3d(8, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CascadeMVSNet(n_depths=args.n_depths,\n",
    "                        interval_ratios=args.interval_ratios,\n",
    "                        num_groups=args.num_groups,\n",
    "                        norm_act=ABN)\n",
    "device = 'cpu' if args.cpu else 'cuda:0'\n",
    "model.to(device)\n",
    "load_ckpt(model, args.ckpt_path)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 640])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data[0][\"depths\"][\"level_0\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.Compose([T.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "std=[0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "refine = False\n",
    "read_gt = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating depth and confidence predictions...\n",
      "Processing scan3 with 49 views\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/49 [00:00<00:07,  6.29it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:07<00:00,  6.40it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Creating depth and confidence predictions...')\n",
    "for scan in [\"scan3\"]:\n",
    "    depth_dir = f'./results/{args.dataset_name}/depth'\n",
    "    depth_dir = os.path.join(depth_dir, scan)\n",
    "\n",
    "    img_dir = f'./results/{args.dataset_name}/image_modified'\n",
    "    img_dir = os.path.join(img_dir, scan)\n",
    "\n",
    "    os.makedirs(depth_dir, exist_ok=True)\n",
    "    os.makedirs(img_dir, exist_ok=True)\n",
    "\n",
    "    abs_ratio = []\n",
    "    acc_ratio1 = []\n",
    "    acc_ratio2 = []\n",
    "    acc_ratio3 = []\n",
    "    acc_ratio4 = []\n",
    "    acc_diff1 = []\n",
    "    acc_diff2 = []\n",
    "    acc_diff3 = []\n",
    "    acc_diff4 = []\n",
    "    abs_diff = []\n",
    "\n",
    "    data_range = [i for i, x in enumerate(val_data.metas) if x[0] == scan]\n",
    "    print(f'Processing {scan} with {len(data_range)} views')\n",
    "    for i in tqdm(data_range):\n",
    "        batch =  val_data[i]\n",
    "       \n",
    "        imgs, proj_mats, init_depth_min, depth_interval, \\\n",
    "            scan, vid = decode_batch(batch)\n",
    "        proj_mats = proj_mats.unsqueeze(0).to(\"cuda\")\n",
    "       \n",
    "        \n",
    "        \n",
    "        \n",
    "        os.makedirs(os.path.join(depth_dir, scan), exist_ok=True)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            imgs = imgs.unsqueeze(0).to(device)\n",
    "           \n",
    "            \n",
    "            \n",
    "            if refine == True:\n",
    "                # whether image exist or not\n",
    "                modified_path = os.path.join(img_dir, f'{vid:04d}_class6.npy')\n",
    "                if os.path.exists(modified_path):\n",
    "                    np_array = np.load(modified_path)\n",
    "                    modified_imgs = torch.tensor(np_array).unsqueeze(0).cuda()\n",
    "                    results_modified = model(transform(modified_imgs), proj_mats, init_depth_min, depth_interval)\n",
    "                else:\n",
    "                    modified_imgs = process_batch(pipeline,batch)[0].images\n",
    "                    results_modified = model(transform(modified_imgs), proj_mats, init_depth_min, depth_interval)\n",
    "                imgs_original = imgs[0]\n",
    "                pred_imgs = modified_imgs[0]\n",
    "                torch.stack([imgs_original, pred_imgs], dim=0)\n",
    "                save_image(torch.cat([imgs_original, pred_imgs], dim=0), \n",
    "                           os.path.join(img_dir, f'{vid:04d}_class6.png'))\n",
    "                np.save(os.path.join(img_dir, f'{vid:04d}_class6.npy'), pred_imgs.cpu().numpy())\n",
    "            \n",
    "                results_ori = model(transform(imgs), proj_mats, init_depth_min, depth_interval)\n",
    "\n",
    "                metric_logs = return_log(results_modified,\n",
    "                                        results_ori,\n",
    "                                        val_data[i][\"depths\"][\"level_0\"].numpy(),\n",
    "                                        val_data[i][\"masks\"][\"level_0\"].numpy())\n",
    "                abs_ratio.append(metric_logs[\"abs_ratio\"])\n",
    "                acc_ratio1.append(metric_logs[\"acc_ratio1\"])\n",
    "                acc_ratio2.append(metric_logs[\"acc_ratio2\"])\n",
    "                acc_ratio3.append(metric_logs[\"acc_ratio3\"])\n",
    "                acc_ratio4.append(metric_logs[\"acc_ratio4\"])\n",
    "                acc_diff1.append(metric_logs[\"acc_diff1\"])\n",
    "                acc_diff2.append(metric_logs[\"acc_diff2\"])\n",
    "                acc_diff3.append(metric_logs[\"acc_diff3\"])\n",
    "                acc_diff4.append(metric_logs[\"acc_diff4\"])\n",
    "                abs_diff.append(metric_logs[\"abs_diff\"])\n",
    "\n",
    "                # print output\n",
    "                sys.stdout.write(f'\\r{scan} {vid:04d} '\n",
    "                                f'abs_diff: {np.mean(abs_diff)} '\n",
    "                                f'abs_ratio: {np.mean(abs_ratio)} '\n",
    "                                f'acc_diff1: {np.mean(acc_diff1)} '\n",
    "                                f'acc_ratio1: {np.mean(acc_ratio1)} '\n",
    "                                f'acc_diff2: {np.mean(acc_diff2)} '\n",
    "                                f'acc_ratio2: {np.mean(acc_ratio2)} '\n",
    "                                f'acc_diff3: {np.mean(acc_diff3)} '\n",
    "                                f'acc_ratio3: {np.mean(acc_ratio3)} '\n",
    "                                f'acc_diff4: {np.mean(acc_diff4)} '\n",
    "                                f'acc_ratio4: {np.mean(acc_ratio4)} ')\n",
    "                \n",
    "                sys.stdout.flush()\n",
    "            else:\n",
    "                results_ori = model(transform(imgs), proj_mats, init_depth_min, depth_interval)\n",
    "\n",
    "\n",
    "            \n",
    "        if refine == True:\n",
    "            depth = results_modified['depth_0'][0].cpu().numpy()\n",
    "            depth = np.nan_to_num(depth)\n",
    "            proba = results_modified['confidence_2'][0].cpu().numpy()\n",
    "            proba = np.nan_to_num(proba)\n",
    "            save_pfm(os.path.join(depth_dir, f'{scan}/depth_{vid:04d}_class6.pfm'), depth)\n",
    "            save_pfm(os.path.join(depth_dir, f'{scan}/proba_{vid:04d}_class6.pfm'), proba)\n",
    "        else:   \n",
    "            depth = results_ori['depth_0'][0].cpu().numpy()\n",
    "            depth = np.nan_to_num(depth) # change nan to 0\n",
    "            proba = results_ori['confidence_2'][0].cpu().numpy() # NOTE: this is 1/4 scale!\n",
    "            proba = np.nan_to_num(proba) # change nan to 0\n",
    "            save_pfm(os.path.join(depth_dir, f'{scan}/depth_{vid:04d}.pfm'), depth)\n",
    "            save_pfm(os.path.join(depth_dir, f'{scan}/proba_{vid:04d}.pfm'), proba)\n",
    "        if args.save_visual:\n",
    "            mi = np.min(depth[depth>0])\n",
    "            ma = np.max(depth)\n",
    "            depth = (depth-mi)/(ma-mi+1e-8)\n",
    "            depth = (255*depth).astype(np.uint8)\n",
    "            depth_img = cv2.applyColorMap(depth, cv2.COLORMAP_JET)\n",
    "            cv2.imwrite(os.path.join(depth_dir, f'{scan}/depth_visual_{vid:04d}.jpg'),\n",
    "                        depth_img)\n",
    "            cv2.imwrite(os.path.join(depth_dir, f'{scan}/proba_visual_{vid:04d}.jpg'),\n",
    "                        (255*(proba>args.conf)).astype(np.uint8))\n",
    "        del imgs, proj_mats, results_ori\n",
    "    \n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusing point clouds...\n",
      "Processing scan106 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:43<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scan106 contains 3.67 M points\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Step 2. Perform depth filtering and fusion\n",
    "point_dir = f'results/{args.dataset_name}/points'\n",
    "os.makedirs(point_dir, exist_ok=True)\n",
    "print('Fusing point clouds...')\n",
    "\n",
    "for scan in [\"scan106\"]:\n",
    "    print(f'Processing {scan} ...')\n",
    "    \n",
    "    # buffers for the final vertices of this scan\n",
    "    vs = []\n",
    "    v_colors = []\n",
    "    # buffers storing the refined data of each ref view\n",
    "    os.makedirs(f'results/{args.dataset_name}/image_refined/{scan}', exist_ok=True)\n",
    "    image_refined = set()\n",
    "    depth_refined = {}\n",
    "    for meta in tqdm(list(filter(lambda x: x[0]==scan and x[2]==0, val_data.metas))[:args.max_ref_views]):\n",
    "       \n",
    "        try:\n",
    "            ref_vid = meta[2]\n",
    "            if ref_vid in image_refined: # not yet refined actually\n",
    "                image_ref = read_refined_image(args.dataset_name, scan, ref_vid)\n",
    "                depth_ref = depth_refined[ref_vid]\n",
    "            else:\n",
    "                if refine:\n",
    "                    img_dir = f'./results/{args.dataset_name}/image_modified/{scan}'\n",
    "                    image_ref = np.load(os.path.join(img_dir, f'{ref_vid:04d}_class6.npy'))[0]\n",
    "                    print(image_ref.shape)\n",
    "                    image_ref *= 255\n",
    "                    image_ref = image_ref.transpose(1,2,0)\n",
    "                    image_ref = image_ref.astype(np.uint8)\n",
    "                    image_ref = cv2.resize(image_ref, tuple(args.img_wh))\n",
    "                    print(image_ref.shape)\n",
    "\n",
    "                else:\n",
    "                    image_ref = read_image(args.dataset_name, args.root_dir, scan, ref_vid)\n",
    "                    image_ref = cv2.resize(image_ref, tuple(args.img_wh),\n",
    "                                            interpolation=cv2.INTER_LINEAR)[:,:,::-1] # to RGB\n",
    "                \n",
    "                if read_gt:\n",
    "                    depth_ref = read_pfm(f'{args.root_dir}/Depths/{scan}/depth_map_{ref_vid:04d}.pfm')[0]\n",
    "                    depth_ref = cv2.resize(depth_ref, tuple(args.img_wh),\n",
    "                                            interpolation=cv2.INTER_LINEAR)\n",
    "                else:\n",
    "                    depth_ref = read_pfm(f'results/{args.dataset_name}/depth/' \\\n",
    "                                            f'{scan}/{scan}/depth_{ref_vid:04d}.pfm')[0]\n",
    "                    print(depth_ref.shape)\n",
    "            if read_gt:\n",
    "                proba_ref = np.ones_like(depth_ref)\n",
    "            proba_ref = read_pfm(f'results/{args.dataset_name}/depth/' \\\n",
    "                                    f'{scan}/{scan}/proba_{ref_vid:04d}.pfm')[0]\n",
    "            proba_ref = cv2.resize(proba_ref, None, fx=4, fy=4,\n",
    "                                    interpolation=cv2.INTER_LINEAR)\n",
    "            mask_conf = proba_ref > args.conf # confidence mask\n",
    "            P_world2ref = read_proj_mat(args.dataset_name, val_data, scan, ref_vid)\n",
    "            \n",
    "            src_vids = meta[3]\n",
    "            mask_geos = []\n",
    "            depth_ref_reprojs = [depth_ref]\n",
    "            image_src2refs = [image_ref]\n",
    "            # for each src view, check the consistency and refine depth\n",
    "            for src_vid in src_vids:\n",
    "                if src_vid in image_refined: # use refined data of previous runs\n",
    "                    image_src = read_refined_image(args.dataset_name, scan, src_vid)\n",
    "                    depth_src = depth_refined[src_vid]\n",
    "                else:\n",
    "                    image_src = read_image(args.dataset_name, args.root_dir, scan, src_vid)\n",
    "                    image_src = cv2.resize(image_src, tuple(args.img_wh),\n",
    "                                            interpolation=cv2.INTER_LINEAR)[:,:,::-1] # to RGB\n",
    "                    depth_src = read_pfm(f'results/{args.dataset_name}/depth/' \\\n",
    "                                            f'{scan}/{scan}/depth_{src_vid:04d}.pfm')[0]\n",
    "                    depth_refined[src_vid] = depth_src\n",
    "                P_world2src = read_proj_mat(args.dataset_name, val_data, scan, src_vid)\n",
    "                depth_ref_reproj, mask_geo, image_src2ref = \\\n",
    "                    check_geo_consistency(depth_ref, P_world2ref,\n",
    "                                            depth_src, P_world2src,\n",
    "                                            image_ref, image_src, tuple(args.img_wh))\n",
    "                depth_ref_reprojs += [depth_ref_reproj]\n",
    "                image_src2refs += [image_src2ref]\n",
    "                mask_geos += [mask_geo]\n",
    "            mask_geo_sum = np.sum(mask_geos, 0)\n",
    "            mask_geo_final = mask_geo_sum >= args.min_geo_consistent\n",
    "            depth_refined[ref_vid] = \\\n",
    "                (np.sum(depth_ref_reprojs, 0)/(mask_geo_sum+1)).astype(np.float32)\n",
    "            image_refined_ = \\\n",
    "                np.sum(image_src2refs, 0)/np.expand_dims((mask_geo_sum+1), -1)\n",
    "\n",
    "            image_refined.add(ref_vid)\n",
    "            save_refined_image(image_refined_, args.dataset_name, scan, ref_vid)\n",
    "            mask_final = mask_conf & mask_geo_final\n",
    "            \n",
    "            # create the final points\n",
    "            xy_ref = np.mgrid[:args.img_wh[1],:args.img_wh[0]][::-1]\n",
    "            xyz_ref = np.vstack((xy_ref, np.ones_like(xy_ref[:1]))) * depth_refined[ref_vid]\n",
    "            xyz_ref = xyz_ref.transpose(1,2,0)[mask_final].T # (3, N)\n",
    "            color = image_refined_[mask_final] # (N, 3)\n",
    "            xyz_ref_h = np.vstack((xyz_ref, np.ones_like(xyz_ref[:1])))\n",
    "            xyz_world = (np.linalg.inv(P_world2ref) @ xyz_ref_h).T # (N, 4)\n",
    "            xyz_world = xyz_world[::args.skip, :3]\n",
    "            color = color[::args.skip]\n",
    "            \n",
    "            # append to buffers\n",
    "            vs += [xyz_world]\n",
    "            v_colors += [color]\n",
    "\n",
    "        except Exception as e:\n",
    "            # some scenes might not have depth prediction due to too few valid src views\n",
    "            \n",
    "            print(f'Error: {e}')\n",
    "    # clear refined buffer\n",
    "    image_refined.clear()\n",
    "    depth_refined.clear()\n",
    "    shutil.rmtree(f'results/{args.dataset_name}/image_refined/{scan}')\n",
    "\n",
    "    # process all points in the buffers\n",
    "    vs = np.ascontiguousarray(np.vstack(vs).astype(np.float32))\n",
    "    v_colors = np.vstack(v_colors).astype(np.uint8)\n",
    "    print(f'{scan} contains {len(vs)/1e6:.2f} M points')\n",
    "    vs.dtype = [('x', 'f4'), ('y', 'f4'), ('z', 'f4')]\n",
    "    v_colors.dtype = [('red', 'u1'), ('green', 'u1'), ('blue', 'u1')]\n",
    "\n",
    "    vertex_all = np.empty(len(vs), vs.dtype.descr+v_colors.dtype.descr)\n",
    "    for prop in vs.dtype.names:\n",
    "        vertex_all[prop] = vs[prop][:, 0]\n",
    "    for prop in v_colors.dtype.names:\n",
    "        vertex_all[prop] = v_colors[prop][:, 0]\n",
    "    if read_gt:\n",
    "        el = PlyElement.describe(vertex_all, 'vertex')\n",
    "        PlyData([el]).write(f'{point_dir}/{scan}_gt.ply')\n",
    "    elif refine:\n",
    "        el = PlyElement.describe(vertex_all, 'vertex')\n",
    "        PlyData([el]).write(f'{point_dir}/{scan}_refine.ply')\n",
    "    \n",
    "    else:\n",
    "        el = PlyElement.describe(vertex_all, 'vertex')\n",
    "        PlyData([el]).write(f'{point_dir}/{scan}.ply')\n",
    "    del vertex_all, vs, v_colors\n",
    "shutil.rmtree(f'results/{args.dataset_name}/image_refined')\n",
    "\n",
    "print('Done!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
