{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn \n",
    "from torch.nn import functional as F\n",
    "conv = nn.Conv3d(3, 16, (4,3,3), padding=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3, 4, 3, 3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.weight.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dcn.modules.deform_conv import *\n",
    "dcn0 = DeformConvPack_d(64,32 ,kernel_size=3, stride=1, padding=1, dimension='HW').cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 3, 32, 32])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = torch.randn(1, 64, 3, 32, 32).cuda()\n",
    "dcn0(test_data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dcn.modules.deform_conv import *\n",
    "class LoRALayer():\n",
    "    def __init__(\n",
    "        self, \n",
    "        r: int, \n",
    "        lora_alpha: int, \n",
    "        lora_dropout: float,\n",
    "        merge_weights: bool,\n",
    "    ):\n",
    "        self.r = r\n",
    "        self.lora_alpha = lora_alpha\n",
    "        # Optional dropout\n",
    "        if lora_dropout > 0.:\n",
    "            self.lora_dropout = nn.Dropout(p=lora_dropout)\n",
    "        else:\n",
    "            self.lora_dropout = lambda x: x\n",
    "        # Mark the weight as unmerged\n",
    "        self.merged = False\n",
    "        self.merge_weights = merge_weights\n",
    "class DeformConvPack_d_lora(DeformConvPack_d, LoRALayer):\n",
    "    # LoRA implemented in a dense layer\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_channels: int, \n",
    "        out_channels: int,\n",
    "        kernel_size: int,\n",
    "        r: int = 0, \n",
    "        lora_alpha: int = 1, \n",
    "        lora_dropout: float = 0.,\n",
    "        merge_weights: bool = True,\n",
    "        **kwargs\n",
    "    ):\n",
    "        DeformConvPack_d.__init__(self, in_channels, out_channels, kernel_size, **kwargs)\n",
    "        LoRALayer.__init__(self, r=r, lora_alpha=lora_alpha, lora_dropout=lora_dropout,\n",
    "                           merge_weights=merge_weights)\n",
    "        assert type(kernel_size) is int\n",
    "        # print(\"in init\")\n",
    "        # embed()\n",
    "        # Actual trainable parameters\n",
    "        if type(kernel_size) is int:\n",
    "            h,w,d = kernel_size, kernel_size, kernel_size  \n",
    "        else:\n",
    "            d,h,w = kernel_size\n",
    "        if r > 0:\n",
    "            self.lora_A = nn.Parameter(\n",
    "                self.weight.new_zeros((r, in_channels*w*d))\n",
    "            )\n",
    "            self.lora_B = nn.Parameter(\n",
    "                self.weight.new_zeros((out_channels*h, r))\n",
    "            )\n",
    "            self.scaling = self.lora_alpha / self.r\n",
    "            # Freezing the pre-trained weight matrix\n",
    "            self.weight.requires_grad = False\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        DeformConvPack_d.reset_parameters(self)\n",
    "        if hasattr(self, 'lora_A'):\n",
    "            # initialize A the same way as the default for nn.Linear and B to zero\n",
    "            nn.init.kaiming_uniform_(self.lora_A, a=math.sqrt(5))\n",
    "            nn.init.zeros_(self.lora_B)\n",
    "\n",
    "    def train(self, mode: bool = True): # True for train and False for eval\n",
    " \n",
    "        DeformConvPack_d.train(self, mode)\n",
    "        if mode:\n",
    "            if self.merge_weights and self.merged:\n",
    "                # Make sure that the weights are not merged\n",
    "                self.weight.data -= (self.lora_B @ self.lora_A).view(self.weight.shape) * self.scaling\n",
    "                self.merged = False\n",
    "        else:\n",
    "            # print(\"test\")\n",
    "            # embed()\n",
    "            if self.merge_weights and not self.merged:\n",
    "                # print(\"merging\")\n",
    "                # embed()\n",
    "                # Merge the weights and mark it\n",
    "                self.weight.data += (self.lora_B @ self.lora_A).view(self.weight.shape) * self.scaling\n",
    "                self.merged = True\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "\n",
    "        if self.r > 0 and not self.merged:\n",
    "\n",
    "           \n",
    "             \n",
    "            self.weight + (self.lora_B @ self.lora_A).view(self.weight.shape) * self.scaling\n",
    "            \n",
    "        \n",
    "        return DeformConvPack_d.forward(self, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeformConvPack_d_lora(DeformConvPack_d, LoRALayer):\n",
    "    # LoRA implemented in a dense layer\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_channels: int, \n",
    "        out_channels: int,\n",
    "        kernel_size: int,\n",
    "        r: int = 0, \n",
    "        lora_alpha: int = 1, \n",
    "        lora_dropout: float = 0.,\n",
    "        merge_weights: bool = True,\n",
    "        **kwargs\n",
    "    ):\n",
    "        DeformConvPack_d.__init__(self, in_channels, out_channels, kernel_size, **kwargs)\n",
    "        LoRALayer.__init__(self, r=r, lora_alpha=lora_alpha, lora_dropout=lora_dropout,\n",
    "                           merge_weights=merge_weights)\n",
    "        assert type(kernel_size) is int\n",
    "        # print(\"in init\")\n",
    "        # embed()\n",
    "        # Actual trainable parameters\n",
    "        if type(kernel_size) is int:\n",
    "            h,w,d = kernel_size, kernel_size, kernel_size  \n",
    "        else:\n",
    "            d,h,w = kernel_size\n",
    "        if r > 0:\n",
    "            self.lora_A = nn.Parameter(\n",
    "                self.weight.new_zeros((r, in_channels*w*d))\n",
    "            )\n",
    "            self.lora_B = nn.Parameter(\n",
    "                self.weight.new_zeros((out_channels*h, r))\n",
    "            )\n",
    "            self.scaling = self.lora_alpha / self.r\n",
    "            # Freezing the pre-trained weight matrix\n",
    "            self.weight.requires_grad = False\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        DeformConvPack_d.reset_parameters(self)\n",
    "        if hasattr(self, 'lora_A'):\n",
    "            # initialize A the same way as the default for nn.Linear and B to zero\n",
    "            nn.init.kaiming_uniform_(self.lora_A, a=math.sqrt(5))\n",
    "            nn.init.zeros_(self.lora_B)\n",
    "\n",
    "    def train(self, mode: bool = True): # True for train and False for eval\n",
    " \n",
    "        DeformConvPack_d.train(self, mode)\n",
    "        if mode:\n",
    "            if self.merge_weights and self.merged:\n",
    "                # Make sure that the weights are not merged\n",
    "                self.weight.data -= (self.lora_B @ self.lora_A).view(self.weight.shape) * self.scaling\n",
    "                self.merged = False\n",
    "        else:\n",
    "            # print(\"test\")\n",
    "            # embed()\n",
    "            if self.merge_weights and not self.merged:\n",
    "                # print(\"merging\")\n",
    "                # embed()\n",
    "                # Merge the weights and mark it\n",
    "                self.weight.data += (self.lora_B @ self.lora_A).view(self.weight.shape) * self.scaling\n",
    "                self.merged = True\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "\n",
    "        if self.r > 0 and not self.merged:\n",
    "\n",
    "           \n",
    "             \n",
    "            self.weight + (self.lora_B @ self.lora_A).view(self.weight.shape) * self.scaling\n",
    "            \n",
    "        \n",
    "        return DeformConvPack_d.forward(self, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "d3c2 = DeformConvPack_d_lora(64,32,3, dimension='HW',\n",
    "                              r=2,stride = 1,padding = 1, r=2,lora_alpha=1, lora_dropout=0.1, merge_weights=True).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 64, 3, 3, 3])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d3c2.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "d3c2.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 3, 32, 32])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d3c2(test_data).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
